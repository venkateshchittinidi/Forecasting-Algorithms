{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en5-hlfsUmRN"
      },
      "source": [
        "Spark setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTxy6tVgUkSu"
      },
      "source": [
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh_YtWniu70v",
        "outputId": "1b7f0f60-8ac3-4744-a671-d99b6d80c760"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install --upgrade pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 82kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f0adde9310e2057018829ce563fc88f6b0eaada18600a9ed08bb999119367b2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C2CqpeIuy6d"
      },
      "source": [
        "#!sudo apt update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mlGUpDVhXaA"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages io.delta:delta-core_2.11:0.5.0 pyspark-shell\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark \n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas \n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKm7ZezZwHT2"
      },
      "source": [
        "def read_tsv(file_path: str, header: str = \"true\"):\n",
        "    df = spark.read.options(inferSchema=\"true\", header=\"true\",sep=\"\\t\").csv(spark.read.text(file_path).limit(100000).rdd.flatMap(lambda x: x))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OFBHn2kS8wo"
      },
      "source": [
        "def GenerateGraphResponse(client, id_, col_name, DB,user_id, date_col, window):\n",
        "    coll = db.db.GraphResponse\n",
        "    val_2 = coll.find_one({\"id_\": id_, \"col_name\": col_name}, {\"response\": 1})\n",
        "    if val_2:\n",
        "        return val_2[\"response\"]\n",
        "    else:\n",
        "        val = extract_data(id_)\n",
        "        print(val)\n",
        "        resp = GenerateGraphs(client, val[\"sourcePath\"], predict_col, DB,user_id,date_col,window)\n",
        "        main_dic = {\"id_\": id_, \"col_name\": col_name, \"response\": resp}\n",
        "        coll.insert(main_dic)\n",
        "        return resp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIsQV1x6gKsY"
      },
      "source": [
        " def post(self):\n",
        "        data = request.json\n",
        "        a=get_jwt_identity()\n",
        "        filepath = getSourcePath(data['data_path'])\n",
        "        coll = db.db.ModelCollection\n",
        "        al = coll.find_one({\"data_id\" : data['data_path']})\n",
        "        if al is None :\n",
        "            coll.insert({\"data_id\" : data['data_path'],'flag':0,\"is_deleted\":0})\n",
        "        else:\n",
        "            coll.update_one({\"data_id\" : data['data_path']} , {\"$set\":{\"flag\" : 0 }})\n",
        "        model_name = data['model_name']\n",
        "        data[\"user_id\"] = a['user_id']\n",
        "        params={\"data_id\":data['data_path']}\n",
        "        version  = sessions.run_method(user_id=a['user_id'], transformation_name='Instancerow',input_kwargs=params)\n",
        "        if data['toggle'] == \"True\":\n",
        "            params = {\"user_id\":a['user_id'],\"data_path\":filepath,\"toggle\":data['toggle'],\"predict_col\":data['predict_col'] ,\"retrain\":data[\"retrain\"],\"data_id\":data['data_path'],\"submit_type\":0,\"model_name\":model_name,'model':'string'}\n",
        "            resp_ = sessions.run_method(user_id=a['user_id'], transformation_name='EverythingIntoOne', input_kwargs=params)\n",
        "            resp=db.db.MLMODEL.find_one({\"data_id\":data['data_path']})\n",
        "            if resp[\"Status\"] == 200:\n",
        "                host , user , password , domain = get_clickhouse_details_user_id(a['user_id'])\n",
        "                client = Client(host,\n",
        "                user=user,\n",
        "                password=password)\n",
        "                url=str(request.base_url).split(\"v1/\")[0] + \"v1/\" + \"Instances/ManualColumnSelect\"\n",
        "                date_col=json.loads(db.db.Inbound_Outbound.find_one({\"type\":url,\"user_id\" :user_id},sort=[('Date', -1)])[\"Request\"].replace(\"'\",'\"'))[\"date_col\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Lzd1tWS9Hr"
      },
      "source": [
        "path = \"oss://ai-surge-dev-oss/surge-queryslice/ai_surge_com_mt/support/public_project/Churn_latest_modifed_test_dojo\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "reyJVuoiS9NA",
        "outputId": "d4b761c5-bacf-4ab8-eb62-1930a8027d5a"
      },
      "source": [
        "bucket = path.split(\"/\")[2]\n",
        "bucket"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ai-surge-dev-oss'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-3KLpjfwKoe",
        "outputId": "dd63f35a-1713-4d2e-a7c5-0a3b5390cd73"
      },
      "source": [
        "data = read_tsv(file_path)\n",
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+----------------+-------------+\n",
            "|CategoryID|Level|ParentCategoryID|SubcategoryID|\n",
            "+----------+-----+----------------+-------------+\n",
            "|         0|    1|              10|           45|\n",
            "|         1|    2|               9|           45|\n",
            "|         2|    3|              12|            5|\n",
            "|         3|    3|               9|           25|\n",
            "|         4|    3|               2|           39|\n",
            "|         5|    3|               2|           35|\n",
            "|         6|    3|               4|           53|\n",
            "|         7|    2|               2|           45|\n",
            "|         8|    3|               2|           31|\n",
            "|         9|    3|               9|           18|\n",
            "|        10|    3|               8|           21|\n",
            "|        11|    3|               3|           16|\n",
            "|        12|    2|               6|           45|\n",
            "|        13|    3|              12|           52|\n",
            "|        14|    3|               6|           15|\n",
            "|        15|    3|               2|           49|\n",
            "|        16|    3|               2|           34|\n",
            "|        17|    2|              12|           45|\n",
            "|        18|    3|               2|           30|\n",
            "|        19|    3|               4|           38|\n",
            "+----------+-----+----------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AwY2nFXwqFn"
      },
      "source": [
        "def read_csv(file_path, header=\"true\"):\n",
        "    df = spark.read.format(\"csv\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .option(\"header\", header) \\\n",
        "        .option(\"sep\", \",\") \\\n",
        "        .load(file_path)\n",
        "    return df\n",
        "    \n",
        "def read_tsv(file_path : str , header : str= \"true\"):\n",
        "    df = spark.read.format(\"csv\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"header\", header) \\\n",
        "    .option(\"sep\", \"\\t\") \\\n",
        "    .load(file_path)\n",
        "    return df\n",
        "\n",
        "def read_json(file_path : str , header : str= \"true\"):\n",
        "    df = spark.read.format(\"json\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"header\", header) \\\n",
        "    .option(\"multiLine\",\"true\") \\\n",
        "    .load(file_path)\n",
        "    return df\n",
        "\n",
        "def read_parquet(file_path : str , header : str= \"true\"):\n",
        "    df = spark.read.format(\"parquet\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"header\", header) \\\n",
        "    .load(file_path)\n",
        "    return df\n",
        "\n",
        "def read_excel(file_path : str , header : str= \"true\"):\n",
        "    df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"header\", header) \\\n",
        "    .load(file_path)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Z9ErqBvSwO"
      },
      "source": [
        "file_path = \"/content/Category.tsv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MqWuyovS_1"
      },
      "source": [
        "df = spark.read.options(inferSchema=\"true\", header=\"true\",sep=\"\\t\").csv(spark.read.text(file_path).limit(100000).rdd.flatMap(lambda x: x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmgV_mhnvahM",
        "outputId": "cdf05e68-7197-427d-cfa8-b689eaad0241"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+----------------+-------------+\n",
            "|CategoryID|Level|ParentCategoryID|SubcategoryID|\n",
            "+----------+-----+----------------+-------------+\n",
            "|         0|    1|              10|           45|\n",
            "|         1|    2|               9|           45|\n",
            "|         2|    3|              12|            5|\n",
            "|         3|    3|               9|           25|\n",
            "|         4|    3|               2|           39|\n",
            "|         5|    3|               2|           35|\n",
            "|         6|    3|               4|           53|\n",
            "|         7|    2|               2|           45|\n",
            "|         8|    3|               2|           31|\n",
            "|         9|    3|               9|           18|\n",
            "|        10|    3|               8|           21|\n",
            "|        11|    3|               3|           16|\n",
            "|        12|    2|               6|           45|\n",
            "|        13|    3|              12|           52|\n",
            "|        14|    3|               6|           15|\n",
            "|        15|    3|               2|           49|\n",
            "|        16|    3|               2|           34|\n",
            "|        17|    2|              12|           45|\n",
            "|        18|    3|               2|           30|\n",
            "|        19|    3|               4|           38|\n",
            "+----------+-----+----------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrTelzjN9Ela"
      },
      "source": [
        "import os \n",
        "import pyspark\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import datetime\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import string\n",
        "import more_itertools as mit\n",
        "import spark_utils\n",
        "from spark_utils import write_csv_as_delta,read_delta,read_csv,write_delta,getMode,getMean,getDate,read_delta\n",
        "from pyspark.sql.functions import *\n",
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N88ODZkr3XL"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import DateType , IntegerType , FloatType , StringType\n",
        "from datetime import datetime \n",
        "import datetime\n",
        "from collections import Counter\n",
        "from pyspark.sql.functions import to_date\n",
        "import re\n",
        "from collections import Counter\n",
        "from datetime import datetime "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ISKH73Zv0Y"
      },
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id , desc, row_number\n",
        "from pyspark.sql.window import Window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "w86mHG9gcYO4",
        "outputId": "14011195-0e6a-4c75-b362-c26aba0a4b24"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/Churn_Modelling.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwr6xDwdZdku"
      },
      "source": [
        "write_csv_as_delta(\"/content/duplicatedata.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YObi6RQcZiad"
      },
      "source": [
        "data = read_delta(\"/content/duplicatedata\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbP1tcRE31sH",
        "outputId": "9fbabb54-75d4-448a-dc51-4e2ecbf1a96e"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Id0',\n",
              " 'Id1',\n",
              " 'SepalLengthCm',\n",
              " 'SepalWidthCm',\n",
              " 'PetalLengthCm',\n",
              " 'PetalWidthCm',\n",
              " 'Species']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "88pAMZTe3ibp",
        "outputId": "0bf8d498-c3a8-43b5-ebce-7c4f708a567a"
      },
      "source": [
        "df = data.loc[:,~data.columns.duplicated()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-281ae86cd47d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1305\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1306\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'loc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozh1X5e_eR7a"
      },
      "source": [
        "def read_dataframe_chunks(data , chunk_size = 10000 , start_id = 0):\n",
        "    id_col = data.columns[-1]\n",
        "    max_id = data.select([max(id_col)]).collect()[0][0]\n",
        "    for id_ in range(start_id , max_id , chunk_size):\n",
        "        chunk_data = data.filter((col(id_col) >= id_) & (col(id_col) <= id_ + chunk_size - 1))\n",
        "        yield chunk_data.select(data.columns[:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FY6z1VSZmIj"
      },
      "source": [
        "def add_index(data):\n",
        "    if \"__id__\" not in data.columns:\n",
        "        data = data.withColumn(\"_id_\",monotonically_increasing_id())\n",
        "        data = data.withColumn(\"__id__\", row_number().over(Window.orderBy(col('_id_'))) - 1)\n",
        "    else :\n",
        "        data = data.withColumn(\"_id_\",monotonically_increasing_id())\n",
        "        data = data.withColumn(\"__id__\", row_number().over(Window.orderBy(col('_id_'))) - 1)\n",
        "    data = data.drop(col(\"_id_\"))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDThO5UffSUP"
      },
      "source": [
        "def ValidateVersion_Old(client ,data_path , version , DB , table_name):\n",
        "    client.execute(f'USE {DB}')\n",
        "    data = read_delta_version(data_path , version)\n",
        "    data = add_index(data)\n",
        "    id_col = data.columns[-1]\n",
        "    max_id = data.select([max(id_col)]).collect()[0][0]\n",
        "    version_vals = client.execute(f\"SELECT COUNT(*) FROM {table_name} WHERE __version__ = {version}\")[0][0]\n",
        "    if max_id + 1 == version_vals :\n",
        "        return True , None\n",
        "    else :\n",
        "        return False , version_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmF_XC-eaKa"
      },
      "source": [
        "for chunk_df in read_dataframe_chunks(data , start_id = continue_from):\n",
        "    print(chunk_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IfhYzLZZpHt"
      },
      "source": [
        "data = add_index(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ9ro5yEZ2_K",
        "outputId": "4d926ed7-9572-4163-ab81-2e9bbfbc3679"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+------+\n",
            "|RowNumber|CustomerId|  Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|__id__|\n",
            "+---------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+------+\n",
            "|        1|  15634602| Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|     0|\n",
            "|        2|  15647311|     Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|     1|\n",
            "|        3|  15619304|     Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|     2|\n",
            "|        4|  15701354|     Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|     3|\n",
            "|        5|  15737888| Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|     4|\n",
            "|        6|  15574012|      Chu|        645|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|      149756.71|     1|     5|\n",
            "|        7|  15592531| Bartlett|        822|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|     6|\n",
            "|        8|  15656148|   Obinna|        376|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|     7|\n",
            "|        9|  15792365|       He|        501|   France|  Male| 44|     4|142051.07|            2|        0|             1|        74940.5|     0|     8|\n",
            "|       10|  15592389|       H?|        684|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|     9|\n",
            "|       11|  15767821|   Bearce|        528|   France|  Male| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|    10|\n",
            "|       12|  15737173|  Andrews|        497|    Spain|  Male| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|    11|\n",
            "|       13|  15632264|      Kay|        476|   France|Female| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|    12|\n",
            "|       14|  15691483|     Chin|        549|   France|Female| 25|     5|      0.0|            2|        0|             0|      190857.79|     0|    13|\n",
            "|       15|  15600882|    Scott|        635|    Spain|Female| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|    14|\n",
            "|       16|  15643966|  Goforth|        616|  Germany|  Male| 45|     3|143129.41|            2|        0|             1|       64327.26|     0|    15|\n",
            "|       17|  15737452|    Romeo|        653|  Germany|  Male| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|    16|\n",
            "|       18|  15788218|Henderson|        549|    Spain|Female| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|    17|\n",
            "|       19|  15661507|  Muldrow|        587|    Spain|  Male| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|    18|\n",
            "|       20|  15568982|      Hao|        726|   France|Female| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|    19|\n",
            "+---------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvIBfbeObY9M"
      },
      "source": [
        "df=spark.createDataFrame([(1,'has','kiran',11,0,1),(2,'working1','kiran',10,20,1),(2,'working1','kiran',10,20,1)],['id','products','brands','margin','total_sale','target'])\n",
        " \n",
        "Out[39]: \"df=spark.createDataFrame([(8,'biscuits','kirancisi',11,500,1)],['id','products','brands','margin','total_sale','target'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVWN51BrbZCQ",
        "outputId": "1e38705f-e0a5-41a2-e561-80948036314d"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+------+------+----------+------+\n",
            "| id|products|brands|margin|total_sale|target|\n",
            "+---+--------+------+------+----------+------+\n",
            "|  1|     has| kiran|    11|         0|     1|\n",
            "|  2|working1| kiran|    10|        20|     1|\n",
            "|  2|working1| kiran|    10|        20|     1|\n",
            "+---+--------+------+------+----------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAkaq8HfbZKp",
        "outputId": "e29ad337-c2c9-4ad1-bc80-c716710c7720"
      },
      "source": [
        "from pyspark.sql.window import Window as W\n",
        "from pyspark.sql import functions as F\n",
        " \n",
        "windowSpec = W.partitionBy(\"id\",\"products\",\"brands\").orderBy(\"id\",\"products\",\"brands\")\n",
        "df.withColumn(\"new_column\", F.row_number().over(windowSpec)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+------+------+----------+------+----------+\n",
            "| id|products|brands|margin|total_sale|target|new_column|\n",
            "+---+--------+------+------+----------+------+----------+\n",
            "|  1|     has| kiran|    11|         0|     1|         1|\n",
            "|  2|working1| kiran|    10|        20|     1|         1|\n",
            "|  2|working1| kiran|    10|        20|     1|         2|\n",
            "+---+--------+------+------+----------+------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_JGgAoDbZQT",
        "outputId": "27782eed-329d-48d3-d28d-14ac1c3c2d17"
      },
      "source": [
        " \n",
        "from pyspark.sql import Window\n",
        " \n",
        "window = Window.orderBy(F.col('id'))\n",
        "df_final = df.withColumn('primary_key', F.row_number().over(window))\n",
        "#df_final.show()\n",
        "from pyspark.sql import functions as F\n",
        "df_pri=df_final.select(F.concat_ws('_','id','products','brands','primary_key').alias('primary_'))\n",
        "df_pri.show()\n",
        "df_final.show()\n",
        " \n",
        "#a=append_dfs(df_final,df_pri)\n",
        "d1 = df_pri.select(\"*\").toPandas()\n",
        "d2 = df_final.select(\"*\").toPandas()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|          primary_|\n",
            "+------------------+\n",
            "|     1_has_kiran_1|\n",
            "|2_working1_kiran_2|\n",
            "|2_working1_kiran_3|\n",
            "+------------------+\n",
            "\n",
            "+---+--------+------+------+----------+------+-----------+\n",
            "| id|products|brands|margin|total_sale|target|primary_key|\n",
            "+---+--------+------+------+----------+------+-----------+\n",
            "|  1|     has| kiran|    11|         0|     1|          1|\n",
            "|  2|working1| kiran|    10|        20|     1|          2|\n",
            "|  2|working1| kiran|    10|        20|     1|          3|\n",
            "+---+--------+------+------+----------+------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UPN1OAjb7ZD"
      },
      "source": [
        "d2[\"Primary\"] = d1[\"primary_\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C84HvVvVb7fF"
      },
      "source": [
        "data = d2.drop(\"primary_key\",axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "SKSiD-fMc06C",
        "outputId": "7339e2bc-f487-45d4-825d-3654b3c85ea6"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>products</th>\n",
              "      <th>brands</th>\n",
              "      <th>margin</th>\n",
              "      <th>total_sale</th>\n",
              "      <th>target</th>\n",
              "      <th>Primary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>has</td>\n",
              "      <td>kiran</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1_has_kiran_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>working1</td>\n",
              "      <td>kiran</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>2_working1_kiran_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>working1</td>\n",
              "      <td>kiran</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>2_working1_kiran_3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  products brands  margin  total_sale  target             Primary\n",
              "0   1       has  kiran      11           0       1       1_has_kiran_1\n",
              "1   2  working1  kiran      10          20       1  2_working1_kiran_2\n",
              "2   2  working1  kiran      10          20       1  2_working1_kiran_3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEiWTbeads6R"
      },
      "source": [
        "df=spark.createDataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4aR4YU2c6TY",
        "outputId": "5d283183-5e1c-4621-c0f7-f438a78e8c8f"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+------+------+----------+------+------------------+\n",
            "| id|products|brands|margin|total_sale|target|           Primary|\n",
            "+---+--------+------+------+----------+------+------------------+\n",
            "|  1|     has| kiran|    11|         0|     1|     1_has_kiran_1|\n",
            "|  2|working1| kiran|    10|        20|     1|2_working1_kiran_2|\n",
            "|  2|working1| kiran|    10|        20|     1|2_working1_kiran_3|\n",
            "+---+--------+------+------+----------+------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O67AUKutb71Y"
      },
      "source": [
        "write_csv_as_delta(\"/content/Iris_new_small.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSPEH1b1qORT"
      },
      "source": [
        "df = read_delta(\"/content/Iris_new_small\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRhUzr4YhO15",
        "outputId": "6e0b9f48-107f-4345-c6f5-805c9e2cbc8d"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-------------+------------+-------------+------------+-----------+\n",
            "|  Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+----+-------------+------------+-------------+------------+-----------+\n",
            "|   1|          5.1|        null|          1.4|         0.2|Iris-setosa|\n",
            "|   2|          4.9|           3|          1.4|         0.2|Iris-setosa|\n",
            "|null|          4.7|           #|          1.3|         0.2|Iris-setosa|\n",
            "|   4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|   5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "+----+-------------+------------+-------------+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9-WxbiWhVAv"
      },
      "source": [
        "df = df.filter(df[\"SepalWidthCm\"]. isNotNull()).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NT0fuyohcit",
        "outputId": "d074fd1c-1694-4cd8-a054-eb31638a0184"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NuXjR2osjJB"
      },
      "source": [
        "import pandas as pd\n",
        "new_col = pd.date_range(start='2010-04-24', end='2019-11-27', periods=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKKXlT6nsro0"
      },
      "source": [
        "ddata = df.select(\"*\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xGKxdkbutTeg",
        "outputId": "c2a175df-226f-4566-ea3f-a23bac65f6a8"
      },
      "source": [
        "ddata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>date</th>\n",
              "      <th>Id.1</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4/24/2010</td>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>11/29/2011</td>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7/5/2013</td>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2/9/2015</td>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>9/15/2016</td>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id        date  Id.1  ...  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1   4/24/2010     1  ...            1.4           0.2  Iris-setosa\n",
              "1   2  11/29/2011     2  ...            1.4           0.2  Iris-setosa\n",
              "2   2    7/5/2013     2  ...            1.4           0.2  Iris-setosa\n",
              "3   2    2/9/2015     2  ...            1.4           0.2  Iris-setosa\n",
              "4   3   9/15/2016     3  ...            1.3           0.2  Iris-setosa\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQtx2mtqOYF"
      },
      "source": [
        "datta = ddata.drop('date',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h-A-rt0s_RO"
      },
      "source": [
        "ddata.insert(1,\"Date\",new_col,True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EiIbSPkitre0",
        "outputId": "11c81915-e86f-4c04-82c3-107e09b2131e"
      },
      "source": [
        "ddata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>date</th>\n",
              "      <th>Id.1</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-04-24</td>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-11-29</td>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2013-07-05</td>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>2016-09-15</td>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id        date  Id.1  ...  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1  2010-04-24     1  ...            1.4           0.2  Iris-setosa\n",
              "1   2  2011-11-29     2  ...            1.4           0.2  Iris-setosa\n",
              "2   2  2013-07-05     2  ...            1.4           0.2  Iris-setosa\n",
              "3   2  2015-02-09     2  ...            1.4           0.2  Iris-setosa\n",
              "4   3  2016-09-15     3  ...            1.3           0.2  Iris-setosa\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPl44IUBuL2V"
      },
      "source": [
        "spark_df = spark.createDataFrame(ddata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxnB9xwBuTcs",
        "outputId": "30a95728-381b-44f2-bd3b-8e2b4484593a"
      },
      "source": [
        "spark_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+----+-------------+------------+-------------+------------+-----------+\n",
            "| Id|      date|Id.1|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+----------+----+-------------+------------+-------------+------------+-----------+\n",
            "|  1|2010-04-24|   1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
            "|  2|2011-11-29|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  2|2013-07-05|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  2|2015-02-09|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|2016-09-15|   3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|2018-04-22|   4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|2019-11-27|   5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "+---+----------+----+-------------+------------+-------------+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Tw6LDzup99",
        "outputId": "aad56a16-fe93-4fa1-d5af-bfa43eb99db7"
      },
      "source": [
        "spark_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Id', 'bigint'),\n",
              " ('date', 'date'),\n",
              " ('Id.1', 'bigint'),\n",
              " ('SepalLengthCm', 'double'),\n",
              " ('SepalWidthCm', 'double'),\n",
              " ('PetalLengthCm', 'double'),\n",
              " ('PetalWidthCm', 'double'),\n",
              " ('Species', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofXR8wdrtztq"
      },
      "source": [
        "ddata['date'] = pd.to_datetime(ddata['date']).dt.date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM3NL6ZYrSxB"
      },
      "source": [
        "data = spark_df.withColumn(\"date\" , to_date(spark_df[\"date\"]).alias(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM-ulA0RrhZG"
      },
      "source": [
        "spark_df.withColumn(\"date\",date_format(spark_df[\"date\"],\"dd/MM/yyy\").alias(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVZKMEzZqOgh"
      },
      "source": [
        "from pyspark.sql.functions import date_format,col\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vROn8F6jbZVW",
        "outputId": "1dfcebdf-ec5c-4664-93f6-f0cb83f11fec"
      },
      "source": [
        "spark_df.select(\"date\",date_format(col(\"date\"),\"dd/MM/yyy\")).alias(\"date\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------------------------+\n",
            "|      date|date_format(date, dd/MM/yyy)|\n",
            "+----------+----------------------------+\n",
            "|2010-04-24|                  24/04/2010|\n",
            "|2011-11-29|                  29/11/2011|\n",
            "|2013-07-05|                  05/07/2013|\n",
            "|2015-02-09|                  09/02/2015|\n",
            "|2016-09-15|                  15/09/2016|\n",
            "|2018-04-22|                  22/04/2018|\n",
            "|2019-11-27|                  27/11/2019|\n",
            "+----------+----------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJBnRibqhRAs"
      },
      "source": [
        "def getAll_date_Nulls(data,null_dict,col_name):\n",
        "     null_date = data.select([count(when(col(c).isNull(), c)).alias(c) for (c, c_type) in data.dtypes])\n",
        "     resp = null_date.first()\n",
        "     main_resp = resp.asDict()\n",
        "     null_dict[col_name] = main_resp[col_name]\n",
        "     return null_dict\n",
        "\n",
        "def getAllNulls(data):\n",
        "    null_data = data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for (c, c_type) in data.dtypes if\n",
        "    c_type not in ('boolean', 'timestamp', 'date')])\n",
        "    ret = null_data.first()\n",
        "    return ret.asDict()\n",
        "\n",
        "\n",
        "def RegMatch(item: str, pattern: str) -> bool:\n",
        "    return re.match(pattern, item) is not None\n",
        "\n",
        "\n",
        "def RegMatchApply(items: list, pattern: str) -> bool:\n",
        "    # outputs = Parallel(n_jobs=2, backend=backend)(delayed(RegMatch)(item , pattern) for item in items)\n",
        "    outputs = []\n",
        "    for item in items:\n",
        "        outputs.append(RegMatch(item, pattern))\n",
        "    indexes = np.where(np.array(outputs) == False)\n",
        "    return len(indexes[0]) == 0, indexes\n",
        "\n",
        "\n",
        "def CheckNoise(data, column):\n",
        "    data2 = data.withColumn(\"dummy\", col(column).rlike('[@_!#$%^&*()<>?/\\|}{~:�]'))\n",
        "    if data2.filter(data2[\"dummy\"] == True).count() > 0:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def CheckInt(data, col_name):\n",
        "    vals = list(filter(lambda a: a != \"None\", data))\n",
        "    return RegMatchApply(vals, \"^\\d+$\")[0]\n",
        "\n",
        "\n",
        "def CheckFloat(data, col_name):\n",
        "    vals = list(filter(lambda a: a != \"None\", data))\n",
        "    return RegMatchApply(vals, \"^[-+]?[0-9]*[.][0-9]+$\")[0]\n",
        "\n",
        "\n",
        "def CouldBeDate(data, col_name):\n",
        "    date_data = list(map(lambda x: getDate(x), data))\n",
        "    occurence_counter = Counter(date_data)\n",
        "    date_format = occurence_counter.most_common(1)[0][0]\n",
        "    return date_format != None\n",
        "\n",
        "\n",
        "def makeFormat(data, lis: list):\n",
        "    final_lis = []\n",
        "    for li in lis:\n",
        "        final_lis.append({\"Column\": li, \"ColVals\": example(data, li)})\n",
        "    return final_lis\n",
        "\n",
        "\n",
        "def makeFormat3(lis: list, lis1: list, lis2: list):\n",
        "    output = []\n",
        "    for i, j, k in zip(lis, lis1, lis2):\n",
        "        if k in [\"IntegerType\", \"FloatType\", \"DoubleType\"]:\n",
        "            output.append({\"Column\": i, \"ColName\": j, \"ColType\": k, \"tooltip\": \"Nulls will be replaced with Mean/Mode\"})\n",
        "        else:\n",
        "            output.append({\"Column\": i, \"ColName\": j, \"ColType\": k, \"tooltip\": \"Nulls will be replaced with Mode\"})\n",
        "    return output\n",
        "\n",
        "\n",
        "def makeFormat4(data, lis: list):\n",
        "    output = []\n",
        "    # print(val)\n",
        "    for col in lis:\n",
        "        # print(list(map(lambda x : x[0],data.select(col).limit(5).collect())))\n",
        "        val = list(map(lambda x: str(x[0]), data.select(col).limit(5).collect()))\n",
        "        output.append({\"ColName\": col, \"ColVals\": val})\n",
        "    return output\n",
        "\n",
        "\n",
        "def makeFormat2(lis: list, lis2: list):\n",
        "    final_lis = []\n",
        "    for li, li2 in zip(lis, lis2):\n",
        "        final_lis.append({\"Column\": li, \"ColName\": li2})\n",
        "    return final_lis\n",
        "\n",
        "\n",
        "def example(data, col_name):\n",
        "    a = data.select(col_name, col(col_name).rlike('[@_!#$%^&*()<>?/\\|}{~:]')).collect()[:5]\n",
        "    new_vals = []\n",
        "    for val in a:\n",
        "        if val[1]:\n",
        "            new_vals.append(val[0])\n",
        "    return new_vals\n",
        "\n",
        "\n",
        "def extract_data(id_: str):\n",
        "    collection = db.Ingestion\n",
        "    collection2 = db.JoinsColl\n",
        "    val = collection.find_one({\"_id\": ObjectId(id_)}, {\"sourcePath\": 1})\n",
        "    if val is not None:\n",
        "        return val\n",
        "    else:\n",
        "        val = collection2.find_one({\"_id\": ObjectId(id_)}, {\"sourcePath\": 1})\n",
        "        return val\n",
        "\n",
        "\n",
        "def check_tokenized(vals: list):\n",
        "    bools = list(map(lambda x: len(x) == 64, vals))\n",
        "    if len(bools) == 0:\n",
        "        return True\n",
        "    if bools[0] and bools[-1]:\n",
        "        return bools[1:] == bools[:-1]\n",
        "    return False\n",
        "\n",
        "\n",
        "def getTopValues(data, col_name: str):\n",
        "    val = data.limit(20).select(col_name).collect()[:20]\n",
        "    # print(val)\n",
        "    val = list(map(lambda x: x[0], val))\n",
        "    # print(val)\n",
        "    return val\n",
        "\n",
        "\n",
        "def valdate_match(pattern, items):\n",
        "    out = 0\n",
        "    # print(items)\n",
        "    for item in items:\n",
        "        if item != None:\n",
        "            # print(item)\n",
        "            z = re.match(pattern, item)\n",
        "            if z:\n",
        "                out += 1\n",
        "    # print(out)\n",
        "    if out != 0:\n",
        "        return True\n",
        "\n",
        "\n",
        "def check_mailCols(data, col_name):\n",
        "    data2 = data.withColumn(\"dummy\", col(col_name).rlike('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$'))\n",
        "    count = data2.filter(data2[\"dummy\"] == False).count()\n",
        "    # print(count)\n",
        "    if count > 0:\n",
        "        return True, count\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def Standardization(data, total_count, null_dict):\n",
        "    result = []\n",
        "    mail_list = []\n",
        "    temp = {}\n",
        "    columns = data.columns\n",
        "    for col in columns:\n",
        "        if str(data.schema[col].dataType) == \"StringType\" and null_dict[col] != total_count:\n",
        "            top_5 = getTopValues(data, col)\n",
        "            # print(top_5)\n",
        "            if valdate_match('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$', top_5):\n",
        "                mail_list.append(col)\n",
        "    # print(mail_list)\n",
        "    for cols in mail_list:\n",
        "        bool_, c = check_mailCols(data, cols)\n",
        "        # print(bool_ , c)\n",
        "        if bool_:\n",
        "            temp['ColName'] = cols\n",
        "            temp['Count'] = c\n",
        "            result.append(temp)\n",
        "    return result\n",
        "\n",
        "\n",
        "def predict_sensitivity(data):\n",
        "    data = data.limit(10000)\n",
        "    data = data.select(\"*\").toPandas()\n",
        "    data = data.dropna()\n",
        "    data = data.head(200)\n",
        "    data_len = len(data)\n",
        "    cols = data.columns\n",
        "    cols_to_preds = {}\n",
        "    cols_to_ret = {}\n",
        "    for col in cols:\n",
        "        # if str(data.schema[col_name].dataType) not in [\"DateType\" , \"TimestampType\"]:\n",
        "        vals = data[col].values.astype(\"str\")\n",
        "        if check_tokenized(vals):\n",
        "            continue\n",
        "        cols_to_preds[col] = []\n",
        "        for val in vals:\n",
        "            doc = model(str(col + \" \" + val))\n",
        "            try:\n",
        "                cols_to_preds[col].append(doc.ents[-1].label_)\n",
        "            except:\n",
        "                continue\n",
        "    for col_name, val in cols_to_preds.items():\n",
        "        if len(val) / data_len > 0.5:\n",
        "            m_v = mode(val)[0][0]\n",
        "            cols_to_ret[col_name] = m_v\n",
        "        else:\n",
        "            continue\n",
        "    cols_to_ret_filt = {}\n",
        "    for col, pred in cols_to_ret.items():\n",
        "        if pred == \"S\":\n",
        "            cols_to_ret_filt[col] = pred\n",
        "    return list(cols_to_ret_filt.keys())\n",
        "\n",
        "\n",
        "#from spark_utils import return_filtered, return_text_time, CheckIfExists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DxPlvmatEk0",
        "outputId": "42de2cc1-5ff4-4e17-b410-ed1d3db1f1eb"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "|_c0|RowNumber|     date|CustomerId|National_Insurance_number|     Credit_Card_No|  Surname|CreditScore|Geography|Gender| Age|Tenure|   Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|payment_mode|           mailId|\n",
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "|  0|        1|4/24/2010|  15634602|            EJ 87 23 16 H|6518 2286 9458 0302| Hargrave|        619|   France|Female|  42|     2|      0.0$|            1|        1|             1|     101348.88$|     1| credit_card|       hello#.com|\n",
            "|  1|        2|4/24/2010|  15647311|            OL 43 31 62 W|1895 4190 0493 2177|     Hill|        608|    Spain|Female|  41|     1| 83807.86$|            1|        0|             1|     112542.58$|     0|  debit_card|       hello#.com|\n",
            "|  2|        3|4/24/2010|  15619304|            SP 19 16 08 Z|7391 2068 7721 4726|     Onio|        502|   France|Female|  42|     8| 159660.8$|            3|        1|             0|     113931.57$|     1| credit_card|       hello#.com|\n",
            "|  3|        4|4/25/2010|  15701354|            BL 75 04 39 Q|8863 3167 4447 6130|     Boni|        699|   France|Female|null|     1|      0.0$|            2|        0|             0|      93826.63$|     0|  debit_card|abc.dei@qngf.noaj|\n",
            "|  4|        5|4/25/2010|  15737888|            VJ 49 13 25 F|6042 7133 1005 8123| Mitchell|        850|    Spain|Female|  39|  null|125510.82$|    Venkatesh|        1|             1|       79084.1$|     0|  debit_card|       hello#.com|\n",
            "|  5|        6|4/25/2010|  15574012|            LI 01 30 98 Q|4425 9932 7939 1867|      Chu|       Teja|    Spain|  Male|null|     8|113755.78$|            2|        1|             0|     149756.71$|     1|  debit_card|abc.dek@qngt.oulx|\n",
            "|  6|        7|4/26/2010|  15592531|            EQ 03 89 69 M|7794 1734 3408 3103| Bartlett|        822|   France|  Male|  50|  null|      0.0$|            2|        1|             1|       10062.8$|     0| credit_card|abc.del@qngr.npiz|\n",
            "|  7|        8|4/26/2010|  15656148|            RA 20 76 44 N|7862 7332 2009 7097|   Obinna|        376|  Germany|Female|  29|     4|115046.74$|            4|        1|             0|     119346.88$|     1| credit_card|       hello#.com|\n",
            "|  8|        9|4/26/2010|  15792365|            XX 88 51 05 C|0985 3441 5947 6664|       He|        501|   France|  Male|  44|     4|142051.07$|            2|        0|             1|       74940.5$|     0|  debit_card|       hello#.com|\n",
            "|  9|       10|4/27/2010|  15592389|            HF 10 25 99 E|7783 3046 1162 8870|       H?|        684|   France|  Male|  27|     2|134603.88$|            1|        1|             1|      71725.73$|     0|  debit_card|       hello#.com|\n",
            "| 10|       11|4/27/2010|  15767821|            HR 79 79 37 T|4643 4252 8979 4317|   Bearce|        528|   France|  Male|null|  null|102016.72$|            2|        0|             0|      80181.12$|     0| credit_card| abc.dep@qngl.lym|\n",
            "| 11|       12|4/27/2010|  15737173|            UL 84 05 44 Y|2148 3870 3474 5852|  Andrews|        497|    Spain|  Male|  24|  null|      0.0$|            2|        1|             0|      76390.01$|     0| credit_card|       hello#.com|\n",
            "| 12|       13|4/28/2010|  15632264|            NY 23 39 00 W|5111 6254 4955 3485|      Kay|        476|   France|Female|  34|  null|      0.0$|            2|        1|             0|      26260.98$|     0| credit_card|       hello#.com|\n",
            "| 13|       14|4/28/2010|  15691483|            UP 19 02 03 O|1813 2711 3855 5658|     Chin|        549|   France|Female|  34|     5|      0.0$|            2|        0|             0|     190857.79$|     0| credit_card|       hello#.com|\n",
            "| 14|       15|4/28/2010|  15600882|            BC 81 86 38 Z|1855 9335 9147 1280|    Scott|        635|    Spain|Female|  34|     7|      0.0$|            2|        1|             1|      65951.65$|     0|  debit_card|       hello#.com|\n",
            "| 15|       16|4/29/2010|  15643966|            OP 12 33 50 G|0486 0327 5429 1176|  Goforth|        616|  Germany|  Male|null|     3|143129.41$|            2|        0|             1|      64327.26$|     0|  debit_card| abc.deu@qngi.rsk|\n",
            "| 16|       17|4/29/2010|  15737452|            WM 60 91 78 K|8079 7648 7959 1858|    Romeo|        653|  Germany|  Male|  58|     1|132602.88$|            1|        1|             0|       5097.67$|     1| credit_card|abc.dev@qngm.gopm|\n",
            "| 17|       18|4/29/2010|  15788218|            MI 29 05 40 J|2375 4679 8792 5009|Henderson|        549|    Spain|Female|  24|     9|      0.0$|            2|        1|             1|      14406.41$|     0|  debit_card|       hello#.com|\n",
            "| 18|       19|4/30/2010|  15661507|            JM 62 01 40 X|3144 4069 0205 9336|  Muldrow|        587|    Spain|  Male|  45|     6|      0.0$|            1|        0|             0|     158684.81$|     0| credit_card|       hello#.com|\n",
            "| 19|       20|4/30/2010|  15568982|            IR 51 70 14 X|5284 8662 0654 4079|  Hao%^&&|        726|   France|Female|  24|     6|      0.0$|            2|        1|             1|      54724.03$|     0| credit_card|       hello#.com|\n",
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL-iITCttKnA"
      },
      "source": [
        "spark_df = df.orderBy(rand()).limit(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKAM3h3et_Yt",
        "outputId": "ee754164-180f-421d-a858-5ef9f4416ba7"
      },
      "source": [
        "spark_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+---------+----------+----------+-------------------------+-------------------+-------------+-----------+---------+------+---+------+----------+-------------+---------+--------------+---------------+------+------------+----------------+\n",
            "| _c0|RowNumber|      date|CustomerId|National_Insurance_number|     Credit_Card_No|      Surname|CreditScore|Geography|Gender|Age|Tenure|   Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|payment_mode|          mailId|\n",
            "+----+---------+----------+----------+-------------------------+-------------------+-------------+-----------+---------+------+---+------+----------+-------------+---------+--------------+---------------+------+------------+----------------+\n",
            "|8526|     8527| 6/28/2018|  15768945|            CU 81 76 20 D|2526 8756 9010 8618|     Chibueze|        627|   France|  Male| 27|     1|  62092.9$|            1|        1|             1|     105887.04$|     0| credit_card|      hello#.com|\n",
            "|9005|     9006|12/13/2018|  15802823|            XQ 04 55 65 D|9943 4080 7157 3802|      Maclean|        745|    Spain|Female| 38|     7|      0.0$|            2|        1|             1|     194230.82$|     0|  debit_card|      hello#.com|\n",
            "|7481|     7482| 6/27/2017|  15778589|            UU 95 81 20 R|0850 6463 8968 7404|      Collier|        626|   France|  Male| 34|     7| 113014.7$|            2|        1|             1|      56646.28$|     0| credit_card|      hello#.com|\n",
            "|1253|     1254|  7/7/2011|  15699523|            DR 34 33 53 N|6108 2687 7948 1632|          Chu|        499|  Germany|Female| 55|     4|126817.65$|            2|        1|             0|     123269.71$|     0|  debit_card|abc.kos@qfly.ubk|\n",
            "|7578|     7579| 7/31/2017|  15656417|            BY 81 43 87 K|0698 8118 4395 6663|        Marsh|        582|   France|Female| 39|     1|132077.48$|            2|        1|             0|     192255.15$|     0|  debit_card|      hello#.com|\n",
            "|1672|     1673|11/30/2011|  15713854|            JM 21 14 01 Z|0163 2712 8599 2570|    Cremonesi|        513|   France|Female| 37|     6|      0.0$|            2|        1|             0|     110142.34$|     0| credit_card|      hello#.com|\n",
            "| 665|      666|12/13/2010|  15645772|            YE 78 20 31 U|2123 1698 5097 0559|     Onwumelu|        661|   France|  Male| 33|     9|      0.0$|            2|        1|             1|      84174.81$|     0| credit_card|      hello#.com|\n",
            "|6408|     6409| 6/16/2016|  15738497|            CF 16 98 85 Q|3203 4254 7735 5432|Chukwujamuike|        729|    Spain|  Male| 44|     4|107726.93$|            2|        1|             0|     153064.87$|     0| credit_card|      hello#.com|\n",
            "|7561|     7562| 7/25/2017|  15700046|            AA 38 77 31 E|7997 3234 7142 6940|         Yuan|        635|   France|  Male| 41|     4|103544.88$|            2|        1|             0|     193746.55$|     0| credit_card|      hello#.com|\n",
            "|2533|     2534| 9/27/2012|  15631838|            KK 08 38 27 Z|5349 0836 4796 4834|      Findlay|        606|   France|  Male| 61|     5|108166.09$|            2|        0|             1|       8643.21$|     0|  debit_card|abcdilt@ngmx.apj|\n",
            "+----+---------+----------+----------+-------------------------+-------------------+-------------+-----------+---------+------+---+------+----------+-------------+---------+--------------+---------------+------+------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AChU1Sb7rvzc"
      },
      "source": [
        "def RepresentsInt(s):\n",
        "    #return re.match(r\"[0-9]\", s) is not None\n",
        "    return len(re.findall(r'[0-9]+', s)) > 0\n",
        "\n",
        "def ConvertStringToNumeric(dataFrame , col_name , Int = True):\n",
        "    vals = dataFrame.select(col_name).collect()[0:100]\n",
        "    vals = list(map(lambda x : x[0] , vals))\n",
        "    vals = [val for val in vals if val is not None]\n",
        "    if len(vals) == 0:\n",
        "        return  None , {\"Status\" : 400 , \"Message\" : \"Too many Nulls , Handle them first !\"}\n",
        "    #vals = list(map(lambda x : RepresentsInt(x) , vals))\n",
        "    #vals = Counter(vals)\n",
        "    #if vals[True] < int(0.8*len(vals)) or vals[False] > int(0.8*len(vals)):\n",
        "    #return None , {\"Status\" : 400 , \"Message\" : \"String Objects contain less than 80% of Int Vals\"}\n",
        "    if Int :\n",
        "        #dataFrame = dataFrame.withColumn(col_name , regexp_extract(col(col_name) , \"\\\\d+\" , 0))\n",
        "        try :\n",
        "            dataFrame = dataFrame.withColumn(col_name , dataFrame[col_name].cast(IntegerType()))\n",
        "            write_delta(dataFrame,\"/content/Noisy_churn\")\n",
        "            return dataFrame , {\"Status\" : 200 , \"Message\" : \"String Objects Converted to Int\"}\n",
        "        except :\n",
        "            return None , {\"Status\" : 400 , \"Message\" : \"Column Cannot be converted into Int\"}\n",
        "    else :\n",
        "        #dataFrame = dataFrame.withColumn(col_name , regexp_extract(col(col_name) , \"\\\\d+(.[0-9]*)?\" , 0))\n",
        "        try :\n",
        "            dataFrame = dataFrame.withColumn(col_name , dataFrame[col_name].cast(FloatType()))\n",
        "            return dataFrame , {\"Status\" : 200 , \"Message\" : \"String Objects Converted to Float\"}\n",
        "        except :\n",
        "            return None , {\"Status\" : 400 , \"Message\" : \"Column Cannot be converted into Int\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m0jBcW8uaPl"
      },
      "source": [
        "def FindAndReplace(data,col_name,find_val,replace_val):\n",
        "    #file_path = kwargs['params'][\"data_path\"]\n",
        "    #col_name = kwargs['params'][\"col_name\"]\n",
        "    #find_val = kwargs['params'][\"find_val\"]\n",
        "    #replace_val = kwargs['params'][\"replace_val\"]\n",
        "    #try : \n",
        "        #data = read_delta(file_path)\n",
        "    if col_name not in data.columns :\n",
        "        return {\"Status\" : 201 , \"Message\" : \"Couldn't find column name in Data\"}\n",
        "    if str(data.schema[col_name].dataType) in [\"IntegerType\" , \"LongType\"]:\n",
        "        find_val = int(find_val)\n",
        "        replace_val = int(replace_val)\n",
        "        data = data.withColumn(col_name, when(data[col_name] == find_val, replace_val).otherwise(data[col_name]))\n",
        "\n",
        "    elif str(data.schema[col_name].dataType) in  [\"FloatType\" , \"DoubleType\"]:\n",
        "        find_val = float(find_val)\n",
        "        replace_val = float(replace_val)\n",
        "        data = data.withColumn(col_name, when(data[col_name] == find_val, replace_val).otherwise(data[col_name]))\n",
        "\n",
        "    elif str(data.schema[col_name].dataType) in [\"StringType\" , \"DateType\"]:\n",
        "        data = data.withColumn(col_name, when(data[col_name] == find_val, replace_val).otherwise(data[col_name]))\n",
        "        data.show()\n",
        "    write_delta(data,\"/content/Noisy_churn\")\n",
        "    return {\"Status\" : 200 , \"Message\" : \"Replacement Successful\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K19Pv_isu--D",
        "outputId": "d8ae7bb9-c4cf-46a7-9493-b2fd833ca11b"
      },
      "source": [
        "FindAndReplace(spark_df,\"CreditScore\",\"635\",\"Teju\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+---------+----------+----------+-------------------------+-------------------+-------------+-----------+---------+------+---+------+----------+-------------+---------+--------------+---------------+------+------------+----------------+\n",
            "| _c0|RowNumber|      date|CustomerId|National_Insurance_number|     Credit_Card_No|      Surname|CreditScore|Geography|Gender|Age|Tenure|   Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|payment_mode|          mailId|\n",
            "+----+---------+----------+----------+-------------------------+-------------------+-------------+-----------+---------+------+---+------+----------+-------------+---------+--------------+---------------+------+------------+----------------+\n",
            "|1253|     1254|  7/7/2011|  15699523|            DR 34 33 53 N|6108 2687 7948 1632|          Chu|        499|  Germany|Female| 55|     4|126817.65$|            2|        1|             0|     123269.71$|     0|  debit_card|abc.kos@qfly.ubk|\n",
            "|9005|     9006|12/13/2018|  15802823|            XQ 04 55 65 D|9943 4080 7157 3802|      Maclean|        745|    Spain|Female| 38|     7|      0.0$|            2|        1|             1|     194230.82$|     0|  debit_card|      hello#.com|\n",
            "|1672|     1673|11/30/2011|  15713854|            JM 21 14 01 Z|0163 2712 8599 2570|    Cremonesi|        513|   France|Female| 37|     6|      0.0$|            2|        1|             0|     110142.34$|     0| credit_card|      hello#.com|\n",
            "|2533|     2534| 9/27/2012|  15631838|            KK 08 38 27 Z|5349 0836 4796 4834|      Findlay|        606|   France|  Male| 61|     5|108166.09$|            2|        0|             1|       8643.21$|     0|  debit_card|abcdilt@ngmx.apj|\n",
            "|6408|     6409| 6/16/2016|  15738497|            CF 16 98 85 Q|3203 4254 7735 5432|Chukwujamuike|        729|    Spain|  Male| 44|     4|107726.93$|            2|        1|             0|     153064.87$|     0| credit_card|      hello#.com|\n",
            "| 665|      666|12/13/2010|  15645772|            YE 78 20 31 U|2123 1698 5097 0559|     Onwumelu|        661|   France|  Male| 33|     9|      0.0$|            2|        1|             1|      84174.81$|     0| credit_card|      hello#.com|\n",
            "|7481|     7482| 6/27/2017|  15778589|            UU 95 81 20 R|0850 6463 8968 7404|      Collier|        626|   France|  Male| 34|     7| 113014.7$|            2|        1|             1|      56646.28$|     0| credit_card|      hello#.com|\n",
            "|7561|     7562| 7/25/2017|  15700046|            AA 38 77 31 E|7997 3234 7142 6940|         Yuan|       Teju|   France|  Male| 41|     4|103544.88$|            2|        1|             0|     193746.55$|     0| credit_card|      hello#.com|\n",
            "|7578|     7579| 7/31/2017|  15656417|            BY 81 43 87 K|0698 8118 4395 6663|        Marsh|        582|   France|Female| 39|     1|132077.48$|            2|        1|             0|     192255.15$|     0|  debit_card|      hello#.com|\n",
            "|8526|     8527| 6/28/2018|  15768945|            CU 81 76 20 D|2526 8756 9010 8618|     Chibueze|       mani|   France|  Male| 27|     1|  62092.9$|            1|        1|             1|     105887.04$|     0| credit_card|      hello#.com|\n",
            "+----+---------+----------+----------+-------------------------+-------------------+-------------+-----------+---------+------+---+------+----------+-------------+---------+--------------+---------------+------+------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Message': 'Replacement Successful', 'Status': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNKPwHkMMgkE"
      },
      "source": [
        "write_csv_as_delta(\"/content/Iris_new.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_gI55LsEw0"
      },
      "source": [
        "df = read_delta(\"/content/iris_new\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFihh8h23Sum"
      },
      "source": [
        "current_date = datetime.today().date()\n",
        "data = df.withColumn('load_date', lit(current_date))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmZmuPeqsPKO",
        "outputId": "73fc510d-816e-42e7-ecf6-5d9bd48d0d20"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Id', 'int'),\n",
              " ('date', 'timestamp'),\n",
              " ('Id.1', 'int'),\n",
              " ('SepalLengthCm', 'double'),\n",
              " ('SepalWidthCm', 'double'),\n",
              " ('PetalLengthCm', 'double'),\n",
              " ('PetalWidthCm', 'double'),\n",
              " ('Species', 'string'),\n",
              " ('load_date', 'date')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ag1_Sqd0oTB"
      },
      "source": [
        "#data = df.withColumn(\"date\" , to_date(df[\"date\"]).alias(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssXIEJ1701QK",
        "outputId": "aabe64b4-eb95-4a98-c7f4-d6eecefea713"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "| Id|               date|Id.1|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species| load_date|\n",
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "|  1|2010-04-24 00:00:00|   1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2011-11-29 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2013-07-05 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2015-02-09 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  3|2016-09-15 00:00:00|   3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|2021-04-17|\n",
            "|  4|2018-04-22 00:00:00|   4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|2021-04-17|\n",
            "|  5|2019-11-27 00:00:00|   5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  6|               null|   6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|2021-04-17|\n",
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCNrYg7o09XP"
      },
      "source": [
        "pandas_data_frame = data.select(\"*\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ItAaLg1Eku"
      },
      "source": [
        "pandas_data_frame['load_date'] = pandas_data_frame['load_date'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e677Qyn11EsI"
      },
      "source": [
        "df = spark.createDataFrame(pandas_data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-fqp6z18vZS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93wsF8Iy1Ew0",
        "outputId": "144a27b9-6889-4389-dfa3-8eb56b6eb7bf"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "| Id|               date|Id.1|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species| load_date|\n",
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "|  1|2010-04-24 00:00:00|   1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2011-11-29 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2013-07-05 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2015-02-09 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  3|2016-09-15 00:00:00|   3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|2021-04-17|\n",
            "|  4|2018-04-22 00:00:00|   4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|2021-04-17|\n",
            "|  5|2019-11-27 00:00:00|   5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  6|               null|   6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|2021-04-17|\n",
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldv-3MG42NMf"
      },
      "source": [
        "import datetime\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBe0VDP44IlU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPERK6Ll3qJx"
      },
      "source": [
        "write_delta(data,\"/content/iris_date\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5YA4Rt-3xFJ",
        "outputId": "5ef0f0fd-3939-45ed-8ebf-3f35bc7a6c20"
      },
      "source": [
        "dt = read_delta('/content/iris_date')\n",
        "dt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "| Id|               date|Id.1|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species| load_date|\n",
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "|  1|2010-04-24 00:00:00|   1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2011-11-29 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2013-07-05 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  2|2015-02-09 00:00:00|   2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  3|2016-09-15 00:00:00|   3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|2021-04-17|\n",
            "|  4|2018-04-22 00:00:00|   4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|2021-04-17|\n",
            "|  5|2019-11-27 00:00:00|   5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|2021-04-17|\n",
            "|  6|               null|   6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|2021-04-17|\n",
            "+---+-------------------+----+-------------+------------+-------------+------------+-----------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EQ1LoB12Tfu",
        "outputId": "3362a22c-5cf8-438a-c489-b254caf18e30"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Id', 'bigint'),\n",
              " ('date', 'date'),\n",
              " ('Id.1', 'bigint'),\n",
              " ('SepalLengthCm', 'double'),\n",
              " ('SepalWidthCm', 'double'),\n",
              " ('PetalLengthCm', 'double'),\n",
              " ('PetalWidthCm', 'double'),\n",
              " ('Species', 'string'),\n",
              " ('load_date', 'date')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfuLYvjcsAiS",
        "outputId": "6de4b9e9-62df-4472-a1ee-69f7af138e67"
      },
      "source": [
        "ConvertStringToNumeric(df,'CreditScore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DataFrame[_c0: int, RowNumber: int, date: string, CustomerId: int, National_Insurance_number: string, Credit_Card_No: string, Surname: string, CreditScore: int, Geography: string, Gender: string, Age: int, Tenure: int, Balance: string, NumOfProducts: string, HasCrCard: int, IsActiveMember: int, EstimatedSalary: string, Exited: int, payment_mode: string, mailId: string],\n",
              " {'Message': 'String Objects Converted to Int', 'Status': 200})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_TB7LV91Dj_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ueR-LrISr0"
      },
      "source": [
        "write_csv_as_delta(\"/content/Sales_Performance.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iadl9h7sIVhW"
      },
      "source": [
        "write_csv_as_delta(\"/content/PoS.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vut6WYVeIHU"
      },
      "source": [
        "date_type = read_delta(\"/content/tet_date_type\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqsey6WLOUGQ"
      },
      "source": [
        "write_csv_as_delta(\"/content/Noisy_churn.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx5dZFN9OX3R"
      },
      "source": [
        "noise = read_delta(\"/content/Noisy_churn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxU9ajOQPM8a",
        "outputId": "f07701d0-3382-4302-e909-90d22975a517"
      },
      "source": [
        "noise.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "|_c0|RowNumber|     date|CustomerId|National_Insurance_number|     Credit_Card_No|  Surname|CreditScore|Geography|Gender| Age|Tenure|   Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|payment_mode|           mailId|\n",
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "|  0|        1|4/24/2010|  15634602|            EJ 87 23 16 H|6518 2286 9458 0302| Hargrave|        619|   France|Female|  42|     2|      0.0$|            1|        1|             1|     101348.88$|     1| credit_card|       hello#.com|\n",
            "|  1|        2|4/24/2010|  15647311|            OL 43 31 62 W|1895 4190 0493 2177|     Hill|        608|    Spain|Female|  41|     1| 83807.86$|            1|        0|             1|     112542.58$|     0|  debit_card|       hello#.com|\n",
            "|  2|        3|4/24/2010|  15619304|            SP 19 16 08 Z|7391 2068 7721 4726|     Onio|        502|   France|Female|  42|     8| 159660.8$|            3|        1|             0|     113931.57$|     1| credit_card|       hello#.com|\n",
            "|  3|        4|4/25/2010|  15701354|            BL 75 04 39 Q|8863 3167 4447 6130|     Boni|        699|   France|Female|null|     1|      0.0$|            2|        0|             0|      93826.63$|     0|  debit_card|abc.dei@qngf.noaj|\n",
            "|  4|        5|4/25/2010|  15737888|            VJ 49 13 25 F|6042 7133 1005 8123| Mitchell|        850|    Spain|Female|  39|  null|125510.82$|    Venkatesh|        1|             1|       79084.1$|     0|  debit_card|       hello#.com|\n",
            "|  5|        6|4/25/2010|  15574012|            LI 01 30 98 Q|4425 9932 7939 1867|      Chu|       Teja|    Spain|  Male|null|     8|113755.78$|            2|        1|             0|     149756.71$|     1|  debit_card|abc.dek@qngt.oulx|\n",
            "|  6|        7|4/26/2010|  15592531|            EQ 03 89 69 M|7794 1734 3408 3103| Bartlett|        822|   France|  Male|  50|  null|      0.0$|            2|        1|             1|       10062.8$|     0| credit_card|abc.del@qngr.npiz|\n",
            "|  7|        8|4/26/2010|  15656148|            RA 20 76 44 N|7862 7332 2009 7097|   Obinna|        376|  Germany|Female|  29|     4|115046.74$|            4|        1|             0|     119346.88$|     1| credit_card|       hello#.com|\n",
            "|  8|        9|4/26/2010|  15792365|            XX 88 51 05 C|0985 3441 5947 6664|       He|        501|   France|  Male|  44|     4|142051.07$|            2|        0|             1|       74940.5$|     0|  debit_card|       hello#.com|\n",
            "|  9|       10|4/27/2010|  15592389|            HF 10 25 99 E|7783 3046 1162 8870|       H?|        684|   France|  Male|  27|     2|134603.88$|            1|        1|             1|      71725.73$|     0|  debit_card|       hello#.com|\n",
            "| 10|       11|4/27/2010|  15767821|            HR 79 79 37 T|4643 4252 8979 4317|   Bearce|        528|   France|  Male|null|  null|102016.72$|            2|        0|             0|      80181.12$|     0| credit_card| abc.dep@qngl.lym|\n",
            "| 11|       12|4/27/2010|  15737173|            UL 84 05 44 Y|2148 3870 3474 5852|  Andrews|        497|    Spain|  Male|  24|  null|      0.0$|            2|        1|             0|      76390.01$|     0| credit_card|       hello#.com|\n",
            "| 12|       13|4/28/2010|  15632264|            NY 23 39 00 W|5111 6254 4955 3485|      Kay|        476|   France|Female|  34|  null|      0.0$|            2|        1|             0|      26260.98$|     0| credit_card|       hello#.com|\n",
            "| 13|       14|4/28/2010|  15691483|            UP 19 02 03 O|1813 2711 3855 5658|     Chin|        549|   France|Female|  34|     5|      0.0$|            2|        0|             0|     190857.79$|     0| credit_card|       hello#.com|\n",
            "| 14|       15|4/28/2010|  15600882|            BC 81 86 38 Z|1855 9335 9147 1280|    Scott|        635|    Spain|Female|  34|     7|      0.0$|            2|        1|             1|      65951.65$|     0|  debit_card|       hello#.com|\n",
            "| 15|       16|4/29/2010|  15643966|            OP 12 33 50 G|0486 0327 5429 1176|  Goforth|        616|  Germany|  Male|null|     3|143129.41$|            2|        0|             1|      64327.26$|     0|  debit_card| abc.deu@qngi.rsk|\n",
            "| 16|       17|4/29/2010|  15737452|            WM 60 91 78 K|8079 7648 7959 1858|    Romeo|        653|  Germany|  Male|  58|     1|132602.88$|            1|        1|             0|       5097.67$|     1| credit_card|abc.dev@qngm.gopm|\n",
            "| 17|       18|4/29/2010|  15788218|            MI 29 05 40 J|2375 4679 8792 5009|Henderson|        549|    Spain|Female|  24|     9|      0.0$|            2|        1|             1|      14406.41$|     0|  debit_card|       hello#.com|\n",
            "| 18|       19|4/30/2010|  15661507|            JM 62 01 40 X|3144 4069 0205 9336|  Muldrow|        587|    Spain|  Male|  45|     6|      0.0$|            1|        0|             0|     158684.81$|     0| credit_card|       hello#.com|\n",
            "| 19|       20|4/30/2010|  15568982|            IR 51 70 14 X|5284 8662 0654 4079|  Hao%^&&|        726|   France|Female|  24|     6|      0.0$|            2|        1|             1|      54724.03$|     0| credit_card|       hello#.com|\n",
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsas13YOPduO",
        "outputId": "64ce7b07-8da4-4847-830a-91bf73e6805d"
      },
      "source": [
        "noise.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_c0', 'int'),\n",
              " ('RowNumber', 'int'),\n",
              " ('date', 'string'),\n",
              " ('CustomerId', 'int'),\n",
              " ('National_Insurance_number', 'string'),\n",
              " ('Credit_Card_No', 'string'),\n",
              " ('Surname', 'string'),\n",
              " ('CreditScore', 'string'),\n",
              " ('Geography', 'string'),\n",
              " ('Gender', 'string'),\n",
              " ('Age', 'int'),\n",
              " ('Tenure', 'int'),\n",
              " ('Balance', 'string'),\n",
              " ('NumOfProducts', 'string'),\n",
              " ('HasCrCard', 'int'),\n",
              " ('IsActiveMember', 'int'),\n",
              " ('EstimatedSalary', 'string'),\n",
              " ('Exited', 'int'),\n",
              " ('payment_mode', 'string'),\n",
              " ('mailId', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-dJH-7WeNPL"
      },
      "source": [
        "data = noise.withColumn(\"Age\" , noise[\"Age\"].cast(IntegerType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHh2_p3IQBWq",
        "outputId": "28d2e1e7-40f5-4de4-93c5-d88425cb01c4"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "|_c0|RowNumber|     date|CustomerId|National_Insurance_number|     Credit_Card_No|  Surname|CreditScore|Geography|Gender| Age|Tenure|   Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|payment_mode|           mailId|\n",
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "|  0|        1|4/24/2010|  15634602|            EJ 87 23 16 H|6518 2286 9458 0302| Hargrave|        619|   France|Female|  42|     2|      0.0$|            1|        1|             1|     101348.88$|     1| credit_card|       hello#.com|\n",
            "|  1|        2|4/24/2010|  15647311|            OL 43 31 62 W|1895 4190 0493 2177|     Hill|        608|    Spain|Female|  41|     1| 83807.86$|            1|        0|             1|     112542.58$|     0|  debit_card|       hello#.com|\n",
            "|  2|        3|4/24/2010|  15619304|            SP 19 16 08 Z|7391 2068 7721 4726|     Onio|        502|   France|Female|  42|     8| 159660.8$|            3|        1|             0|     113931.57$|     1| credit_card|       hello#.com|\n",
            "|  3|        4|4/25/2010|  15701354|            BL 75 04 39 Q|8863 3167 4447 6130|     Boni|        699|   France|Female|null|     1|      0.0$|            2|        0|             0|      93826.63$|     0|  debit_card|abc.dei@qngf.noaj|\n",
            "|  4|        5|4/25/2010|  15737888|            VJ 49 13 25 F|6042 7133 1005 8123| Mitchell|        850|    Spain|Female|  39|  null|125510.82$|    Venkatesh|        1|             1|       79084.1$|     0|  debit_card|       hello#.com|\n",
            "|  5|        6|4/25/2010|  15574012|            LI 01 30 98 Q|4425 9932 7939 1867|      Chu|       Teja|    Spain|  Male|null|     8|113755.78$|            2|        1|             0|     149756.71$|     1|  debit_card|abc.dek@qngt.oulx|\n",
            "|  6|        7|4/26/2010|  15592531|            EQ 03 89 69 M|7794 1734 3408 3103| Bartlett|        822|   France|  Male|  50|  null|      0.0$|            2|        1|             1|       10062.8$|     0| credit_card|abc.del@qngr.npiz|\n",
            "|  7|        8|4/26/2010|  15656148|            RA 20 76 44 N|7862 7332 2009 7097|   Obinna|        376|  Germany|Female|  29|     4|115046.74$|            4|        1|             0|     119346.88$|     1| credit_card|       hello#.com|\n",
            "|  8|        9|4/26/2010|  15792365|            XX 88 51 05 C|0985 3441 5947 6664|       He|        501|   France|  Male|  44|     4|142051.07$|            2|        0|             1|       74940.5$|     0|  debit_card|       hello#.com|\n",
            "|  9|       10|4/27/2010|  15592389|            HF 10 25 99 E|7783 3046 1162 8870|       H?|        684|   France|  Male|  27|     2|134603.88$|            1|        1|             1|      71725.73$|     0|  debit_card|       hello#.com|\n",
            "| 10|       11|4/27/2010|  15767821|            HR 79 79 37 T|4643 4252 8979 4317|   Bearce|        528|   France|  Male|null|  null|102016.72$|            2|        0|             0|      80181.12$|     0| credit_card| abc.dep@qngl.lym|\n",
            "| 11|       12|4/27/2010|  15737173|            UL 84 05 44 Y|2148 3870 3474 5852|  Andrews|        497|    Spain|  Male|  24|  null|      0.0$|            2|        1|             0|      76390.01$|     0| credit_card|       hello#.com|\n",
            "| 12|       13|4/28/2010|  15632264|            NY 23 39 00 W|5111 6254 4955 3485|      Kay|        476|   France|Female|  34|  null|      0.0$|            2|        1|             0|      26260.98$|     0| credit_card|       hello#.com|\n",
            "| 13|       14|4/28/2010|  15691483|            UP 19 02 03 O|1813 2711 3855 5658|     Chin|        549|   France|Female|  34|     5|      0.0$|            2|        0|             0|     190857.79$|     0| credit_card|       hello#.com|\n",
            "| 14|       15|4/28/2010|  15600882|            BC 81 86 38 Z|1855 9335 9147 1280|    Scott|        635|    Spain|Female|  34|     7|      0.0$|            2|        1|             1|      65951.65$|     0|  debit_card|       hello#.com|\n",
            "| 15|       16|4/29/2010|  15643966|            OP 12 33 50 G|0486 0327 5429 1176|  Goforth|        616|  Germany|  Male|null|     3|143129.41$|            2|        0|             1|      64327.26$|     0|  debit_card| abc.deu@qngi.rsk|\n",
            "| 16|       17|4/29/2010|  15737452|            WM 60 91 78 K|8079 7648 7959 1858|    Romeo|        653|  Germany|  Male|  58|     1|132602.88$|            1|        1|             0|       5097.67$|     1| credit_card|abc.dev@qngm.gopm|\n",
            "| 17|       18|4/29/2010|  15788218|            MI 29 05 40 J|2375 4679 8792 5009|Henderson|        549|    Spain|Female|  24|     9|      0.0$|            2|        1|             1|      14406.41$|     0|  debit_card|       hello#.com|\n",
            "| 18|       19|4/30/2010|  15661507|            JM 62 01 40 X|3144 4069 0205 9336|  Muldrow|        587|    Spain|  Male|  45|     6|      0.0$|            1|        0|             0|     158684.81$|     0| credit_card|       hello#.com|\n",
            "| 19|       20|4/30/2010|  15568982|            IR 51 70 14 X|5284 8662 0654 4079|  Hao%^&&|        726|   France|Female|  24|     6|      0.0$|            2|        1|             1|      54724.03$|     0| credit_card|       hello#.com|\n",
            "+---+---------+---------+----------+-------------------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb6BArj9IRwa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SRYD-oXMlLL",
        "outputId": "89b9c8f9-8e9f-490c-8d5b-23c6cdde3e44"
      },
      "source": [
        "df = read_delta(\"/content/tet_date_type\")\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-------------------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|RowNumber|               date|CustomerId|  Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+---------+-------------------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|        1|2010-04-24 00:00:00|  15634602| Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
            "|        2|2010-04-24 00:00:00|  15647311|     Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|        3|2010-04-24 00:00:00|  15619304|     Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|        4|               null|  15701354|     Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
            "|        5|               null|  15737888| Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "|        6|               null|  15574012|      Chu|        645|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|      149756.71|     1|\n",
            "|        7|2010-04-26 00:00:00|  15592531| Bartlett|        822|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|\n",
            "|        8|2010-04-26 00:00:00|  15656148|   Obinna|        376|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|\n",
            "|        9|2010-04-26 00:00:00|  15792365|       He|        501|   France|  Male| 44|     4|142051.07|            2|        0|             1|        74940.5|     0|\n",
            "|       10|2010-04-27 00:00:00|  15592389|       H?|        684|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|\n",
            "|       11|2010-04-27 00:00:00|  15767821|   Bearce|        528|   France|  Male| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|\n",
            "|       12|2010-04-27 00:00:00|  15737173|  Andrews|        497|    Spain|  Male| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|\n",
            "|       13|2010-04-28 00:00:00|  15632264|      Kay|        476|   France|Female| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|\n",
            "|       14|2010-04-28 00:00:00|  15691483|     Chin|        549|   France|Female| 25|     5|      0.0|            2|        0|             0|      190857.79|     0|\n",
            "|       15|2010-04-28 00:00:00|  15600882|    Scott|        635|    Spain|Female| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|\n",
            "|       16|2010-04-29 00:00:00|  15643966|  Goforth|        616|  Germany|  Male| 45|     3|143129.41|            2|        0|             1|       64327.26|     0|\n",
            "|       17|2010-04-29 00:00:00|  15737452|    Romeo|        653|  Germany|  Male| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|\n",
            "|       18|2010-04-29 00:00:00|  15788218|Henderson|        549|    Spain|Female| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|\n",
            "|       19|2010-04-30 00:00:00|  15661507|  Muldrow|        587|    Spain|  Male| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|\n",
            "|       20|2010-04-30 00:00:00|  15568982|      Hao|        726|   France|Female| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|\n",
            "+---------+-------------------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBRSL1hfwJw4"
      },
      "source": [
        "int_count = 50\n",
        "orginal_data = 60\n",
        "val = int((int_count / orginal_data) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgoVwXPEx5Z8"
      },
      "source": [
        "def getAllNulls(data):\n",
        "    null_data = data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for (c, c_type) in data.dtypes if\n",
        "                             c_type not in ('boolean', 'timestamp', 'date')])\n",
        "    ret = null_data.first()\n",
        "    return ret.asDict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu9itzAkz8HG"
      },
      "source": [
        "def check_date_type_anomalies(rows):\n",
        "    temp = {}\n",
        "    row_obj = Row(\"is_date\")\n",
        "    n_rows = []\n",
        "    for row in rows:\n",
        "        column_val = row[col]\n",
        "        if getDate(column_val):\n",
        "            _row = row_obj(True)\n",
        "        else:\n",
        "            _row = row_obj(False)\n",
        "        n_rows.append(_row)\n",
        "    return iter(n_rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJqkoF2JvIGB"
      },
      "source": [
        "def ExtractAnomalies(data_path):\n",
        "    data = read_delta(data_path)\n",
        "   \n",
        "    data = data.select([column for column in data.columns if column != \"load_date\"])\n",
        "    #print(data.head())\n",
        "    total_count = data.count()\n",
        "    null_dict = getAllNulls(data)\n",
        "    null_anomalies = []\n",
        "    null_anomalies_cols = []\n",
        "    null_data_types = []\n",
        "    for i, j in null_dict.items():\n",
        "        if j > 0:\n",
        "            null_anomalies.append(j)\n",
        "            null_anomalies_cols.append(i)\n",
        "            null_data_types.append(str(data.schema[i].dataType))\n",
        "    data_type_anomalies = []\n",
        "    # data_no_null = data.na.drop()\n",
        "    noise_anomalies_cols = []\n",
        "    for col_name in data.columns:\n",
        "        orginal_data = data.filter(data[col_name]. isNotNull()).count()\n",
        "        if str(data.schema[col_name].dataType) == \"StringType\":\n",
        "            temp = {}\n",
        "            tdf = data.select(col_name, col(col_name).cast(\"int\").isNotNull().alias(\"is_int\"))\n",
        "            int_count = tdf.filter(col(\"is_int\") == True).count()\n",
        "            #orginal_data = df[col_name].na.drop(\"any\").show(false).count()\n",
        "            #orginal_data = data.filter(data[col_name]. isNotNull()).count()\n",
        "            if int((int_count / orginal_data) * 100)  >= 80:\n",
        "                temp['col_name'] = col_name\n",
        "                temp['NewType'] = \"IntegerType\"\n",
        "                temp['prevType'] = \"StringType\"\n",
        "                data_type_anomalies.append(temp)\n",
        "            tdf = data.select(col_name, col(col_name).cast(\"float\").isNotNull().alias(\"is_float\"))\n",
        "            float_count = tdf.filter(col(\"is_float\") == True).count()\n",
        "            #orginal_data = data.filter(data[col_name]. isNotNull()).count()\n",
        "            if int((float_count / orginal_data) * 100)  >= 80:\n",
        "            #if float_count:\n",
        "                temp['col_name'] = col_name\n",
        "                temp['NewType'] = \"FloatType\"\n",
        "                temp['prevType'] = \"StringType\"\n",
        "                data_type_anomalies.append(temp)\n",
        "            t_rdd = data.select(col(col_name).alias(\"column_to_check\")).rdd.mapPartitions(check_date_type_anomalies)\n",
        "            date_match = create_data_frame(t_rdd)\n",
        "            date_match_count = date_match.filter(col(\"is_date\") == True).count()\n",
        "            #orginal_data = df.filter(df[col_name]. isNotNull()).count()\n",
        "            if int((date_match_count / orginal_data) * 100)  >= 80:\n",
        "            #if date_match_count:\n",
        "                temp['col_name'] = col_name\n",
        "                temp['NewType'] = \"DateType\"\n",
        "                temp['prevType'] = \"StringType\"\n",
        "                data_type_anomalies.append(temp)\n",
        "                # data_type_anomalies.append(f\"{col_name} is StringType but we think it should be DataTime\")\n",
        "            elif CheckNoise(data, col_name):\n",
        "                noise_anomalies_cols.append(col_name)\n",
        "            return temp\n",
        "\n",
        "    sensitive_cols = predict_sensitivity(data)\n",
        "    # sensitive_cols = []\n",
        "    sensitive = \"true\"\n",
        "    if len(null_anomalies) != 0 or len(data_type_anomalies) != 0 or len(sensitive_cols) == 0:\n",
        "        if len(null_anomalies) == 0:\n",
        "            null_anomalies = []\n",
        "        if len(data_type_anomalies) == 0:\n",
        "            data_type_anomalies = []\n",
        "        if len(sensitive_cols) == 0:\n",
        "            sensitive = \"false\"\n",
        "        return_dic = {\"Null_anomalies\": makeFormat3(null_anomalies, null_anomalies_cols, null_data_types),\n",
        "                        # \"DataType_anomalies\" : makeFormat2(data_type_anomalies , data_type_anomalies_cols),\n",
        "                        \"DataType_anomalies\": data_type_anomalies,\n",
        "                        \"Sensitive_anomalies\": makeFormat4(data, sensitive_cols),\n",
        "                        \"Mail_anomolies\": Standardization(data, total_count, null_dict),\n",
        "                        \"Noise_anomalies\": makeFormat(data, noise_anomalies_cols), \"Sensitive\": sensitive,\n",
        "                        \"Status\": 200, \"Message\": \"Success\"}\n",
        "    else:\n",
        "        if len(null_anomalies) == 0:\n",
        "            null_anomalies = []\n",
        "        if len(data_type_anomalies) == 0:\n",
        "            data_type_anomalies = []\n",
        "        if len(sensitive_cols) == 0:\n",
        "            sensitive = \"false\"\n",
        "        return_dic = {\"Null_anomalies\": makeFormat3(null_anomalies, null_anomalies_cols, null_data_types),\n",
        "                        # \"DataType_anomalies\" : makeFormat2(data_type_anomalies , data_type_anomalies_cols),\n",
        "                        \"DataType_anomalies\": data_type_anomalies,\n",
        "                        \"Sensitive_anomalies\": makeFormat4(data, sensitive_cols),\n",
        "                        \"Mail_anomolies\": Standardization(data, total_count, null_dict),\n",
        "                        \"Noise_anomalies\": makeFormat(data, noise_anomalies_cols), \"Sensitive\": sensitive,\n",
        "                        \"Status\": 200, \"Message\": \"No Anomalies found\"}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "lkoEK0x_zPib",
        "outputId": "f3a54cd6-0242-4b77-c5ba-cd7f8907d22b"
      },
      "source": [
        "ExtractAnomalies(\"/content/Iris_new_small\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row(Id=1, SepalLengthCm=5.1, SepalWidthCm=None, PetalLengthCm=1.4, PetalWidthCm=0.2, Species='Iris-setosa')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5979007be0af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mExtractAnomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Iris_new_small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-0dc48a53c355>\u001b[0m in \u001b[0;36mExtractAnomalies\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mdata_type_anomalies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mt_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"column_to_check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_date_type_anomalies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mdate_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_rdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mdate_match_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_date\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#orginal_data = df.filter(df[col_name]. isNotNull()).count()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_data_frame' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOYKey4mzKHA"
      },
      "source": [
        "df = read_delta(\"/content/Iris_new_small\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53jC41PazSqf",
        "outputId": "5291a031-72a7-4fbe-e5d2-d7813a5c2005"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-------------+------------+-------------+------------+-----------+\n",
            "|  Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+----+-------------+------------+-------------+------------+-----------+\n",
            "|   1|          5.1|        null|          1.4|         0.2|Iris-setosa|\n",
            "|   2|          4.9|           3|          1.4|         0.2|Iris-setosa|\n",
            "|null|          4.7|           #|          1.3|         0.2|Iris-setosa|\n",
            "|   4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|   5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "+----+-------------+------------+-------------+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1XHumx1whGP"
      },
      "source": [
        "def ExtractAnomalies(data_path):\n",
        "    data = read_delta(data_path)\n",
        "    data = data.select([column for column in data.columns if column != \"load_date\"])\n",
        "    # print(data.head())\n",
        "    total_count = data.count()\n",
        "    null_dict = getAllNulls(data)\n",
        "    for col_name in data.columns:\n",
        "        if str(data.schema[col_name].dataType) in [\"TimestampType\",\"date\",\"DateType\"]:\n",
        "            print(\"Teja worest dayyyyyyyyyyyyyyyyyyyyyyyyyyy\")\n",
        "            null_dict = getAll_date_Nulls(data,null_dict,col_name)\n",
        "    #print(null_dict)\n",
        "    #return null_dict\n",
        "    null_anomalies = []\n",
        "    null_anomalies_cols = []\n",
        "    null_data_types = []\n",
        "    for i, j in null_dict.items():\n",
        "        if j > 0:\n",
        "            null_anomalies.append(j)\n",
        "            null_anomalies_cols.append(i)\n",
        "            null_data_types.append(str(data.schema[i].dataType))\n",
        "    data_type_anomalies = []\n",
        "    # data_type_anomalies_cols = []\n",
        "    noise_anomalies_cols = []\n",
        "    for col_name in data.columns:\n",
        "        if str(data.schema[col_name].dataType) == \"StringType\":\n",
        "            temp = {}\n",
        "            data = data.na.drop(subset=[col_name])\n",
        "            vals = data.select(col_name).collect()[:100]\n",
        "            vals = list(map(lambda x: str(x[0]), vals))\n",
        "            if CheckInt(vals, col_name):\n",
        "                temp['col_name'] = col_name\n",
        "                temp['NewType'] = \"IntegerType\"\n",
        "                temp['prevType'] = \"StringType\"\n",
        "                data_type_anomalies.append(temp)\n",
        "                # data_type_anomalies_cols.append(col_name)\n",
        "            elif CheckFloat(vals, col_name):\n",
        "                temp['col_name'] = col_name\n",
        "                temp['NewType'] = \"FloatType\"\n",
        "                temp['prevType'] = \"StringType\"\n",
        "                data_type_anomalies.append(temp)\n",
        "                # data_type_anomalies.append(f\"{col_name} is StringType but we think it should be FloatType\")\n",
        "                # data_type_anomalies_cols.append(col_name)\n",
        "            elif CouldBeDate(vals, col_name):\n",
        "                temp['col_name'] = col_name\n",
        "                temp['NewType'] = \"DateType\"\n",
        "                temp['prevType'] = \"StringType\"\n",
        "                data_type_anomalies.append(temp)\n",
        "                # data_type_anomalies.append(f\"{col_name} is StringType but we think it should be DataTime\")\n",
        "                # data_type_anomalies_cols.append(col_name)\n",
        "            elif CheckNoise(data, col_name):\n",
        "                noise_anomalies_cols.append(col_name)\n",
        "    #sensitive_cols = predict_sensitivity(data)\n",
        "    # sensitive_cols = []\n",
        "    sensitive = \"true\"\n",
        "    if len(null_anomalies) != 0 or len(data_type_anomalies) != 0:\n",
        "        if len(null_anomalies) == 0:\n",
        "            null_anomalies = []\n",
        "        if len(data_type_anomalies) == 0:\n",
        "            data_type_anomalies = []\n",
        "        return_dic = {\"Null_anomalies\": makeFormat3(null_anomalies, null_anomalies_cols, null_data_types),\n",
        "                      # \"DataType_anomalies\" : makeFormat2(data_type_anomalies , data_type_anomalies_cols),\n",
        "                      \"DataType_anomalies\": data_type_anomalies,\n",
        "                      \"Mail_anomolies\": Standardization(data, total_count, null_dict),\n",
        "                      \"Noise_anomalies\": makeFormat(data, noise_anomalies_cols),\n",
        "                      \"Status\": 200, \"Message\": \"Success\"}\n",
        "    else:\n",
        "        if len(null_anomalies) == 0:\n",
        "            null_anomalies = []\n",
        "        if len(data_type_anomalies) == 0:\n",
        "            data_type_anomalies = []\n",
        "        return_dic = {\"Null_anomalies\": makeFormat3(null_anomalies, null_anomalies_cols, null_data_types),\n",
        "                      # \"DataType_anomalies\" : makeFormat2(data_type_anomalies , data_type_anomalies_cols),\n",
        "                      \"DataType_anomalies\": data_type_anomalies,\n",
        "                      \"Mail_anomolies\": Standardization(data, total_count, null_dict),\n",
        "                      \"Noise_anomalies\": makeFormat(data, noise_anomalies_cols), \"Sensitive\": sensitive,\n",
        "                      \"Status\": 200, \"Message\": \"No Anomalies found\"}\n",
        "    return return_dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDXLljs_fsIo",
        "outputId": "212b0fb6-2ac8-43ad-e23b-4dca5e8935a1"
      },
      "source": [
        "data.schema['date']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructField(date,DateType,true)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0mnfiIAPE4g"
      },
      "source": [
        "df = read_delta(\"/content/Iris_new\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9o-S7yPSoH"
      },
      "source": [
        "data = df.withColumn(\"SepalLengthCm\" , df[\"SepalLengthCm\"].cast(StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT1HuFG2Pb6C"
      },
      "source": [
        "data = data.withColumn(\"SepalWidthCm\" , df[\"SepalWidthCm\"].cast(StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXUxnBC_Per9"
      },
      "source": [
        "data = data.withColumn(\"PetalLengthCm\" , df[\"PetalLengthCm\"].cast(StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgEqMkbHPo62"
      },
      "source": [
        "data = data.withColumn(\"PetalWidthCm\" , df[\"PetalWidthCm\"].cast(StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhmarKIzPImm"
      },
      "source": [
        "write_delta(data,\"/content/Iris_new\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVb16MO4MwYX",
        "outputId": "4e0c6156-5bc1-449e-b434-a82fed508293"
      },
      "source": [
        "ExtractAnomalies(\"/content/Iris_new\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DataType_anomalies': [{'NewType': 'FloatType',\n",
              "   'col_name': 'SepalLengthCm',\n",
              "   'prevType': 'StringType'},\n",
              "  {'NewType': 'FloatType',\n",
              "   'col_name': 'SepalWidthCm',\n",
              "   'prevType': 'StringType'},\n",
              "  {'NewType': 'FloatType',\n",
              "   'col_name': 'PetalLengthCm',\n",
              "   'prevType': 'StringType'},\n",
              "  {'NewType': 'FloatType',\n",
              "   'col_name': 'PetalWidthCm',\n",
              "   'prevType': 'StringType'}],\n",
              " 'Mail_anomolies': [],\n",
              " 'Message': 'Success',\n",
              " 'Noise_anomalies': [],\n",
              " 'Null_anomalies': [{'ColName': 'SepalLengthCm',\n",
              "   'ColType': 'StringType',\n",
              "   'Column': 67,\n",
              "   'tooltip': 'Nulls will be replaced with Mode'},\n",
              "  {'ColName': 'SepalWidthCm',\n",
              "   'ColType': 'StringType',\n",
              "   'Column': 1,\n",
              "   'tooltip': 'Nulls will be replaced with Mode'}],\n",
              " 'Status': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sp_UG2ek6dV",
        "outputId": "78c26613-ecd5-4a18-ce76-0bf557660723"
      },
      "source": [
        "if str(df.schema[\"date\"].dataType) in [\"TimestampType\",\"date\"]:\n",
        "    print(\"teja\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "teja\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKSHDjWQiLK2",
        "outputId": "4a5b254a-f525-4a34-9e08-3e1dc01a4549"
      },
      "source": [
        "df.schema['date']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructField(date,TimestampType,true)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTxbKmsnio3-"
      },
      "source": [
        "val = getMode(data , \"date\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlnN7EftjnAa",
        "outputId": "ed851f0e-ce00-41a5-ace8-d64c4e8a2bab"
      },
      "source": [
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2010, 10, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa1giXy2wgs5"
      },
      "source": [
        "#data = df.withColumn(\"date\" , df[\"date\"].cast(StringType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acQG0SfnJcdd"
      },
      "source": [
        "df = read_delta(\"/content/PoS\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjlVC1GUjAW4"
      },
      "source": [
        "def CouldBeDate(data , col_name):\n",
        "    date_data = data.select(col_name).collect()[0:20]\n",
        "    date_data = list(map(lambda x : x[0] , date_data))\n",
        "    date_data = list(map(lambda x : getDate(x) , date_data))\n",
        "    occurence_counter = Counter(date_data)\n",
        "    return occurence_counter[None] < 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKfdiFcBjNyp",
        "outputId": "10b115c0-43d1-47a6-dd01-2ea0df0de8f1"
      },
      "source": [
        "CouldBeDate(df,'Date')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "4Z5Ayr-nj94b",
        "outputId": "26655c61-8987-4987-9149-26b4e1f498bb"
      },
      "source": [
        "date_data = data.select(col_name).limit(50).collect()\n",
        "date_data = list(map(lambda x : x[0] , date_data))\n",
        "patterns = list(map(lambda x : generate_pattern(x) , date_data))\n",
        "occurence_counter = Counter(patterns)\n",
        "date_format = occurence_counter.most_common(1)[0][0]\n",
        "if date_format == \"\":\n",
        "    continue\n",
        "else:\n",
        "    try:\n",
        "        data = data.withColumn(col_name , to_date(data[col_name], date_format).alias(col_name))\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-65aa979942bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdate_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mgenerate_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdate_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moccurence_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdate_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moccurence_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'col_name' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV394wvwincJ",
        "outputId": "81b5f576-7eee-4f08-f208-bd83f13c84fc"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Country', 'string'),\n",
              " ('City', 'string'),\n",
              " ('Product', 'string'),\n",
              " ('Store', 'string'),\n",
              " ('Brand', 'string'),\n",
              " ('Date', 'string'),\n",
              " ('sold_units', 'int'),\n",
              " ('On_Hand_Units', 'int'),\n",
              " ('Sold_Amount', 'int'),\n",
              " ('On_Hand_Amount', 'int'),\n",
              " ('version', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUp4GkGTpXEp"
      },
      "source": [
        "df = df.withColumn('Date',to_date(col('Date')).alias('Date').cast(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1yFk6uvKDWS"
      },
      "source": [
        "data = df.withColumn(\"Date\" , to_date(df[\"Date\"]).alias(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPOxvduaeaTH",
        "outputId": "d3424368-e179-4677-ec75-9fed5c718a18"
      },
      "source": [
        "date_type.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RowNumber',\n",
              " 'date',\n",
              " 'CustomerId',\n",
              " 'Surname',\n",
              " 'CreditScore',\n",
              " 'Geography',\n",
              " 'Gender',\n",
              " 'Age',\n",
              " 'Tenure',\n",
              " 'Balance',\n",
              " 'NumOfProducts',\n",
              " 'HasCrCard',\n",
              " 'IsActiveMember',\n",
              " 'EstimatedSalary',\n",
              " 'Exited']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egDIbIe8KcCE"
      },
      "source": [
        "data = date_type.withColumn(\"date\" , to_date(date_type[\"date\"]).alias(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQidIeliJlqK",
        "outputId": "4be26b4b-bba0-4eb7-f27d-37eeda581282"
      },
      "source": [
        "data = read_delta(\"/content/PoS\")\n",
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|RowNumber|      date|CustomerId|  Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+---------+----------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|        1|2010-04-24|  15634602| Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
            "|        2|2010-04-24|  15647311|     Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|        3|2010-04-24|  15619304|     Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|        4|      null|  15701354|     Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
            "|        5|      null|  15737888| Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "|        6|      null|  15574012|      Chu|        645|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|      149756.71|     1|\n",
            "|        7|2010-04-26|  15592531| Bartlett|        822|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|\n",
            "|        8|2010-04-26|  15656148|   Obinna|        376|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|\n",
            "|        9|2010-04-26|  15792365|       He|        501|   France|  Male| 44|     4|142051.07|            2|        0|             1|        74940.5|     0|\n",
            "|       10|2010-04-27|  15592389|       H?|        684|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|\n",
            "|       11|2010-04-27|  15767821|   Bearce|        528|   France|  Male| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|\n",
            "|       12|2010-04-27|  15737173|  Andrews|        497|    Spain|  Male| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|\n",
            "|       13|2010-04-28|  15632264|      Kay|        476|   France|Female| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|\n",
            "|       14|2010-04-28|  15691483|     Chin|        549|   France|Female| 25|     5|      0.0|            2|        0|             0|      190857.79|     0|\n",
            "|       15|2010-04-28|  15600882|    Scott|        635|    Spain|Female| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|\n",
            "|       16|2010-04-29|  15643966|  Goforth|        616|  Germany|  Male| 45|     3|143129.41|            2|        0|             1|       64327.26|     0|\n",
            "|       17|2010-04-29|  15737452|    Romeo|        653|  Germany|  Male| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|\n",
            "|       18|2010-04-29|  15788218|Henderson|        549|    Spain|Female| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|\n",
            "|       19|2010-04-30|  15661507|  Muldrow|        587|    Spain|  Male| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|\n",
            "|       20|2010-04-30|  15568982|      Hao|        726|   France|Female| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|\n",
            "+---------+----------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MabZaX6h5Tb",
        "outputId": "e59d8290-8ce5-4d2d-c350-eba111a97db6"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('RowNumber', 'int'),\n",
              " ('date', 'date'),\n",
              " ('CustomerId', 'int'),\n",
              " ('Surname', 'string'),\n",
              " ('CreditScore', 'int'),\n",
              " ('Geography', 'string'),\n",
              " ('Gender', 'string'),\n",
              " ('Age', 'int'),\n",
              " ('Tenure', 'int'),\n",
              " ('Balance', 'double'),\n",
              " ('NumOfProducts', 'int'),\n",
              " ('HasCrCard', 'int'),\n",
              " ('IsActiveMember', 'int'),\n",
              " ('EstimatedSalary', 'double'),\n",
              " ('Exited', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Y9ZM7thh_3"
      },
      "source": [
        "#df = df.withColumn(\"date\",to_date(col('date')).alias('date').cast(\"date\"))\n",
        "#data = data.withColumn(col_name , to_date(data[col_name]).alias(col_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TaNgpn2taWB"
      },
      "source": [
        "#data = data.na.fill({\"date\" : getMode(data , \"date\")})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT7S9M64thzl"
      },
      "source": [
        "#data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ZDBKp5jBKx"
      },
      "source": [
        "#data = data.withColumn(\"date\" , to_date(data[\"date\"]).alias(\"date\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdYJxhHxKSz"
      },
      "source": [
        "#data.schema['date']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVtqJyVa3C2c",
        "outputId": "25f381b0-d073-4a5a-dd60-1399560095cd"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-----------+----------+-------+--------+--------+----------+-------------+-----------+--------------+-------+\n",
            "|    Country|       City|   Product|  Store|   Brand|    Date|sold_units|On_Hand_Units|Sold_Amount|On_Hand_Amount|version|\n",
            "+-----------+-----------+----------+-------+--------+--------+----------+-------------+-----------+--------------+-------+\n",
            "|      kiran|      India| Product_0|Store_0| Brand_0|    null|         8|           38|        367|           335|      1|\n",
            "|      India|  Hyderabad|Product_11|Store_0| Brand_5|    null|        25|            0|     125318|         47272|      1|\n",
            "|     France|       Nice| Product_8|Store_8|Brand_16|    null|         6|            0|      82176|        475477|      1|\n",
            "|      Spain|    Seville|Product_47|Store_1|Brand_12|1/1/1970|        32|            0|     126560|        244151|      1|\n",
            "|  Singapore|     Yishun|Product_22|Store_0| Brand_2|1/1/1970|         2|            0|      54529|         14026|      1|\n",
            "|     France|      Dijon| Product_2|Store_9|Brand_16|1/1/1970|        19|            0|       5334|        167047|      1|\n",
            "|  Singapore|     Yishun|Product_35|Store_2| Brand_8|1/1/1970|        65|            0|      23283|         94977|      1|\n",
            "|      Spain|    Seville|Product_40|Store_6| Brand_9|1/1/1970|       100|            0|      12287|        310314|      1|\n",
            "|Netherlands|      Assen| Product_3|Store_2| Brand_0|1/1/1970|        36|            0|       1718|        373982|      1|\n",
            "|     Sweden|     Gr�nna|Product_14|Store_9| Brand_0|1/1/1970|        93|            0|      46451|         64944|      1|\n",
            "|    Ukraine|       Kyiv| Product_9|Store_5|Brand_15|1/1/1970|        19|            0|       7609|        210289|      1|\n",
            "|      India|      Delhi|Product_27|Store_9|Brand_13|1/1/1970|        12|            0|      50133|        254311|      1|\n",
            "|     Russia|Arkhangelsk|Product_19|Store_6| Brand_8|1/1/1970|         7|            0|     111239|         71127|      1|\n",
            "|     Sweden|      Eksj�|Product_25|Store_5| Brand_5|1/1/1970|        30|            0|      18704|         82075|      1|\n",
            "|      Spain|     Bilbao|Product_45|Store_7|Brand_15|1/1/1970|        91|            0|      72332|        233645|      1|\n",
            "|  Singapore|    Punggol|Product_21|Store_3|Brand_20|1/1/1970|        35|            0|      34357|        801414|      1|\n",
            "|     Russia|Arkhangelsk|Product_34|Store_2|Brand_20|1/1/1970|        67|            0|      27063|        345587|      1|\n",
            "|     Sweden|     Arboga| Product_3|Store_8| Brand_0|1/1/1970|        12|            0|      45572|         21953|      1|\n",
            "|     Sweden|      Boden| Product_0|Store_5| Brand_5|1/1/1970|        80|            0|       5705|        156443|      1|\n",
            "|        USA|   Columbus|Product_13|Store_8|Brand_19|1/1/1970|        36|            0|      26242|        389647|      1|\n",
            "+-----------+-----------+----------+-------+--------+--------+----------+-------------+-----------+--------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewi4DRXP2oNC"
      },
      "source": [
        "#data = data.na.fill({\"date\" : getMode(data , \"date\")})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDb5r4zG2bJy"
      },
      "source": [
        "#test(df,'date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLEUdG0ogvZM"
      },
      "source": [
        "Handling nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmZIy-CCQ8kg"
      },
      "source": [
        "def HandleNulls(data : pyspark.sql.dataframe.DataFrame , recommended_nulls : list , custom_null_cols : list , custom_null_vals : list , rejected_null_cols : list) -> pyspark.sql.dataframe.DataFrame:\n",
        "    columns = data.columns\n",
        "    dataset_length = data.count()\n",
        "    custom_col_dic = {}\n",
        "    for col_name , col_val in zip(custom_null_cols , custom_null_vals):\n",
        "        custom_col_dic[col_name] = col_val\n",
        "    for col_name in columns :\n",
        "        if col_name in recommended_nulls :\n",
        "            if str(data.schema[col_name].dataType) == \"StringType\" :\n",
        "                try :\n",
        "                    data = data.na.fill({col_name : getMode(data , col_name)})\n",
        "                except :\n",
        "                    data = data.na.fill({col_name : \"\"})\n",
        "            elif str(data.schema[col_name].dataType) in [\"IntegerType\" , \"LongType\"]:\n",
        "                try :\n",
        "                    if data.select(col_name).distinct().count()/dataset_length > 0.05 :\n",
        "                        data = data.na.fill({col_name : getMean(data , col_name)})\n",
        "                    else :\n",
        "                        data = data.na.fill({col_name : getMode(data , col_name)})\n",
        "                except :\n",
        "                    data = data.na.fill({col_name : 0})\n",
        "            elif str(data.schema[col_name].dataType) in [\"FloatType\" , \"DoubleType\"]:\n",
        "                try :\n",
        "                    data = data.na.fill({col_name : round(getMean(data , col_name) , 2)})\n",
        "                except :\n",
        "                    data = data.na.fill({col_name : 0.0})\n",
        "            \n",
        "            elif str(data.schema[col_name].dataType) in ['timestamp','TimestampType','date','DateType']:\n",
        "                print(\"My frist code in spark22222222222222222222222222222222222\")\n",
        "                #try :\n",
        "                data = data.withColumn(col_name , data[col_name].cast(StringType()))\n",
        "                data = data.na.fill({col_name : getMode(data , col_name)})\n",
        "                data = data.withColumn(col_name , to_date(data[col_name]).alias(col_name))\n",
        "                print(\"My frist code in pyspark777777777777777777777777777777777777777777\")\n",
        "                #except :\n",
        "                #data = data.na.fill({col_name : 0.0})\n",
        "        elif col_name in custom_null_cols:\n",
        "            if str(data.schema[col_name].dataType) == \"StringType\" :\n",
        "                try :\n",
        "                    data = data.na.fill({col_name : custom_col_dic[col_name]})\n",
        "                except :\n",
        "                    data = data.na.fill({col_name : \"\"})\n",
        "            elif str(data.schema[col_name].dataType) in [\"IntegerType\" , \"LongType\"]:\n",
        "                try :\n",
        "                    data = data.na.fill({col_name : int(custom_col_dic[col_name])})\n",
        "                except :\n",
        "                    data = data.na.fill({col_name : 0})\n",
        "            elif str(data.schema[col_name].dataType) in [\"FloatType\" , \"DoubleType\"]:\n",
        "                try :\n",
        "                    data = data.na.fill({col_name : float(custom_col_dic[col_name])})\n",
        "                except :\n",
        "                    data = data.na.fill({col_name : 0.0})\n",
        "        elif col_name in rejected_null_cols:\n",
        "            data = data.na.drop(subset=[col_name])\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smy4w-DitkdH"
      },
      "source": [
        "recommended_nulls = ['date']\n",
        "custom_null_cols = []\n",
        "custom_null_vals = []\n",
        "rejected_null_cols = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtXNr591VrM1"
      },
      "source": [
        "#data = df.na.fill({'Date' : getMode(df , \"Date\")})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjB7L7vqO8fN",
        "outputId": "eed34c74-95c1-4e29-aefa-742c9c700243"
      },
      "source": [
        "df = HandleNulls(data , recommended_nulls,custom_null_cols,custom_null_vals,rejected_null_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My frist code in spark22222222222222222222222222222222222\n",
            "My frist code in pyspark777777777777777777777777777777777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uHxF7CU4oa4",
        "outputId": "31bd2378-8ac4-4c68-a2ee-1314f609459c"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|RowNumber|      date|CustomerId|  Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+---------+----------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|        1|2010-04-24|  15634602| Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
            "|        2|2010-04-24|  15647311|     Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|        3|2010-04-24|  15619304|     Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|        4|2012-03-04|  15701354|     Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
            "|        5|2012-03-04|  15737888| Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "|        6|2012-03-04|  15574012|      Chu|        645|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|      149756.71|     1|\n",
            "|        7|2010-04-26|  15592531| Bartlett|        822|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|\n",
            "|        8|2010-04-26|  15656148|   Obinna|        376|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|\n",
            "|        9|2010-04-26|  15792365|       He|        501|   France|  Male| 44|     4|142051.07|            2|        0|             1|        74940.5|     0|\n",
            "|       10|2010-04-27|  15592389|       H?|        684|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|\n",
            "|       11|2010-04-27|  15767821|   Bearce|        528|   France|  Male| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|\n",
            "|       12|2010-04-27|  15737173|  Andrews|        497|    Spain|  Male| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|\n",
            "|       13|2010-04-28|  15632264|      Kay|        476|   France|Female| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|\n",
            "|       14|2010-04-28|  15691483|     Chin|        549|   France|Female| 25|     5|      0.0|            2|        0|             0|      190857.79|     0|\n",
            "|       15|2010-04-28|  15600882|    Scott|        635|    Spain|Female| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|\n",
            "|       16|2010-04-29|  15643966|  Goforth|        616|  Germany|  Male| 45|     3|143129.41|            2|        0|             1|       64327.26|     0|\n",
            "|       17|2010-04-29|  15737452|    Romeo|        653|  Germany|  Male| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|\n",
            "|       18|2010-04-29|  15788218|Henderson|        549|    Spain|Female| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|\n",
            "|       19|2010-04-30|  15661507|  Muldrow|        587|    Spain|  Male| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|\n",
            "|       20|2010-04-30|  15568982|      Hao|        726|   France|Female| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|\n",
            "+---------+----------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHxg3awSvzpf"
      },
      "source": [
        "def for_API_3(csv_file , lis1 , lis2 , user_id):\n",
        "    if csv_file.startswith(\"s3\"):\n",
        "        type_ = 's3'\n",
        "        save_path = csv_file\n",
        "    elif csv_file.startswith(\"oss\"):\n",
        "        type_ = 'oss'\n",
        "        save_path = csv_file\n",
        "    nas = LoadNas(save_path , type_ , user_id)\n",
        "    cols = LoadCols(save_path , type_ , user_id)\n",
        "    model , _ = LoadModel(save_path , type_ , user_id)\n",
        "    target , len_ = LoadTargetandLen(save_path , type_ , user_id)\n",
        "\n",
        "    dic = {}\n",
        "    cat_list = []\n",
        "    for i , j in zip(lis1 , lis2):\n",
        "        try :\n",
        "            dic[i] = int(j)\n",
        "        except :\n",
        "            dic[i] = j\n",
        "            cat_list.append(i)\n",
        "    dic[target] = [1]\n",
        "\n",
        "    Data = pd.DataFrame.from_dict(dic)\n",
        "    #print(\"Shape : 1 : \" , Data.shape)\n",
        "    for i in cat_list :\n",
        "        Data[i] = Data[i].astype('category')\n",
        "    \n",
        "    data = LoadData(save_path , type_ , user_id)\n",
        "    apply_cats(df=Data , trn=data)\n",
        "    #print(\"NAS : \" , nas)\n",
        "    [Data, _, _] , _ = proc_df(Data , target , na_dict = nas)\n",
        "    #Data, _, _ = proc_df(Data , target , na_dict = nas)\n",
        "    #print(Data)\n",
        "    #print(\"Shape : data : \" , data.shape)\n",
        "    #print(\"Shape : 2 : \" , Data.columns)\n",
        "    pred = model.predict(Data)\n",
        "    pred = pred[0]\n",
        "    try :\n",
        "        pred = round(float(pred) , 2)\n",
        "        if pred.is_integer():\n",
        "            return \"Predicted Output for \" + target + \" is \" + str(int(pred))\n",
        "        else :\n",
        "            return \"Predicted Output for \" + target + \" is \" + str(pred)\n",
        "    except :\n",
        "        pred = str(pred)\n",
        "    return \"Predicted Output for \" + target + \" is \" + pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Iq3_ULjh5b"
      },
      "source": [
        "import pandas as pd\n",
        "#data = pd.read_csv('/content/_PointOfSales.csv', encoding='latin-1')\n",
        "#data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaiO-NG-kGzu"
      },
      "source": [
        "#data.to_csv('Modifiedsales.csv',header=True,index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csiUus2UH6se"
      },
      "source": [
        "from delta.tables import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTVzu4Mejfes"
      },
      "source": [
        "deltaTable = DeltaTable.forPath(spark, \"/content/Churn_Modelling\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOBKVtZphpkr"
      },
      "source": [
        "from spark_utils import read_csv , read_delta , write_delta,write_csv_as_delta,read_delta_as_pddf ,getVersionsDelta,getMode,getMean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0samTYafWo_",
        "outputId": "ec75361e-3d50-47c5-8456-a817ffd01b0f"
      },
      "source": [
        "getVersionsDelta('/content/Churn_Modelling')[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBw2tgPBxtZ6"
      },
      "source": [
        "write_csv_as_delta(\"/content/Iris_new.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br3Y9wWCy67I",
        "outputId": "14eaa5e2-a08a-42f5-e89e-233580c7571a"
      },
      "source": [
        "df2 = read_delta(\"/content/Iris_new\")\n",
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
            "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|\n",
            "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|\n",
            "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|\n",
            "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|\n",
            "| 13|         null|         3.0|          1.4|         0.1|Iris-setosa|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKaNK4Ah53BU"
      },
      "source": [
        "df3 = df2.withColumn(\"date\",col(\"date\").cast(StringType())) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AjmLlbJ7LXr"
      },
      "source": [
        " #data = df3.Null.fill({\"date\" : getMode(df3 , \"date\")})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lIV6L2J7gXN",
        "outputId": "da1f3439-392e-4881-fbae-462605148bcf"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|RowNumber|                date|CustomerId|  Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+---------+--------------------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|        1|          12/24/2010|  15634602| Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
            "|        2|          12/24/2010|      null|     Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|        3|          12/24/2010|      None|     Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|        4|           4/25/2010|  15701354|     Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
            "|        5|           4/25/2010|  15737888| Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "|        6|           4/25/2010|  15574012|      Chu|        645|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|      149756.71|     1|\n",
            "|        7|                 ...|  15592531| Bartlett|        822|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|\n",
            "|        8|           4/26/2010|  15656148|   Obinna|        376|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|\n",
            "|        9|           4/26/2010|  15792365|       He|        501|   France|  Male| 44|     4|142051.07|            2|        0|             1|        74940.5|     0|\n",
            "|       10|           4/27/2010|  15592389|       H?|        684|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|\n",
            "|       11|                 ...|  15767821|   Bearce|        528|   France|  Male| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|\n",
            "|       12|           4/27/2010|  15737173|  Andrews|        497|    Spain|  Male| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|\n",
            "|       13|           4/28/2010|  15632264|      Kay|        476|   France|Female| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|\n",
            "|       14|           4/28/2010|  15691483|     Chin|        549|   France|Female| 25|     5|      0.0|            2|        0|             0|      190857.79|     0|\n",
            "|       15|           4/28/2010|  15600882|    Scott|        635|    Spain|Female| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|\n",
            "|       16|           4/29/2010|  15643966|  Goforth|        616|  Germany|  Male| 45|     3|143129.41|            2|        0|             1|       64327.26|     0|\n",
            "|       17|           4/29/2010|  15737452|    Romeo|        653|  Germany|  Male| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|\n",
            "|       18|           4/29/2010|  15788218|Henderson|        549|    Spain|Female| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|\n",
            "|       19|           4/30/2010|  15661507|  Muldrow|        587|    Spain|  Male| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|\n",
            "|       20|           4/30/2010|  15568982|      Hao|        726|   France|Female| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|\n",
            "+---------+--------------------+----------+---------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQaRkara6VQJ"
      },
      "source": [
        "write_delta(df3,\"/content/tet_date\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWbUvsenu9WH"
      },
      "source": [
        "null_data = df2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for (c, c_type) in df2.dtypes if c_type not in ('boolean', 'timestamp', 'date')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DKppMNCwOxU"
      },
      "source": [
        "null_data = df2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for (c, c_type) in df2.dtypes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWjPKkVy1f03",
        "outputId": "d278e8bd-8222-4540-c3bf-bb69c0e8d289"
      },
      "source": [
        "df2.select([count(when(isnan('date'),True))]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------+\n",
            "|count(CASE WHEN isnan(date) THEN true END)|\n",
            "+------------------------------------------+\n",
            "|                                         0|\n",
            "+------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07iWD9wDy5LK"
      },
      "source": [
        "null_data = df2.select([count(when(col('date').isNull(),True))]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNCMuFVlREjl",
        "outputId": "cb05dc4b-39bd-43a4-fcbb-020a3d5c5a47"
      },
      "source": [
        "null_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
            "|RowNumber|date|CustomerId|Surname|CreditScore|Geography|Gender|Age|Tenure|Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+---------+----+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
            "|        0|   3|         1|      0|          0|        0|     0|  0|     0|      0|            0|        0|             0|              0|     0|\n",
            "+---------+----+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdC8PZatQMGW"
      },
      "source": [
        "val = null_data.first()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H447OSDjQcYT",
        "outputId": "29b28e55-fef2-4fbb-bc29-616b19993068"
      },
      "source": [
        "val.asDict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Age': 3,\n",
              " 'Balance': 3,\n",
              " 'CreditScore': 3,\n",
              " 'CustomerId': 3,\n",
              " 'EstimatedSalary': 3,\n",
              " 'Exited': 3,\n",
              " 'Gender': 3,\n",
              " 'Geography': 3,\n",
              " 'HasCrCard': 3,\n",
              " 'IsActiveMember': 3,\n",
              " 'NumOfProducts': 3,\n",
              " 'RowNumber': 3,\n",
              " 'Surname': 3,\n",
              " 'Tenure': 3,\n",
              " 'date': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "Vd5FgBBKvUTZ",
        "outputId": "956b817d-3708-42e7-9587-98a2258f7b26"
      },
      "source": [
        "ret = null_data.first()\n",
        "ret.asDict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a00fe90ecfce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'first'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b9omuCvt3ZJ"
      },
      "source": [
        "def getAllNulls(data):\n",
        "    null_data = data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for (c, c_type) in data.dtypes if\n",
        "                             c_type not in ('boolean', 'timestamp', 'date')])\n",
        "    ret = null_data.first()\n",
        "    return ret.asDict()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "RNXTB6V-t7L0",
        "outputId": "07e9be95-c130-4680-a170-ba8c828807a3"
      },
      "source": [
        "getAllNulls(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c083417d7378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetAllNulls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "9-XSk6jQy7AG",
        "outputId": "51cd752b-986d-482d-ed4a-527dfa14f4dd"
      },
      "source": [
        "write_delta(df2,\"/content/Iris_new\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6c869f95a30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/Iris_new\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8737ZMHQds9B"
      },
      "source": [
        "def TokenizeAndSave(data_path , data , col_name):\n",
        "    data1 = data.withColumn('tokenize_' + col_name,sha2(col_name,256))\n",
        "    final_data = data1.select(col_name,'tokenize_' + col_name)\n",
        "    data3 = data1.drop(col(col_name))\n",
        "    data3 = data3.withColumnRenamed('tokenize_' + col_name , col_name)\n",
        "    if os.path.isfile(data_path + \"/tokenized\"):\n",
        "        old_data = read_delta(data_path + \"/tokenized\")\n",
        "        old_data = old_data.withColumn(\"_id_\", monotonically_increasing_id())\n",
        "        final_data = final_data.withColumn(\"_id_\", monotonically_increasing_id())\n",
        "        final_data = old_data.join(final_data, \"_id_\", \"outer\").drop(\"_id_\")\n",
        "    write_delta(final_data , data_path + \"/tokenized\")\n",
        "    return data3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcuCsrWod7BI"
      },
      "source": [
        "def Tokenization(data_path,col_name):\n",
        "  #data_path = kwargs[\"params\"][\"data_path\"]\n",
        "  #col_name = kwargs[\"params\"][\"col_name\"]\n",
        "  #collection  = db.Ingestion\n",
        "  #val = collection.find_one({\"sourcePath\": data_path})\n",
        "  try:\n",
        "    data = read_delta(data_path)\n",
        "    if str(data.schema[col_name].dataType) == \"StringType\":\n",
        "      data = TokenizeAndSave(data_path , data , col_name)\n",
        "      #write_delta(data , data_path)\n",
        "      #comments_dic = {\"comment\" : f\"Applied Tokenization on Column {col_name}\", \"task\" : \"Tokenization\",\"params\" : kwargs['params'] , \"time\" : dt.datetime.now() ,\"domain\" : \"DataSecurity\"}\n",
        "      #WriteComment(data_path , comments_dic)\n",
        "      get_total_rows=read_delta(data_path + \"/tokenized\")\n",
        "      print(get_total_rows.count())\n",
        "      return {\"Status\" : 200 , \"Message\" : \"Tokenized Successfully\"}\n",
        "    elif str(data.schema[col_name].dataType) in [\"IntegerType\", \"LongType\",'FloatType','DoubleType']:\n",
        "      data = data.withColumn(col_name , data[col_name].cast(StringType()))\n",
        "      #data = data.withColumn(col_name,sha2(col_name,256))\n",
        "      data = TokenizeAndSave(data_path , data , col_name)\n",
        "      #write_delta(data , data_path)\n",
        "      #comments_dic = {\"comment\" : f\"Applied Tokenization on Column {col_name}\", \"task\" : \"Tokenization\",\"params\" : kwargs['params'] , \"time\" : dt.datetime.now() ,\"domain\" : \"DataSecurity\"}\n",
        "      #WriteComment(data_path , comments_dic)\n",
        "      get_total_rows=read_delta(data_path + \"/tokenized\")\n",
        "      print(get_total_rows.count())\n",
        "      return {\"Status\" : 200 , \"Message\" : \"Tokenized Successfully\"}\n",
        "    else:\n",
        "      return {\"Status\" : 201 , \"Message\" : \"Cannot Tokenize\"}\n",
        "  except:\n",
        "    return {\"Status\" : 400 , \"Message\" : \"Cannot Tokenize\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM-gANfZ8wRj"
      },
      "source": [
        "def TokenizeAndSave(data_path , data , col_name):\n",
        "    data1 = data.withColumn('tokenize_' + col_name,sha2(col_name,256))\n",
        "    final_data = data1.select(col_name,'tokenize_' + col_name)\n",
        "    data3 = data1.drop(col(col_name))\n",
        "    data3 = data3.withColumnRenamed('tokenize_' + col_name , col_name)\n",
        "    if os.path.isfile(data_path + \"_secure\"):\n",
        "        old_data = read_delta(data_path + \"_secure\")\n",
        "        old_data = old_data.withColumn(\"_id_\", monotonically_increasing_id())\n",
        "        final_data = final_data.withColumn(\"_id_\", monotonically_increasing_id())\n",
        "        final_data = old_data.join(final_data, \"_id_\", \"outer\").drop(\"_id_\")\n",
        "    write_delta(final_data , data_path + \"_secure\")\n",
        "    data3.show(5)\n",
        "    return data3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWznyLm19NDi"
      },
      "source": [
        "def New_TokenizeAndSave(data_path , data , col_name):\n",
        "    data1 = data.withColumn('tokenize_' + col_name,sha2(col_name,256))\n",
        "    #final_data = data1.select(col_name,'tokenize_' + col_name)\n",
        "    data3 = data1.drop(col(col_name))\n",
        "    data3 = data3.withColumnRenamed('tokenize_' + col_name , col_name)\n",
        "    \"\"\"\n",
        "    if os.path.isfile(data_path + \"_secure\"):\n",
        "        old_data = read_delta(data_path + \"_secure\")\n",
        "        old_data = old_data.withColumn(\"_id_\", monotonically_increasing_id())\n",
        "        final_data = final_data.withColumn(\"_id_\", monotonically_increasing_id())\n",
        "        final_data = old_data.join(final_data, \"_id_\", \"outer\").drop(\"_id_\")\n",
        "    write_delta(final_data , data_path + \"_secure\")\"\"\"\n",
        "    \n",
        "    data3.show(5)\n",
        "    return data3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaLzOSxv7-kW"
      },
      "source": [
        "def Tokenization(data_path,col_name):\n",
        "    data = read_delta(data_path)\n",
        "    if str(data.schema[col_name].dataType) == \"StringType\":\n",
        "      data = New_TokenizeAndSave(data_path , data , col_name)\n",
        "      #get_total_rows=read_delta(data_path + \"_secure\")\n",
        "      #print(get_total_rows.count())\n",
        "      return {\"Status\" : 200 , \"Message\" : \"Tokenized Successfully\"}\n",
        "    elif str(data.schema[col_name].dataType) in [\"IntegerType\", \"LongType\",'FloatType','DoubleType']:\n",
        "      data = data.withColumn(col_name , data[col_name].cast(StringType()))\n",
        "      data = New_TokenizeAndSave(data_path , data , col_name)\n",
        "      #get_total_rows=read_delta(data_path + \"_secure\")\n",
        "      #get_total_rows.count()\n",
        "      return {\"Status\" : 200 , \"Message\" : \"Tokenized Successfully\"}\n",
        "    else:\n",
        "      return {\"Status\" : 201 , \"Message\" : \"Cannot Tokenize\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnmi26d3Y5oP"
      },
      "source": [
        "def TransformationsHist(data_path,val1) :\n",
        "    #id_ = kwargs[\"params\"][\"id_\"]\n",
        "    #val = extract_data(id_)\n",
        "    #collection1 = db.VersionHistory\n",
        "    #val1 = collection1.find_one({\"file_id\": id_}, {\"version_hist\": 1, \"_id\": 0})\n",
        "    # print(val1)\n",
        "    #data_path = val[\"sourcePath\"]\n",
        "    deltaTable = DeltaTable.forPath(spark, data_path)\n",
        "    fullHistoryDF = deltaTable.history()\n",
        "    versions = list(map(lambda x: x[0], fullHistoryDF.select(\"version\").collect()))\n",
        "    # print(versions)\n",
        "    # time_stamps = list(map(lambda x : x[0] ,fullHistoryDF.select(\"timestamp\").collect()))\n",
        "    if val1:\n",
        "        transformations_ = [j[\"task\"] for i in versions for j in val1[\"version_hist\"] if j[\"version\"] == i]\n",
        "        transformations_.append(\"No Transformations applied\")\n",
        "    else:\n",
        "        transformations_ = [\"No Transformations applied\"]\n",
        "    version = versions[0]\n",
        "    return_lis = []\n",
        "    for vers, time_s in zip(versions, transformations_):\n",
        "        if vers == version:\n",
        "            return_lis.append({\"version\": vers, \"transformation\": time_s, \"highlight\": \"True\"})\n",
        "        else:\n",
        "            return_lis.append({\"version\": vers, \"transformation\": time_s, \"highlight\": \"False\"})\n",
        "    resp = {\"Status\": 200, \"Message\": \"Success\", \"data\": return_lis}\n",
        "    return resp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2RIwRh5Zyl5"
      },
      "source": [
        "TransformationsHist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw7f_CJlkzCn",
        "outputId": "ad9ee2a5-4467-49ae-df4a-fb705cbf2fda"
      },
      "source": [
        "Tokenization('/content/Iris_new','Species')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+--------------------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|             Species|\n",
            "+---+-------------+------------+-------------+------------+--------------------+\n",
            "|  1|          5.1|         3.5|          1.4|         0.2|232df521071298799...|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|232df521071298799...|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|232df521071298799...|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|232df521071298799...|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|232df521071298799...|\n",
            "+---+-------------+------------+-------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Message': 'Tokenized Successfully', 'Status': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ApaSOYjmQ-"
      },
      "source": [
        "write_csv_as_delta('/content/Iris_new.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIiWxt9dkMxL"
      },
      "source": [
        "dd = read_delta('/content/Iris_new')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crS_NrW5S151"
      },
      "source": [
        "deltaTable = DeltaTable.forPath(spark, \"/content/Iris_new\")\n",
        "fullHistoryDF = deltaTable.history()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHkIEYnhTA5E",
        "outputId": "92351805-6ac9-4acc-af7a-bc8150c54250"
      },
      "source": [
        "fullHistoryDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+\n",
            "|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|\n",
            "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+\n",
            "|      1|2021-03-05 13:51:06|  null|    null|    WRITE|[mode -> Overwrit...|null|    null|     null|          0|          null|        false|\n",
            "|      0|2021-03-05 13:49:39|  null|    null|    WRITE|[mode -> Overwrit...|null|    null|     null|       null|          null|        false|\n",
            "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mK6HUVHTfNo"
      },
      "source": [
        "versions = fullHistoryDF.select(\"version\").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUiTqSm5TKCx",
        "outputId": "3d1033d3-506c-472e-bc8e-2b064ad2c6d2"
      },
      "source": [
        "versions = list(map(lambda x: x[0], versions))\n",
        "versions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBsbAaROkoxL",
        "outputId": "fe253e65-fdf6-4e9f-b7f5-98d70a470ee1"
      },
      "source": [
        "dd.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
            "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|\n",
            "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|\n",
            "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|\n",
            "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|\n",
            "| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|\n",
            "| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|\n",
            "| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|\n",
            "| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|\n",
            "| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|\n",
            "| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|\n",
            "| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|\n",
            "| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwO5eeSEgmaI"
      },
      "source": [
        "import os \n",
        "import pyspark\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import datetime\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import string\n",
        "import more_itertools as mit\n",
        "#import spark_utils\n",
        "from spark_utils import write_csv_as_delta,read_delta,read_csv,write_delta\n",
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yt_v1t2GKYl"
      },
      "source": [
        "def extract_destination_path(path:str):\n",
        "    split_path = path.split('/')\n",
        "    #file_name = split_path[-1]\n",
        "    strt = \"/\".join(split_path[3:-1])\n",
        "    strt += \"/archive\"  \n",
        "    return strt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nY4cNNS7a68"
      },
      "source": [
        "def Archive_(data_path):\n",
        "    #data_path = kwargs['params']['datapath']\n",
        "    #data = read_delta_as_pddf(data_path)\n",
        "    #data.to_csv(\"/tmp/example.csv\")\n",
        "    source = data_path.replace('queryslice', \"rawslice\")\n",
        "    source = source + \".csv\"\n",
        "    print(1111111111111111111111111111111,source)\n",
        "    destinatation = extract_destination_path(source)\n",
        "    print(2222222222222222222222222222222,destinatation)\n",
        "    #write_to_oss('LTAI4FnqiPhdZAnMDG2mF8yo', 'QDUNjPeBchtZYGxiy4f0YsjiP12FuY', 'ai-surge-prd-oss', \"http://oss-ap-south-1.aliyuncs.com\", \"/tmp/example.csv\", path) \n",
        "    #os.remove(\"/tmp/example.csv\")\n",
        "    return {'data':\"Success\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTEEyVguCYT8"
      },
      "source": [
        "#/content/oss:/ai-surge-prd-oss/surge-queryslice/retail_aisurge_com/demo/public_project/20210219_110513Sales_Trail.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbP1928XCF7G"
      },
      "source": [
        "path = \"oss:/ai-surge-prd-oss/surge-queryslice/retail_aisurge_com/demo/public_project/20210219_110513Sales_Trail\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGjf_BRVGhCp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmoSEaQaGhGE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0JpFV36GhKm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0SWuvl9GhOb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG6-H68DGhSD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fHFQe3uGhVw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm2a8IkF7a-V"
      },
      "source": [
        "def extract_destination_path(path:str):\n",
        "    split_path = path.split('/')\n",
        "    file_name = split_path[-1]\n",
        "    strt = \"/\".join(split_path[3:-1])\n",
        "    strt += \"/archive/\" + file_name + '.csv'\n",
        "    return strt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75uhMAksBgww"
      },
      "source": [
        "def Archive_(data_path):\n",
        "    #data_path = kwargs['params']['datapath']\n",
        "    destination = data_path.replace('queryslice', \"rawslice\")\n",
        "    path = extract_destination_path(destination)\n",
        "    print(11111111111111111111111,path)\n",
        "    write_to_oss('LTAI4FnqiPhdZAnMDG2mF8yo', 'QDUNjPeBchtZYGxiy4f0YsjiP12FuY', 'ai-surge-prd-oss', \"http://oss-ap-south-1.aliyuncs.com\", \"/tmp/example.csv\", path) \n",
        "    os.remove(\"/tmp/example.csv\")\n",
        "    return {'data':\"Success\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldK5IFrsA4rb"
      },
      "source": [
        "starting path = oss:surge-rawslice/retail_aisurge_com/demo/public_project/archive/20210219_110513Sales_Trail.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-jtLdYbBB8S"
      },
      "source": [
        "dalta path = oss:surge-rawslice/retail_aisurge_com/demo/public_project/archive/20210219_110513Sales_Trail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McrRc2fsBP0t"
      },
      "source": [
        "archive -----> starting path = oss:surge-rawslice/retail_aisurge_com/demo/public_project/archive/20210219_110513Sales_Trail.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbGF81TdZBsm"
      },
      "source": [
        "#############################Masking_Tokenization_pyspark.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R00mWNCYY7H"
      },
      "source": [
        "def Tokenization(**kwargs):\n",
        "  data_path = kwargs[\"params\"][\"data_path\"]\n",
        "  col_name = kwargs[\"params\"][\"col_name\"]\n",
        "  collection  = db.Ingestion\n",
        "  val = collection.find_one({\"sourcePath\": data_path})\n",
        "  try:\n",
        "    data = read_delta(data_path)\n",
        "    if str(data.schema[col_name].dataType) == \"StringType\":\n",
        "      data = TokenizeAndSave(data_path , data , col_name)\n",
        "      write_delta(data , data_path)\n",
        "      comments_dic = {\"comment\" : f\"Applied Tokenization on Column {col_name}\", \"task\" : \"Tokenization\",\"params\" : kwargs['params'] , \"time\" : dt.datetime.now() ,\"domain\" : \"DataSecurity\"}\n",
        "      WriteComment(data_path , comments_dic)\n",
        "      get_total_rows=read_delta(data_path + \"/tokenized\")\n",
        "      try:\n",
        "        get_securedatadetails=db.Secure.find_one({\"ingestion_id\":str(val[\"_id\"])})\n",
        "        if get_securedatadetails is None:\n",
        "            insert_baddata=db.Secure.insert({'sourcePath':f\"{val['sourcePath']}_secure\",\"project_name\": val[\"project_name\"],\"file_extention\": val[\"file_extention\"],\"rowcount\":get_total_rows.count(),\"domain\":val['domain'],\"ingestion_id\":str(val[\"_id\"]),\"created_date\":datetime.utcnow()})\n",
        "        else:\n",
        "            update_createddate_baddata=db.Secure.update_one({'_id' :get_securedatadetails['_id']},{\"$set\":{\"created_date\":datetime.utcnow(),\"rowcount\":get_total_rows.count()}})\n",
        "      except:\n",
        "        pass\n",
        "      return {\"Status\" : 200 , \"Message\" : \"Tokenized Successfully\"}\n",
        "    elif str(data.schema[col_name].dataType) in [\"IntegerType\", \"LongType\",'FloatType','DoubleType']:\n",
        "      data = data.withColumn(col_name , data[col_name].cast(StringType()))\n",
        "      #data = data.withColumn(col_name,sha2(col_name,256))\n",
        "      data = TokenizeAndSave(data_path , data , col_name)\n",
        "      write_delta(data , data_path)\n",
        "      comments_dic = {\"comment\" : f\"Applied Tokenization on Column {col_name}\", \"task\" : \"Tokenization\",\"params\" : kwargs['params'] , \"time\" : dt.datetime.now() ,\"domain\" : \"DataSecurity\"}\n",
        "      WriteComment(data_path , comments_dic)\n",
        "      get_total_rows=read_delta(data_path + \"/tokenized\")\n",
        "      try:\n",
        "        get_securedatadetails=db.Secure.find_one({\"ingestion_id\":str(val[\"_id\"])})\n",
        "        if get_securedatadetails is None:\n",
        "            insert_baddata=db.Secure.insert({'sourcePath':f\"{val['sourcePath']}_secure\",\"project_name\": val[\"project_name\"],\"file_extention\": val[\"file_extention\"],\"rowcount\":get_total_rows.count(),\"domain\":val['domain'],\"ingestion_id\":str(val[\"_id\"]),\"created_date\":datetime.utcnow()})\n",
        "        else:\n",
        "            update_createddate_baddata=db.Secure.update_one({'_id' :get_securedatadetails['_id']},{\"$set\":{\"created_date\":datetime.utcnow(),\"rowcount\":get_total_rows.count()}})\n",
        "      except:\n",
        "        pass\n",
        "      return {\"Status\" : 200 , \"Message\" : \"Tokenized Successfully\"}\n",
        "    else:\n",
        "      return {\"Status\" : 201 , \"Message\" : \"Cannot Tokenize\"}\n",
        "  except:\n",
        "    return {\"Status\" : 400 , \"Message\" : \"Cannot Tokenize\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqwp7Bmta7IC"
      },
      "source": [
        "def ApplyAutomatedDataQuality(**kwargs) -> dict:\n",
        "    id_ = kwargs['params']['_id']\n",
        "    data_type_cols = kwargs['params']['data_type_cols']\n",
        "    recommended_nulls = kwargs['params']['recommended_nulls']\n",
        "    custom_null_cols = kwargs['params']['custom_null_cols']\n",
        "    custom_null_vals = kwargs['params']['custom_null_vals']\n",
        "    tokenize_cols = kwargs['params']['tokenize_cols']\n",
        "    mask_cols = kwargs['params']['mask_cols']\n",
        "    mask_vals = kwargs['params']['mask_vals']\n",
        "    noise_cols = kwargs['params']['noise_cols']\n",
        "    rejected_noise_cols = kwargs['params']['rejected_noise_cols']\n",
        "    rejected_null_cols = kwargs['params']['rejected_null_cols']\n",
        "    val = extract_data(id_)\n",
        "    data_path = val[\"sourcePath\"]\n",
        "    data = read_delta(data_path)\n",
        "    #print(data.columns)\n",
        "    data = HandleNulls(data , recommended_nulls , custom_null_cols , custom_null_vals,rejected_null_cols)\n",
        "    data = HandleStringColumns(data , data_type_cols)\n",
        "    data = HandleNoise(data , noise_cols,rejected_noise_cols)\n",
        "    if type(data) == str :\n",
        "        return {\"Status\" : 400 , \"Message\" : \"ErrorWhileHandlingNoise\"}\n",
        "    data = tokenize_sensitive(data_path , data , tokenize_cols)\n",
        "    if type(data) == str :\n",
        "        return {\"Status\" : 400 , \"Message\" : \"ErrorWhileTokenization\",\"col\": data}\n",
        "    try:\n",
        "        get_total_rows=read_delta(data_path + \"/tokenized\")\n",
        "        count=get_total_rows.count()\n",
        "        get_securedatadetails=db.Secure.find_one({\"ingestion_id\":id_})\n",
        "        if get_securedatadetails is None:\n",
        "            insert_baddata=db.Secure.insert({'sourcePath':f\"{val['sourcePath']}_secure\",\"project_name\": val[\"project_name\"],\"file_extention\": val[\"file_extention\"],\"domain\":val['domain'],\"ingestion_id\":id_,\"rowcount\":get_total_rows.count(),\"created_date\":datetime.utcnow()})\n",
        "        else:\n",
        "            update_createddate_baddata=db.Secure.update_one({'_id' :get_securedatadetails['_id']},{\"$set\":{\"created_date\":datetime.utcnow(),\"rowcount\":get_total_rows.count()}})\n",
        "    except:\n",
        "        pass\n",
        "    data = mask_sensitive(data , mask_cols , mask_vals)\n",
        "    write_delta(data , data_path)\n",
        "    comments_dic = {\"comment\" : \"Applied Automated Data Quality\", \"task\" : \"ApplyAutomatedDataQuality\",  \"params\" : \"\" , \"time\" : datetime.now(),\"domain\" : \"Quality\"}\n",
        "    WriteComment(data_path, comments_dic)\n",
        "    return {\"Status\" : 200 , \"Message\" : \"QualityApplied\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amM0uJo6ZO3M"
      },
      "source": [
        "Automateddraquality.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hVa_YitLy1Z"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "#from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGOsE-4yUlTK"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages io.delta:delta-core_2.11:0.5.0 pyspark-shell\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark \n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas \n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhrL22rpNAKY",
        "outputId": "897fe05a-9dac-41fd-ee1f-784877064568"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/Noisy_churn.csv')\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                    0\n",
              "RowNumber                     0\n",
              "date                          0\n",
              "CustomerId                    0\n",
              "National_Insurance_number     0\n",
              "Credit_Card_No                0\n",
              "Surname                       0\n",
              "CreditScore                   0\n",
              "Geography                     0\n",
              "Gender                        0\n",
              "Age                          12\n",
              "Tenure                       25\n",
              "Balance                       0\n",
              "NumOfProducts                 0\n",
              "HasCrCard                     0\n",
              "IsActiveMember                0\n",
              "EstimatedSalary               0\n",
              "Exited                        0\n",
              "payment_mode                  0\n",
              "mailId                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-Lepvg5VGkX"
      },
      "source": [
        "from delta.tables import *\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import Window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBVoF_7_WTNR"
      },
      "source": [
        "def badandsave(data_path):\n",
        "    df = read_delta(data_path)\n",
        "    cl = df.columns\n",
        "    #w = Window.partitionBy(cl)\n",
        "    #df = df.select('*', f.count(cl[0]).over(w).alias('dupeCount')).where('dupeCount > 1').drop('dupeCount')\n",
        "    df = df.exceptAll(df.drop_duplicates(cl))\n",
        "    if df.count() > 0:\n",
        "        df = df.withColumn(\"Status\", lit('Dupicate_col'))\n",
        "        if os.path.isfile(data_path + \"_baddata\"):\n",
        "            old_data = read_delta(data_path + \"_baddata\")\n",
        "            if len(df.columns) == len(old_data.columns):\n",
        "                final_data = old_data.union(df)\n",
        "                #bad_data = df.union(bad_data)\n",
        "                write_delta(final_data , data_path + \"_baddata\")\n",
        "                return {\"Status\": 200, \"Message\": \"Bad data Successful\"}\n",
        "            else:\n",
        "                return {\"Status\": 400, \"Message\": \"columns mismatch\"}\n",
        "        else:\n",
        "            write_delta(df , data_path + \"_baddata\")\n",
        "            return {\"Status\": 200, \"Message\": \"Bad data Successful\"}\n",
        "    else:\n",
        "        {\"Status\": 400, \"Message\": \"No duplicate Rows\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKi5-NzQdq5y"
      },
      "source": [
        "#badandsave(\"/content/Iris_new\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fETDAOuu9pL"
      },
      "source": [
        "def bad_data(**kwargs):\n",
        "    data_path = kwargs[\"params\"][\"path\"]\n",
        "    #id_ = kwargs[\"params\"][\"_id\"]\n",
        "    #mail_anamoly = kwargs[\"params\"][\"mail_anamoly\"]\n",
        "    mail_col_reject = []\n",
        "    #mail_col = kwargs[\"params\"][\"mail_col\"]\n",
        "    null_anamoly = kwargs[\"params\"][\"null_anamoly\"]\n",
        "    null_col_custom = kwargs[\"params\"][\"custom_null_cols\"]\n",
        "    null_col_recommend = kwargs[\"params\"][\"recommended_nulls\"]\n",
        "    null_col_reject = kwargs[\"params\"][\"rejected_null_cols\"]\n",
        "    noise_anamoly = kwargs[\"params\"][\"noise_anamoly\"]\n",
        "    noise_col_remove = kwargs[\"params\"][\"noise_cols\"]\n",
        "    noise_col_reject = kwargs[\"params\"][\"rejected_noise_cols\"]\n",
        "    dropCol = kwargs[\"params\"][\"dropCol\"]\n",
        "    noise_col = []\n",
        "    data = read_delta(data_path)\n",
        "    df = data\n",
        "    #data = data.withColumn(\"Status\",lit(\"Not\"))\n",
        "    c,d,e = 0,0,0\n",
        "    data_lis = []\n",
        "    if null_anamoly==\"true\":\n",
        "        for col in  null_col_recommend + null_col_custom:\n",
        "            if col in null_col_recommend:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Recommend\"))\n",
        "                else:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Recommend\").otherwise(data['Status']))\n",
        "            elif col in null_col_custom:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Custom\"))\n",
        "                else:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Custom\").otherwise(data['Status']))\n",
        "            c += 1\n",
        "    if noise_anamoly == \"true\":\n",
        "        for col in noise_col + noise_col_remove:\n",
        "            if col in noise_col:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"No_action\"))\n",
        "                else:\n",
        "                    data = data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"No_action\").otherwise(data['Status']))\n",
        "            elif col in noise_col_remove:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Recommend\"))\n",
        "                else:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Recommend\").otherwise(data['Status']))\n",
        "            c += 1   \n",
        "    for col in mail_col_reject + null_col_reject + noise_col_reject :\n",
        "        if col in mail_col_reject:\n",
        "            if c == 0:\n",
        "                data = data.withColumn(\"Status\",when(~(data[col].rlike('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$')) , \"Mail Rejected\"))\n",
        "            else:\n",
        "                data = data.withColumn(\"Status\",when(~(data[col].rlike('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$')) , \"Mail Rejected\").otherwise(data['Status']))\n",
        "        if col in null_col_reject:\n",
        "            if c == 0: \n",
        "                data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Rejected\"))\n",
        "            else:\n",
        "                data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Rejected\").otherwise(data['Status']))\n",
        "\n",
        "        if col in noise_col_reject:\n",
        "            if c == 0:\n",
        "                data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Rejected\"))\n",
        "            else:\n",
        "                data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Rejected\").otherwise(data['Status']))  \n",
        "        c += 1     \n",
        "    try:\n",
        "        bad_data = data.filter(~data[\"Status\"].isNull())\n",
        "        bad_data = bad_data.dropDuplicates()\n",
        "        #bad_data.show()\n",
        "        #print(bad_data.columns)\n",
        "        if dropCol == True:\n",
        "            cl = df.columns\n",
        "            #w = Window.partitionBy(cl[0])\n",
        "            #df = df.select('*', f.count(cl).over(w).alias('dupeCount')).where('dupeCount > 1').drop('dupeCount')\n",
        "            df = df.exceptAll(df.drop_duplicates(cl))\n",
        "            if df.count() > 0:\n",
        "                df = df.withColumn(\"Status\", lit('Dupicate_col'))\n",
        "                df.show()\n",
        "                df.columns\n",
        "                bad_data = bad_data.union(df)\n",
        "\n",
        "        #bad_data.select(\"Status\").filter(data[\"Status\"] != \"Rejected\").show()\n",
        "        write_delta(bad_data , data_path + \"_\" + \"baddata\")\n",
        "        rejected_col=read_delta(data_path + \"_\" + \"baddata\")\n",
        "\n",
        "        total_null_rejected_col=rejected_col.filter(rejected_col.Status.like('%Null Rejected%'))\n",
        "        total_noise_rejected_col=rejected_col.filter(rejected_col.Status.like('%Noise Rejected%'))\n",
        "\n",
        "        total_null_recommended_col=rejected_col.filter(rejected_col.Status.like('%Null Recommend%'))\n",
        "        total_noise_recommended_col=rejected_col.filter(rejected_col.Status.like('%Noise Recommend%'))\n",
        "\n",
        "        total_null_Custom_col=rejected_col.filter(rejected_col.Status.like('%Null Custom%'))\n",
        "\n",
        "        total_mail_col=rejected_col.filter(rejected_col.Status.like('%Mail Rejected%'))\n",
        "        return {\"Message\":\"Bad data Sucess\",\"Status\":200}\n",
        "    except:\n",
        "        if dropCol == True:\n",
        "            resp = badandsave(data_path)\n",
        "            #return resp\n",
        "            if resp[\"Status\"] == 200:\n",
        "                rejected_col = read_delta(data_path + \"_\" + \"baddata\")\n",
        "                total_null_rejected_col = rejected_col.filter(rejected_col.Status.like('%Null Rejected%'))\n",
        "                total_noise_rejected_col = rejected_col.filter(rejected_col.Status.like('%Noise Rejected%'))\n",
        "\n",
        "                total_null_recommended_col = rejected_col.filter(rejected_col.Status.like('%Null Recommend%'))\n",
        "                total_noise_recommended_col = rejected_col.filter(rejected_col.Status.like('%Noise Recommend%'))\n",
        "\n",
        "                total_null_Custom_col = rejected_col.filter(rejected_col.Status.like('%Null Custom%'))\n",
        "\n",
        "                total_mail_col = rejected_col.filter(rejected_col.Status.like('%Mail Rejected%'))\n",
        "                total_duplicate_col_rejected = rejected_col.filter(rejected_col.Status.like('%Dupicate_col%'))\n",
        "                return resp ,total_null_rejected_col.count(),total_duplicate_col_rejected.count()\n",
        "            else:\n",
        "                return resp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDoxr0CV9y0z"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NPtjQPWbECS"
      },
      "source": [
        "from spark_utils import read_csv,read_delta,write_delta,write_csv_as_delta,read_delta_as_pddf,read_delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S2TX6I_bw_t"
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT7m8PcH5iUs"
      },
      "source": [
        "write_csv_as_delta(\"/content/Iris_new.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z_SCngg6B9x"
      },
      "source": [
        "df = read_delta('/content/Iris_new')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oNv8tMm90N8"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKCvxk0p6Ln"
      },
      "source": [
        "cl = df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2-PgAi2p4qV"
      },
      "source": [
        "df = df.exceptAll(df.drop_duplicates(cl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aYHhvKIqvpN",
        "outputId": "4937c362-00f7-437d-de7a-6e9994029937"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------------+------------+-------------+------------+-----------+\n",
            "|Id0|Id1|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+---+-------------+------------+-------------+------------+-----------+\n",
            "|  2|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  2|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "+---+---+-------------+------------+-------------+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lWJ3cY90ce",
        "outputId": "62defecf-9476-4123-8c8d-75bcb3e62526"
      },
      "source": [
        "res = {\"params\":{\"path\":\"/content/Iris_new\",\n",
        "                \"null_anamoly\":\"false\",\n",
        "                \"custom_null_cols\":[],\n",
        "                \"recommended_nulls\":[],\n",
        "                \"rejected_null_cols\":[],\n",
        "                \"noise_anamoly\":\"false\",\n",
        "                \"noise_cols\":[],\n",
        "                \"rejected_noise_cols\":[],\n",
        "                 \"dropCol\":True}}\n",
        "bad_data(params = res[\"params\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Message': 'Bad data Successful', 'Status': 200}, 0, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9TZL6Atrsab",
        "outputId": "e6b5193c-c6bb-4bf7-ae93-2869da4335c2"
      },
      "source": [
        "old = read_delta(\"/content/Iris_new\")\n",
        "old.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLt4KAyrsno",
        "outputId": "774d5f38-fd22-49e5-8a51-8aeca29fa1e8"
      },
      "source": [
        "new = read_delta(\"/content/Iris_new_baddata\")\n",
        "new.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft40PO80rsta"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1C9cCdpGjsg"
      },
      "source": [
        "data_no_null = df.na.drop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luZmaRwUGX6F",
        "outputId": "655dad3c-842d-4bca-c672-94ef6a959c5e"
      },
      "source": [
        "data_no_null.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
            "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|\n",
            "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|\n",
            "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|\n",
            "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|\n",
            "| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcTDtx6UGixB"
      },
      "source": [
        "df = df.drop(\"SepalLengthCm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUckvRT6kPxC",
        "outputId": "31bb6854-9815-4f95-a81a-733df66195ad"
      },
      "source": [
        "!pip install presidio-analyzer\n",
        "!pip install presidio-anonymizer\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting presidio-analyzer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/0f/572aa2729ffc55bfc98ea9678aaee12c9cfead1b4a5769d8c80392332975/presidio_analyzer-2.2.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 6.3MB/s \n",
            "\u001b[?25hCollecting regex==2020.11.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/b2/8f281520d9f08d0f6771b8160a87a4b487850cde9f1abe257da4d8bab599/regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 8.3MB/s \n",
            "\u001b[?25hCollecting tldextract==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.0MB/s \n",
            "\u001b[?25hCollecting spacy==3.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/70/a0b8bd0cb54d8739ba4d6fb3458785c3b9b812b7fbe93b0f10beb1a53ada/spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 313kB/s \n",
            "\u001b[?25hCollecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract==3.1.0->presidio-analyzer) (2.23.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract==3.1.0->presidio-analyzer) (3.0.12)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from tldextract==3.1.0->presidio-analyzer) (2.10)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (3.10.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (54.2.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (3.0.5)\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (1.0.5)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/53/97dc0197cca9357369b3b71bf300896cf2d3604fa60ffaaf5cbc277de7de/pathy-0.4.0-py3-none-any.whl\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (0.8.2)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/d8/e25bc7f99877de34def57d36769f0cce4e895b374cdc766718efc724f9ac/spacy_legacy-3.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (3.7.4.3)\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/82/a5/b5021c74c04cac35a27d34cbf3146d86eb8e173b4491888bc4908c4c8b3b/catalogue-2.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (20.9)\n",
            "Collecting thinc<8.1.0,>=8.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (2.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5->presidio-analyzer) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from requests-file>=1.4->tldextract==3.1.0->presidio-analyzer) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract==3.1.0->presidio-analyzer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract==3.1.0->presidio-analyzer) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract==3.1.0->presidio-analyzer) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy==3.0.5->presidio-analyzer) (3.4.1)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 57.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.5->presidio-analyzer) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.0.5->presidio-analyzer) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.0.5->presidio-analyzer) (1.1.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=4b6aeefc1bd9f5f29e8a81a7ca11aa3822a81e14de4005e17fb2f58afce55ed6\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: pyyaml, regex, requests-file, tldextract, pydantic, catalogue, srsly, smart-open, typer, pathy, spacy-legacy, thinc, spacy, presidio-analyzer\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.3 pathy-0.4.0 presidio-analyzer-2.2.0 pydantic-1.7.3 pyyaml-5.4.1 regex-2020.11.13 requests-file-1.5.1 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.2 srsly-2.4.1 thinc-8.0.3 tldextract-3.1.0 typer-0.3.2\n",
            "Collecting presidio-anonymizer\n",
            "  Downloading https://files.pythonhosted.org/packages/11/70/8ee659fa28be7dfccf0c43f1267bf1ba17e50319bb61e4f28bedc24a6885/presidio_anonymizer-2.2.0-py3-none-any.whl\n",
            "Collecting pycryptodome==3.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/16/9627ab0493894a11c68e46000dbcc82f578c8ff06bc2980dcd016aea9bd3/pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 6.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pycryptodome, presidio-anonymizer\n",
            "Successfully installed presidio-anonymizer-2.2.0 pycryptodome-3.10.1\n",
            "2021-04-19 19:28:29.760301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting en-core-web-lg==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0-py3-none-any.whl (778.8MB)\n",
            "\u001b[K     |████████████████████████████████| 778.8MB 20kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (20.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (54.2.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.10.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.4.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "2u0sA1kkmsRJ",
        "outputId": "d5b59b4f-abb7-4a44-9b3b-b7e4f6cef78f"
      },
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "text=\"My phone number is 212-555-5555\"\n",
        "\n",
        "# Set up the engine, loads the NLP module (spaCy model by default) \n",
        "# and other PII recognizers\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "# Call analyzer to get results\n",
        "results = analyzer.analyze(text=text,\n",
        "                           entities=[\"PHONE_NUMBER\"],\n",
        "                           #entities=[\"Name\"],\n",
        "                           language='en')\n",
        "#print(entities)\n",
        "\n",
        "# Analyzer results are passed to the AnonymizerEngine for anonymization\n",
        "\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n",
        "\n",
        "print(anonymized_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-19 19:55:49,465] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'My'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,467] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'phone'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,470] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'number'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,472] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token 'is'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,474] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token '212'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,475] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token '-'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,477] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token '555'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,478] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token '-'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "[2021-04-19 19:55:49,479] [WARNING] [W108] The rule-based lemmatizer did not find POS annotation for the token '5555'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3d4d4baae1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                            \u001b[0;31m#entities=[\"Name\"],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                            language='en')\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Analyzer results are passed to the AnonymizerEngine for anonymization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'entities' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SROQOHKunM1V",
        "outputId": "cd8e9728-2377-485c-dba0-9fb3dc743a4d"
      },
      "source": [
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[type: PHONE_NUMBER, start: 19, end: 31, score: 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt5UnjxbGbMN",
        "outputId": "6f147605-9d0b-4e31-b9b3-92ce90aa77da"
      },
      "source": [
        "len(data.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auWBHIPMXIAt",
        "outputId": "e9c13b98-c8c7-47da-c70a-ee0a389229b2"
      },
      "source": [
        "res = {\"params\":{\"path\":\"/content/Iris_new\",\n",
        "                \"null_anamoly\":\"false\",\n",
        "                \"custom_null_cols\":[],\n",
        "                \"recommended_nulls\":[],\n",
        "                \"rejected_null_cols\":[],\n",
        "                \"noise_anamoly\":\"false\",\n",
        "                \"noise_cols\":[],\n",
        "                \"rejected_noise_cols\":[],\n",
        "                 \"dropCol\":True}}\n",
        "bad_data(params = res[\"params\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Message': 'Bad data Successful', 'Status': 200}, 0, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qvPkS5wh1kn",
        "outputId": "807dc4fd-cda6-4df1-ff6f-7717ba2a3249"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'custom_null_cols': [],\n",
              "  'dropCol': True,\n",
              "  'noise_anamoly': 'false',\n",
              "  'noise_cols': [],\n",
              "  'null_anamoly': 'false',\n",
              "  'path': '/content/Iris_new',\n",
              "  'recommended_nulls': [],\n",
              "  'rejected_noise_cols': [],\n",
              "  'rejected_null_cols': []}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fG40wxu4uR3",
        "outputId": "5a460a2c-1b23-4ab6-ceb6-91f050311664"
      },
      "source": [
        "res = {\"params\":{\"path\":\"/content/Iris_new\",\n",
        "                \"null_anamoly\":\"false\",\n",
        "                \"custom_null_cols\":[\"PetalLengthCm\"],\n",
        "                \"recommended_nulls\":[\"SepalWidthCm\"],\n",
        "                \"rejected_null_cols\":[\"SepalLengthCm\"],\n",
        "                \"noise_anamoly\":\"false\",\n",
        "                \"noise_cols\":[],\n",
        "                \"rejected_noise_cols\":[],\n",
        "                 \"dropCol\":True}}\n",
        "bad_data(params = res[\"params\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+---------------+-------------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        Species|       Status|\n",
            "+---+-------------+------------+-------------+------------+---------------+-------------+\n",
            "| 98|         null|         2.9|          4.3|         1.3|Iris-versicolor|Null Rejected|\n",
            "| 97|         null|         2.9|          4.2|         1.3|Iris-versicolor|Null Rejected|\n",
            "| 42|         null|         2.3|          1.3|         0.3|    Iris-setosa|Null Rejected|\n",
            "| 83|         null|         2.7|          3.9|         1.2|Iris-versicolor|Null Rejected|\n",
            "| 43|         null|         3.2|          1.3|         0.2|    Iris-setosa|Null Rejected|\n",
            "| 53|         null|         3.1|          4.9|         1.5|Iris-versicolor|Null Rejected|\n",
            "| 61|         null|         2.0|          3.5|         1.0|Iris-versicolor|Null Rejected|\n",
            "| 85|         null|         3.0|          4.5|         1.5|Iris-versicolor|Null Rejected|\n",
            "| 77|         null|         2.8|          4.8|         1.4|Iris-versicolor|Null Rejected|\n",
            "| 51|         null|         3.2|          4.7|         1.4|Iris-versicolor|Null Rejected|\n",
            "| 52|         null|         3.2|          4.5|         1.5|Iris-versicolor|Null Rejected|\n",
            "| 39|         null|         3.0|          1.3|         0.2|    Iris-setosa|Null Rejected|\n",
            "| 35|         null|         3.1|          1.5|         0.1|    Iris-setosa|Null Rejected|\n",
            "| 54|         null|         2.3|          4.0|         1.3|Iris-versicolor|Null Rejected|\n",
            "| 37|         null|         3.5|          1.3|         0.2|    Iris-setosa|Null Rejected|\n",
            "| 95|         null|         2.7|          4.2|         1.3|Iris-versicolor|Null Rejected|\n",
            "| 84|         null|         2.7|          5.1|         1.6|Iris-versicolor|Null Rejected|\n",
            "| 62|         null|         3.0|          4.2|         1.5|Iris-versicolor|Null Rejected|\n",
            "| 45|         null|         3.8|          1.9|         0.4|    Iris-setosa|Null Rejected|\n",
            "| 88|         null|         2.3|          4.4|         1.3|Iris-versicolor|Null Rejected|\n",
            "+---+-------------+------------+-------------+------------+---------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species', 'Status']\n",
            "+---+-------------+------------+-------------+------------+-----------+------------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|      Status|\n",
            "+---+-------------+------------+-------------+------------+-----------+------------+\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|Dupicate_col|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|Dupicate_col|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|Dupicate_col|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|Dupicate_col|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|Dupicate_col|\n",
            "+---+-------------+------------+-------------+------------+-----------+------------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Message': 'Bad data Sucess', 'Status': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUnR6GwrLfvJ",
        "outputId": "b6a4794c-0180-4e2f-f4cd-e9c65f599bb3"
      },
      "source": [
        "dup_col = read_delta(\"/content/Iris_new_baddata\")\n",
        "dup_col.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+---------------+-------------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        Species|       Status|\n",
            "+---+-------------+------------+-------------+------------+---------------+-------------+\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|    Iris-setosa| Dupicate_col|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|    Iris-setosa| Dupicate_col|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|    Iris-setosa| Dupicate_col|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|    Iris-setosa| Dupicate_col|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|    Iris-setosa| Dupicate_col|\n",
            "| 56|         null|         2.8|          4.5|         1.3|Iris-versicolor|Null Rejected|\n",
            "| 72|         null|         2.8|          4.0|         1.3|Iris-versicolor|Null Rejected|\n",
            "| 63|         null|         2.2|          4.0|         1.0|Iris-versicolor|Null Rejected|\n",
            "| 66|         null|         3.1|          4.4|         1.4|Iris-versicolor|Null Rejected|\n",
            "| 69|         null|         2.2|          4.5|         1.5|Iris-versicolor|Null Rejected|\n",
            "| 70|         null|         2.5|          3.9|         1.1|Iris-versicolor|Null Rejected|\n",
            "+---+-------------+------------+-------------+------------+---------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WEYlWtaYCTV",
        "outputId": "034fd3b8-0fcc-4bba-839a-648e7c727271"
      },
      "source": [
        "dd = read_delta(\"/content/Iris_new_baddata\")\n",
        "dd.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+------------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|      Status|\n",
            "+---+-------------+------------+-------------+------------+-----------+------------+\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|Dupicate_col|\n",
            "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|Dupicate_col|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|Dupicate_col|\n",
            "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|Dupicate_col|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|Dupicate_col|\n",
            "+---+-------------+------------+-------------+------------+-----------+------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cM8NzilIjTW"
      },
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import Window\n",
        "cl = df.columns\n",
        "w = Window.partitionBy(cl)\n",
        "df = df.select('*', f.count(cl[3]).over(w).alias('dupeCount'))\\\n",
        "    .where('dupeCount > 1')\\\n",
        "    .drop('dupeCount')\n",
        "df = df.withColumn(\"Status\", lit('Dupicate_col'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYk2oiJwIpg1"
      },
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import Window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmvxOAy-e-W0",
        "outputId": "858a0631-0cbe-47b8-fc09-7e776d64a932"
      },
      "source": [
        "data = read_delta('/content/Noisy_churn_baddata')\n",
        "data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmsspB2KfZiI"
      },
      "source": [
        "df = read_delta_as_pddf('/content/Noisy_churn_baddata')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "NeB4ihNkffNx",
        "outputId": "0177cb06-6884-4864-f264-96e4e0fc3a74"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_c0</th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>date</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>National_Insurance_number</th>\n",
              "      <th>Credit_Card_No</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>payment_mode</th>\n",
              "      <th>mailId</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2632</td>\n",
              "      <td>2633</td>\n",
              "      <td>11/1/2012</td>\n",
              "      <td>15716000</td>\n",
              "      <td>VH 07 51 54 K</td>\n",
              "      <td>3122 0340 5397 1936</td>\n",
              "      <td>Hs?eh</td>\n",
              "      <td>638</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>48.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0$</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7919.08$</td>\n",
              "      <td>0</td>\n",
              "      <td>debit_card</td>\n",
              "      <td>abcdjkm@nots.qtw</td>\n",
              "      <td>NoiseRecommend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6950</td>\n",
              "      <td>6951</td>\n",
              "      <td>12/23/2016</td>\n",
              "      <td>15667392</td>\n",
              "      <td>EJ 67 95 72 N</td>\n",
              "      <td>9351 4888 3499 1102</td>\n",
              "      <td>L?</td>\n",
              "      <td>652</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>123081.84$</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>188657.97$</td>\n",
              "      <td>0</td>\n",
              "      <td>debit_card</td>\n",
              "      <td>hello#.com</td>\n",
              "      <td>NoiseRecommend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1280</td>\n",
              "      <td>1281</td>\n",
              "      <td>7/16/2011</td>\n",
              "      <td>15671590</td>\n",
              "      <td>QH 63 40 44 R</td>\n",
              "      <td>2278 9553 4194 6110</td>\n",
              "      <td>H?</td>\n",
              "      <td>741</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0$</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>73873.65$</td>\n",
              "      <td>0</td>\n",
              "      <td>debit_card</td>\n",
              "      <td>hello#.com</td>\n",
              "      <td>NoiseRecommend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>5/7/2010</td>\n",
              "      <td>15717426</td>\n",
              "      <td>IR 97 35 07 W</td>\n",
              "      <td>5934 2656 8683 0445</td>\n",
              "      <td>Armstrong</td>\n",
              "      <td>850</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0$</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>40812.9$</td>\n",
              "      <td>0</td>\n",
              "      <td>debit_card</td>\n",
              "      <td>abc.dfx@qnom.uhpb</td>\n",
              "      <td>NullRecommend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>941</td>\n",
              "      <td>942</td>\n",
              "      <td>3/19/2011</td>\n",
              "      <td>15676521</td>\n",
              "      <td>WC 38 70 68 H</td>\n",
              "      <td>1909 1895 5756 5155</td>\n",
              "      <td>Y?an</td>\n",
              "      <td>696</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>31.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0$</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>191074.11$</td>\n",
              "      <td>0</td>\n",
              "      <td>debit_card</td>\n",
              "      <td>hello#.com</td>\n",
              "      <td>NoiseRecommend</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    _c0  RowNumber        date  ...  payment_mode             mailId          Status\n",
              "0  2632       2633   11/1/2012  ...    debit_card   abcdjkm@nots.qtw  NoiseRecommend\n",
              "1  6950       6951  12/23/2016  ...    debit_card         hello#.com  NoiseRecommend\n",
              "2  1280       1281   7/16/2011  ...    debit_card         hello#.com  NoiseRecommend\n",
              "3    38         39    5/7/2010  ...    debit_card  abc.dfx@qnom.uhpb   NullRecommend\n",
              "4   941        942   3/19/2011  ...    debit_card         hello#.com  NoiseRecommend\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mugb0ZPfjD8",
        "outputId": "2dc847fb-fb17-40cd-e68c-ec2d1480e113"
      },
      "source": [
        "df['Status'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoiseRecommend    95\n",
              "NullRejected      25\n",
              "NullRecommend     11\n",
              "Name: Status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD5B4ligm4KD"
      },
      "source": [
        "a = []\n",
        "b = []\n",
        "c = []\n",
        "for li in zip(a,b,c):\n",
        "    if not li:\n",
        "        print('scvsavgjasxsa')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlT8rG7pXBPR"
      },
      "source": [
        "Code for Deployement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRgCaZeTgS8X"
      },
      "source": [
        "def bad_data(**kwargs):\n",
        "    #path = kwargs[\"params\"][\"path\"]\n",
        "    id_ = kwargs[\"params\"][\"_id\"]\n",
        "    #mail_anamoly = kwargs[\"params\"][\"mail_anamoly\"]\n",
        "    mail_col_reject = []\n",
        "    #mail_col = kwargs[\"params\"][\"mail_col\"]\n",
        "    null_anamoly = kwargs[\"params\"][\"null_anamoly\"]\n",
        "    null_col_custom = kwargs[\"params\"][\"custom_null_cols\"]\n",
        "    null_col_recommend = kwargs[\"params\"][\"recommended_nulls\"]\n",
        "    null_col_reject = kwargs[\"params\"][\"rejected_null_cols\"]\n",
        "    noise_anamoly = kwargs[\"params\"][\"noise_anamoly\"]\n",
        "    noise_col_remove = kwargs[\"params\"][\"noise_cols\"]\n",
        "    noise_col_reject = kwargs[\"params\"][\"rejected_noise_cols\"]\n",
        "    noise_col = []\n",
        "    #data = read_delta(path)\n",
        "    #data = data.withColumn(\"Status\",lit(\"Not\"))\n",
        "    c,d,e = 0,0,0\n",
        "    data_lis = []\n",
        "    collection  = db.Ingestion\n",
        "    val = collection.find_one({\"_id\": ObjectId(id_)})\n",
        "    #if val[\"sourcePath\"].split(\".\")[-1] not in [\"csv\",\"json\",\"tsv\"]:\n",
        "    #id_ = val[\"sourcePath\"].replace(\"queryslice\" , \"rawslice\") +\".\"+ val[\"file_extention\"]\n",
        "    data = read_delta(val[\"sourcePath\"])  \n",
        "    #data = data.withColumn(\"Status\",lit(\"Not\"))\n",
        "            \n",
        "    if null_anamoly==\"true\":\n",
        "        for col in  null_col_recommend + null_col_custom:\n",
        "            if col in null_col_recommend:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Recommend\"))\n",
        "                else:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Recommend\").otherwise(data['Status']))\n",
        "            elif col in null_col_custom:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Custom\"))\n",
        "                else:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Custom\").otherwise(data['Status']))\n",
        "            c += 1\n",
        "    if noise_anamoly == \"true\":\n",
        "        for col in noise_col + noise_col_remove:\n",
        "            if col in noise_col:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"No_action\"))\n",
        "                else:\n",
        "                    data = data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"No_action\").otherwise(data['Status']))\n",
        "            elif col in noise_col_remove:\n",
        "                if c == 0:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Recommend\"))\n",
        "                else:\n",
        "                    data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Recommend\").otherwise(data['Status']))\n",
        "            c += 1   \n",
        "    for col in mail_col_reject + null_col_reject + noise_col_reject :\n",
        "        if col in mail_col_reject:\n",
        "            if c == 0:\n",
        "                data = data.withColumn(\"Status\",when(~(data[col].rlike('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$')) , \"Rejected\"))\n",
        "            else:\n",
        "                data = data.withColumn(\"Status\",when(~(data[col].rlike('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$')) , \"Rejected\").otherwise(data['Status']))\n",
        "        elif col in null_col_reject:\n",
        "            if c == 0:\n",
        "                data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Rejected\"))\n",
        "            else:\n",
        "                data = data.withColumn(\"Status\",when((data[col].isNull() | isnan(data[col])) , \"Null Rejected\").otherwise(data['Status']))\n",
        "        elif col in noise_col_reject:\n",
        "            if c == 0:\n",
        "                data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Rejected\"))\n",
        "            else:\n",
        "                data = data.withColumn(\"Status\",when((data[col].rlike('[@_!#$%^&*()<>?/\\|}{~:]')) , \"Noise Rejected\").otherwise(data['Status']))  \n",
        "        c += 1     \n",
        "    bad_data = data.filter(~data[\"Status\"].isNull())\n",
        "    bad_data = bad_data.dropDuplicates()\n",
        "    #bad_data.select(\"Status\").filter(data[\"Status\"] != \"Rejected\").show()\n",
        "    write_delta(bad_data , val[\"sourcePath\"]+ \"_\" + \"baddata\")\n",
        "    rejected_col=read_delta(val[\"sourcePath\"]+ \"_\" + \"baddata\")\n",
        "    total_rejected_col=rejected_col.filter(rejected_col.Status.like('%Rejected%'))\n",
        "    total_recommended_col=rejected_col.filter(rejected_col.Status.like('%Recommend%'))\n",
        "    return  {\"Status\":200,\"Message\":\"Successful\",\"total_row_count\":rejected_col.count(),\"total_rejected_col\":total_rejected_col.count(),\"total_recommended_col\":total_recommended_col.count()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwHWIii9SiSv"
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdA1Ji7GJphu"
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brE9Rp7NBj0y"
      },
      "source": [
        "#df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").save('file_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grhPGlgzG9it"
      },
      "source": [
        "#df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save('file_test_teja')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEM3e-CrU8vM"
      },
      "source": [
        "def data_passer(data):\n",
        "    global data_frame\n",
        "    data_frame = data\n",
        "    return data_frame\n",
        "data_frame = data_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKS7JHwEUlWh"
      },
      "source": [
        "def read_csv(file_path : str , header : str= \"true\") -> pyspark.sql.dataframe.DataFrame:\n",
        "    df = spark.read.format(\"csv\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"header\", header) \\\n",
        "    .option(\"sep\", \",\") \\\n",
        "    .load(file_path)\n",
        "    data_passer(df)\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42-xDu53VByl"
      },
      "source": [
        "read_csv('/content/sample_data/california_housing_test.csv','true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGI_OhrrUlZo"
      },
      "source": [
        "def write_csv_as_delta(file_path : str) -> None:\n",
        "    df = read_csv(file_path)\n",
        "    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
        "    write_delta(df , file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0z2LhnAUldL"
      },
      "source": [
        "def write_delta(data : pyspark.sql.dataframe.DataFrame, file_path : str , mode : str = \"overwrite\") -> None:\n",
        "    bad_cols = get_cols_with_bad_chars(data.columns)\n",
        "    if len(bad_cols) == 0:\n",
        "        pass\n",
        "    else :\n",
        "        for col_name , bad_char in bad_cols :\n",
        "            data = data.withColumnRenamed(col_name , ''.join(col_name.split(bad_char)))\n",
        "    data.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(mode).save(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blAoEJWJUlfk"
      },
      "source": [
        "def get_cols_with_bad_chars(cols : list) -> list :\n",
        "    bad_cols = []\n",
        "    for i in cols :\n",
        "        if \" \" in i :\n",
        "            bad_cols.append([i , \" \"])\n",
        "        elif \";\" in i :\n",
        "            bad_cols.append([i , \";\"])\n",
        "        elif \"?\" in i :\n",
        "            bad_cols.append([i , \"?\"])\n",
        "        elif \"!\" in i :\n",
        "            bad_cols.append([i , \"!\"])\n",
        "        elif \"@\" in i :\n",
        "            bad_cols.append([i , \"@\"])\n",
        "        elif \"#\" in i :\n",
        "            bad_cols.append([i , \"#\"])\n",
        "    return bad_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO8Pa8TaUlpN"
      },
      "source": [
        "def read_delta(file_path : str) -> (pyspark.sql.dataframe.DataFrame , str):\n",
        "    try :\n",
        "        data = spark.read.format(\"delta\").load(file_path)\n",
        "    except :\n",
        "        return \" File doesn't exist or its not in Delta format !\"\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFUmKtpvUlrp"
      },
      "source": [
        "def read_delta_as_pddf(file_path):\n",
        "    spark_df = read_delta(file_path)\n",
        "    if isinstance(spark_df , (str)):\n",
        "        return \" File doesn't exist or its not in Delta format !\"\n",
        "    pandas_df = spark_df.select(\"*\").toPandas()\n",
        "    return pandas_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6_DTowYVLSj"
      },
      "source": [
        "write_csv_as_delta('/content/Churn_latest_modifed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teJsFlghmTSm"
      },
      "source": [
        "df = read_delta('/content/Churn_latest_modifed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Aw1b8FlmYg-",
        "outputId": "9e27143e-9ca6-494d-862e-a4b56f0211fc"
      },
      "source": [
        "df.schema"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(RowNumber,IntegerType,true),StructField(date,StringType,true),StructField(CustomerId,IntegerType,true),StructField(NI_number,StringType,true),StructField(Credit_Card_No,StringType,true),StructField(Surname,StringType,true),StructField(CreditScore,IntegerType,true),StructField(Geography,StringType,true),StructField(Gender,StringType,true),StructField(Age,DoubleType,true),StructField(Tenure,DoubleType,true),StructField(Balance,StringType,true),StructField(NumOfProducts,IntegerType,true),StructField(HasCrCard,IntegerType,true),StructField(IsActiveMember,IntegerType,true),StructField(EstimatedSalary,StringType,true),StructField(Exited,IntegerType,true),StructField(payment_mode,StringType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIOqHvXGmrPn"
      },
      "source": [
        "from pyspark.sql.functions import to_timestamp\n",
        "from collections import Counter\n",
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC92_7DLoqHv"
      },
      "source": [
        "def getDate(Date: str, Structure: str = None):\n",
        "    if Date == 'null' or Date == None:\n",
        "        return None\n",
        "    # dates = list(datefinder.find_dates(Date))\n",
        "    try:\n",
        "        date = parse(Date)\n",
        "        if date is not None:\n",
        "            return date\n",
        "        else:\n",
        "            # datetime.strptime('01-01-0001', '%m-%d-%Y')\n",
        "            return None\n",
        "    except:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0_c5r_zmdc2"
      },
      "source": [
        "def convertToDateTime(file_path,col_name):\n",
        "    structure = None\n",
        "    data = read_delta(file_path)\n",
        "    data.show()\n",
        "    #dat_vals = data.select(col_name).collect()[:100]\n",
        "    dat_vals = data.select(col_name)\n",
        "    dat_vals = dat_vals.collect()[:100]\n",
        "    #return {\"da\":dat_vals}\n",
        "    dat_vals = list(map(lambda x : x[0] , dat_vals))\n",
        "    dat_vals = list(map(lambda x : getDate(x), dat_vals))\n",
        "    dat_vals = Counter(dat_vals)\n",
        "    #if dat_vals[None] > 20 :\n",
        "    #return {\"Status\" : 201 , \"Message\" : \"Not a Datetime to be converted to Datetype\"}\n",
        "    if str(data.schema[col_name].dataType) == \"StringType\":\n",
        "        func =  udf(lambda x: getDate(x , structure), DateType())\n",
        "        data = data.withColumn(col_name, func(col(col_name)))\n",
        "        #return {\"11111\":11111}\n",
        "        write_delta(data , file_path)\n",
        "        return {\"11111\":11111}\n",
        "    else :\n",
        "        return {\"Status\" : 201 , \"Message\" : \"Only String Datatypes can be converted to Datetime\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYFv9YdVoVi_",
        "outputId": "eb51a7ff-3c91-4a82-d36a-6f1dbe492679"
      },
      "source": [
        "convertToDateTime('/content/Churn_latest_modifed','date')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---------+----------+-------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+\n",
            "|RowNumber|     date|CustomerId|    NI_number|     Credit_Card_No|  Surname|CreditScore|Geography|Gender| Age|Tenure|   Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|payment_mode|\n",
            "+---------+---------+----------+-------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+\n",
            "|        1|4/24/2010|  15634602|EJ 87 23 16 H|6518 2286 9458 0302| Hargrave|        619|   France|Female|42.0|   2.0|      0.0$|            1|        1|             1|     101348.88$|     1|  debit_card|\n",
            "|        2|4/24/2010|  15647311|OL 43 31 62 W|1895 4190 0493 2177|     Hill|        608|    Spain|Female|41.0|   1.0| 83807.86$|            1|        0|             1|     112542.58$|     0|  debit_card|\n",
            "|        3|4/24/2010|  15619304|SP 19 16 08 Z|7391 2068 7721 4726|     Onio|        502|   France|Female|42.0|   8.0| 159660.8$|            3|        1|             0|     113931.57$|     1|  debit_card|\n",
            "|        4|4/25/2010|  15701354|BL 75 04 39 Q|8863 3167 4447 6130|     Boni|        699|   France|Female|null|   1.0|      0.0$|            2|        0|             0|      93826.63$|     0| Credit_card|\n",
            "|        5|4/25/2010|  15737888|VJ 49 13 25 F|6042 7133 1005 8123| Mitchell|        850|    Spain|Female|39.0|  null|125510.82$|            1|        1|             1|       79084.1$|     0| Credit_card|\n",
            "|        6|4/25/2010|  15574012|LI 01 30 98 Q|4425 9932 7939 1867|      Chu|        645|    Spain|  Male|null|   8.0|113755.78$|            2|        1|             0|     149756.71$|     1|  debit_card|\n",
            "|        7|4/26/2010|  15592531|EQ 03 89 69 M|7794 1734 3408 3103| Bartlett|        822|   France|  Male|50.0|  null|      0.0$|            2|        1|             1|       10062.8$|     0|  debit_card|\n",
            "|        8|4/26/2010|  15656148|RA 20 76 44 N|7862 7332 2009 7097|   Obinna|        376|  Germany|Female|29.0|   4.0|115046.74$|            4|        1|             0|     119346.88$|     1| Credit_card|\n",
            "|        9|4/26/2010|  15792365|XX 88 51 05 C|0985 3441 5947 6664|       He|        501|   France|  Male|44.0|   4.0|142051.07$|            2|        0|             1|       74940.5$|     0| Credit_card|\n",
            "|       10|4/27/2010|  15592389|HF 10 25 99 E|7783 3046 1162 8870|       H?|        684|   France|  Male|27.0|   2.0|134603.88$|            1|        1|             1|      71725.73$|     0|  debit_card|\n",
            "|       11|4/27/2010|  15767821|HR 79 79 37 T|4643 4252 8979 4317|   Bearce|        528|   France|  Male|null|  null|102016.72$|            2|        0|             0|      80181.12$|     0|  debit_card|\n",
            "|       12|4/27/2010|  15737173|UL 84 05 44 Y|2148 3870 3474 5852|  Andrews|        497|    Spain|  Male|24.0|  null|      0.0$|            2|        1|             0|      76390.01$|     0|  debit_card|\n",
            "|       13|4/28/2010|  15632264|NY 23 39 00 W|5111 6254 4955 3485|      Kay|        476|   France|Female|34.0|  null|      0.0$|            2|        1|             0|      26260.98$|     0|  debit_card|\n",
            "|       14|4/28/2010|  15691483|UP 19 02 03 O|1813 2711 3855 5658|     Chin|        549|   France|Female|34.0|   5.0|      0.0$|            2|        0|             0|     190857.79$|     0| Credit_card|\n",
            "|       15|4/28/2010|  15600882|BC 81 86 38 Z|1855 9335 9147 1280|    Scott|        635|    Spain|Female|34.0|   7.0|      0.0$|            2|        1|             1|      65951.65$|     0|  debit_card|\n",
            "|       16|4/29/2010|  15643966|OP 12 33 50 G|0486 0327 5429 1176|  Goforth|        616|  Germany|  Male|null|   3.0|143129.41$|            2|        0|             1|      64327.26$|     0| Credit_card|\n",
            "|       17|4/29/2010|  15737452|WM 60 91 78 K|8079 7648 7959 1858|    Romeo|        653|  Germany|  Male|58.0|   1.0|132602.88$|            1|        1|             0|       5097.67$|     1| Credit_card|\n",
            "|       18|4/29/2010|  15788218|MI 29 05 40 J|2375 4679 8792 5009|Henderson|        549|    Spain|Female|24.0|   9.0|      0.0$|            2|        1|             1|      14406.41$|     0| Credit_card|\n",
            "|       19|4/30/2010|  15661507|JM 62 01 40 X|3144 4069 0205 9336|  Muldrow|        587|    Spain|  Male|45.0|   6.0|      0.0$|            1|        0|             0|     158684.81$|     0| Credit_card|\n",
            "|       20|4/30/2010|  15568982|IR 51 70 14 X|5284 8662 0654 4079|      Hao|        726|   France|Female|24.0|   6.0|      0.0$|            2|        1|             1|      54724.03$|     0| Credit_card|\n",
            "+---------+---------+----------+-------------+-------------------+---------+-----------+---------+------+----+------+----------+-------------+---------+--------------+---------------+------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'11111': 11111}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78SCQO0LtfEO"
      },
      "source": [
        "import pandas as pd\n",
        "from fbprophet import Prophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0r8F6vDt_3j"
      },
      "source": [
        "# Python\n",
        "#df = pd.read_csv('/content/GOOG.csv')\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzkxYCRKuLUP"
      },
      "source": [
        "#df = df.drop(['Open','High','Low','Adj_Close','Volume'],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fqfjIUonuVnz",
        "outputId": "133aa4f7-d791-45a5-964d-67fa1cb519cb"
      },
      "source": [
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8/19/2004</td>\n",
              "      <td>49.982655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8/20/2004</td>\n",
              "      <td>53.952770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8/23/2004</td>\n",
              "      <td>54.495735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8/24/2004</td>\n",
              "      <td>52.239193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8/25/2004</td>\n",
              "      <td>52.802086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date      Close\n",
              "0  8/19/2004  49.982655\n",
              "1  8/20/2004  53.952770\n",
              "2  8/23/2004  54.495735\n",
              "3  8/24/2004  52.239193\n",
              "4  8/25/2004  52.802086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBWSLtRudU7"
      },
      "source": [
        "#df.columns = ['ds','y']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OytYlweIue7y",
        "outputId": "92b3f1b6-942c-4d61-a718-93a9be181d24"
      },
      "source": [
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ds</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8/19/2004</td>\n",
              "      <td>49.982655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8/20/2004</td>\n",
              "      <td>53.952770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8/23/2004</td>\n",
              "      <td>54.495735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8/24/2004</td>\n",
              "      <td>52.239193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8/25/2004</td>\n",
              "      <td>52.802086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ds          y\n",
              "0  8/19/2004  49.982655\n",
              "1  8/20/2004  53.952770\n",
              "2  8/23/2004  54.495735\n",
              "3  8/24/2004  52.239193\n",
              "4  8/25/2004  52.802086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJRIQ2e5aMpa"
      },
      "source": [
        "#df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2NbMvZHvyJA",
        "outputId": "7fc4ea7d-669b-4909-8970-65960a87d28e"
      },
      "source": [
        "#df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3809, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpxZ6bC15d_T"
      },
      "source": [
        "import random\n",
        "import pyspark\n",
        "import json\n",
        "import time,os,sys\n",
        "import string\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from fbprophet import Prophet\n",
        "from fbprophet.serialize import model_to_json, model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPe0qmImAbWc"
      },
      "source": [
        "\"\"\"def cureent_date_time():\n",
        "    current_time = time.time()\n",
        "    name = str(current_time).split('.')[0]\n",
        "    res = ''.join(random.choices(string.ascii_uppercase , k = 5))\n",
        "    final_name = ''.join(name+res+'.json')\n",
        "    return final_name\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5BIdXAyQheH",
        "outputId": "d50a42b9-8548-4f1c-8f15-a676428a7ab7"
      },
      "source": [
        "def test(string): \n",
        "\tprint(string)\n",
        "\tstring = \"GeeksforGeeks\"\n",
        "\tprint(\"Inside Function:\", string) \n",
        "\t\n",
        "test(string) \n",
        "print(\"Outside Function:\", string) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Geeks\n",
            "Inside Function: GeeksforGeeks\n",
            "Outside Function: Geeks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2V2gEbFGrEn"
      },
      "source": [
        "def write_pickle_aws(Access_key : str , Secret_key : str , Bucket : str , Key : str , Object):\n",
        "    client = boto3.client(\n",
        "                        's3',\n",
        "                        aws_access_key_id = Access_key,\n",
        "                        aws_secret_access_key = Secret_key\n",
        "                    )\n",
        "    pickle_byte_obj = pickle.dumps(Object)\n",
        "    response = client.put_object(Body=pickle_byte_obj, Bucket=Bucket, Key=Key)\n",
        "    return {\"Status\" : response[\"ResponseMetadata\"][\"HTTPStatusCode\"]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh6MYeXDJDWy"
      },
      "source": [
        "def load_pickle_aws(Access_key : str , Secret_key : str , Bucket : str , Key : str):\n",
        "    client = boto3.client(\n",
        "                        's3',\n",
        "                        aws_access_key_id = Access_key,\n",
        "                        aws_secret_access_key = Secret_key\n",
        "                    )\n",
        "    response = client.get_object(Bucket=Bucket, Key=Key)\n",
        "    body = response['Body'].read()\n",
        "    data = pickle.loads(body)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzIqxBkJVP_G"
      },
      "source": [
        "\"\"\"def SaveModel(path_model ,  type_ , user_id ,model_name,model):\n",
        "    if type_ == 'local':\n",
        "        with open(path_model + '/' + model_name,'w') as fout:\n",
        "            json.dump(model_to_json(model), fout)\n",
        "        #pickle_out.close()\n",
        "    elif type_ == 's3':\n",
        "        ak , sec = get_acess_and_secret(user_id)\n",
        "        bucket = path_model.split(\"/\")[2]\n",
        "        key = '/'.join((path_model).split(\"/\")[3:])\n",
        "        key = key + '/' + model_name\n",
        "        write_pickle_aws(ak , sec , bucket , key , model)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g45zW-jbAws-"
      },
      "source": [
        "#os.makedirs(path + '/forcasting',exist_ok = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptHf87IUFf8a"
      },
      "source": [
        "#pickle_out = open(test + '/forcasting' + \"/model.Teja\",\"wb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTTtv-qx8Iio"
      },
      "source": [
        "def SaveModel(type_ , path, user_id , model):\n",
        "    if type_ == 'local':\n",
        "        #print(\"haii\",11111111111111111111111111111111111111)\n",
        "        #path = path.split('.')[0] \n",
        "        #print(path)      \n",
        "        os.makedirs(path +'/forcasting',exist_ok =True)\n",
        "        print(path)\n",
        "        pickle_out = open(path + '/forcasting' + \"/model.Teja\",\"wb\")\n",
        "        #print(\"haii\",2222222222222222222222222222222222222)\n",
        "        pickle.dump(model, pickle_out)\n",
        "        pickle_out.close()\n",
        "    elif type_ == 's3':\n",
        "        ak , sec = get_acess_and_secret(user_id)\n",
        "        bucket = path.split(\"/\")[2]\n",
        "        key = '/'.join((path).split(\"/\")[3:])\n",
        "        key = key + \"/model.Teja\"\n",
        "        write_pickle_aws(ak , sec , bucket , key , model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LrBNp9NIyAo"
      },
      "source": [
        "#model = Prophet()  \n",
        "#model.fit(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KriHJyfBIede"
      },
      "source": [
        "#Traning('local','/content/GOOG.csv','Date','Close',1245)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1lsbf8QIbhR"
      },
      "source": [
        "#SaveModel('local','/content/GOOG.csv',1234,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "zF6W5Cm7GqOY",
        "outputId": "7318e83d-f9a8-4d04-eef2-8ff1548b204a"
      },
      "source": [
        "\"\"\"def SaveModel(path_model ,  type_ , user_id , model):\n",
        "    if type_ == 'local':\n",
        "        path_model = path.split('.')[0]       \n",
        "\t    #os.makedirs(path + '/forcasting',exist_ok = True)\n",
        "        pickle_out = open(path_model + \"/model.Teja\",\"wb\")\n",
        "        pickle.dump(model, pickle_out)\n",
        "        pickle_out.close()\n",
        "    elif type_ == 's3':\n",
        "        ak , sec = get_acess_and_secret(user_id)\n",
        "        bucket = path_model.split(\"/\")[2]\n",
        "        key = '/'.join((path_model).split(\"/\")[3:])\n",
        "        key = key + \"/model.Teja\"\n",
        "        write_pickle_aws(ak , sec , bucket , key , model)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def SaveModel(path_model ,  type_ , user_id , model):\\n    if type_ == \\'local\\':\\n        path_model = path.split(\\'.\\')[0]       \\n\\t    #os.makedirs(path + \\'/forcasting\\',exist_ok = True)\\n        pickle_out = open(path_model + \"/model.Teja\",\"wb\")\\n        pickle.dump(model, pickle_out)\\n        pickle_out.close()\\n    elif type_ == \\'s3\\':\\n        ak , sec = get_acess_and_secret(user_id)\\n        bucket = path_model.split(\"/\")[2]\\n        key = \\'/\\'.join((path_model).split(\"/\")[3:])\\n        key = key + \"/model.Teja\"\\n        write_pickle_aws(ak , sec , bucket , key , model)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifNuiYOS16lr"
      },
      "source": [
        "#data_path = \"oss://ai-surge-prd-oss/surge-rawslice/raacom/iliyaz/public_project/99123588-19ef-11eb-aecd-00163e013ddc_samplepipe_delimiter\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VzKHNTi2Axc"
      },
      "source": [
        "#model_path = data_path.split('.')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbPGwp0r2ecb"
      },
      "source": [
        "/content/GOOG/forcasting/data_goo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7VT7yimPrEr"
      },
      "source": [
        "data_goo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqWPYK2xVWVt"
      },
      "source": [
        "def LoadModel(path_model , type_ , user_id):\n",
        "    if type_ == 'local':\n",
        "        pickle_in = open(path_model + '/forcasting/model.Teja' ,\"rb\")\n",
        "        model = pickle.load(pickle_in)\n",
        "        return model\n",
        "    elif type_ == 's3':\n",
        "        ak , sec = get_acess_and_secret(user_id)\n",
        "        bucket = path_model.split(\"/\")[2]\n",
        "        key = '/'.join((path_model).split(\"/\")[3:])\n",
        "        key = key + \"/model.Teja\"\n",
        "        return load_pickle_aws(ak , sec , bucket , key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJTZ-uo50fD0"
      },
      "source": [
        "def Data_set(path,date_column,prediction_column):\n",
        "    df = read_delta_as_pddf(path)\n",
        "    df.head()\n",
        "    df = df[[date_column,prediction_column]]\n",
        "    if df.isnull().sum().sum() > 0:\n",
        "    \tprint('Removed column')\n",
        "    \tdf = df.dropna()\n",
        "    df.columns  = ['ds','y']\n",
        "    df[\"ds\"]= pd.to_datetime(df[\"ds\"])\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxQO5KgoK7lr"
      },
      "source": [
        "#df = read_delta_as_pddf('/content/GOOGNull')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKKEhRWUK_2e"
      },
      "source": [
        "#df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpPRGOBwVXWd"
      },
      "source": [
        "#Data_set('/content/GOOGNull','Date','Close')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMua0RgWcGTM"
      },
      "source": [
        "orig_out = sys.stdout\n",
        "sys.stdout = open(os.devnull, 'w')\n",
        "sys.stdout = orig_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBfekjZlniUi"
      },
      "source": [
        "#path = '/content/GOOG/teja/iliyaz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDJ01bl0nnat"
      },
      "source": [
        "#path = path.split('/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4FPm5n4fkb"
      },
      "source": [
        "def save_model_col(path,some_obj):\n",
        "    os.makedirs(path + '/columns/',exist_ok =True)\n",
        "    with open(path + '/columns/' + '/mypickle.pickle', 'wb') as f:\n",
        "        pickle.dump(some_obj, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVc5EgC74kdu"
      },
      "source": [
        "def load_model_col(path):\n",
        "    with open(path + '/columns/' + '/mypickle.pickle', 'rb') as f:\n",
        "        loaded_obj = pickle.load(f)\n",
        "        return loaded_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crcxUKSxQWIo"
      },
      "source": [
        "#df = Data_set('/content/GOOG','Date','Close')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ijJZ3ut3Uc7"
      },
      "source": [
        "def Traning(path,date_column,prediction_column,user_id,type_):\n",
        "    df = Data_set(path,date_column,prediction_column)\n",
        "    df['ds'] = pd.to_datetime(df['ds']).dt.date\n",
        "    max_date = df['ds'].max()\n",
        "    #max_date = str(max_date)\n",
        "    #max_date = max_date.split(' ')[0]\n",
        "    print(max_date)\n",
        "    some_obj = {'columns_':[date_column,prediction_column]}\n",
        "    save_model_col(path,some_obj)\n",
        "    #print(\"haii\",2222222222222222222222222222222222222)\n",
        "    #pickle.dump(model, pickle_out)\n",
        "    #import logging\n",
        "    #logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "    model = Prophet()  \n",
        "    model.fit(df)\n",
        "    SaveModel(type_, path , user_id , model)\n",
        "    return {'model saved Sucessfully'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVjvAsDfpUvw",
        "outputId": "0eeefe25-12d0-400c-f66f-1a63dab5705e"
      },
      "source": [
        "Traning('/content/GOOG','Date','Close',1245,'local')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-10-04\n",
            "/content/GOOG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model saved Sucessfully'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F69_q081wLsC"
      },
      "source": [
        "def data_frame(window,date):\n",
        "    ls = []\n",
        "    for i in range(window): \n",
        "        date += datetime.timedelta(days=1)\n",
        "        ls.append(date)\n",
        "    data = pd.DataFrame(ls,columns =['ds'])\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa35_yv_69JH"
      },
      "source": [
        "import time\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_MOGKz263jM"
      },
      "source": [
        "def data_frame(window,date):\n",
        "    ls = []\n",
        "    for i in range(window): \n",
        "        date += datetime.timedelta(days=1)\n",
        "        ls.append(date)\n",
        "    return ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGha1kLaBf9X",
        "outputId": "eb3d37f7-d6a2-40de-8f55-10549a6fca87"
      },
      "source": [
        "date = datetime.datetime(2003,8,1)\n",
        "date -= datetime.timedelta(days=30)\n",
        "date"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2003, 7, 2, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe1ZWfSjCetI"
      },
      "source": [
        "def Max_min_time(Table_name,date,window):\n",
        "    client.execute(f'USE {DB}')\n",
        "    max_date = client.execute(f\"SELECT max {date} FROM {Table_name}\")\n",
        "    date = datetime.datetime(max_date)\n",
        "    min_date -= datetime.timedelta(days=window)\n",
        "    min_date\n",
        "    data = client.execute(f\"SELECT * FROM {Table_name} WHERE {date} BETWEEN {min_date} AND {max_date}\")\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MTgM1w3IyEi"
      },
      "source": [
        "SElect * from {Table_name} where concat(toYear({col}),toMonth(Date)) >= select concat(toYear({col}),toMonth(Date)) from (select subtractMonths(Max(Date), 2) as Date from Sales_Trail) t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgwiNYAcOkMa"
      },
      "source": [
        "client.execute(f\"SELECT * FROM {Table_name} WHERE date BETWEEN {min_date} AND {max_date}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-nx0509-18S",
        "outputId": "706f4eb2-c928-4f30-cdd9-35e2e7f71158"
      },
      "source": [
        "date = datetime.datetime(2003,8,1,12,4,5)\n",
        "\n",
        "for i in range(30): \n",
        "    date -= datetime.timedelta(days=1)\n",
        "    print(date) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2003-07-31 12:04:05\n",
            "2003-07-30 12:04:05\n",
            "2003-07-29 12:04:05\n",
            "2003-07-28 12:04:05\n",
            "2003-07-27 12:04:05\n",
            "2003-07-26 12:04:05\n",
            "2003-07-25 12:04:05\n",
            "2003-07-24 12:04:05\n",
            "2003-07-23 12:04:05\n",
            "2003-07-22 12:04:05\n",
            "2003-07-21 12:04:05\n",
            "2003-07-20 12:04:05\n",
            "2003-07-19 12:04:05\n",
            "2003-07-18 12:04:05\n",
            "2003-07-17 12:04:05\n",
            "2003-07-16 12:04:05\n",
            "2003-07-15 12:04:05\n",
            "2003-07-14 12:04:05\n",
            "2003-07-13 12:04:05\n",
            "2003-07-12 12:04:05\n",
            "2003-07-11 12:04:05\n",
            "2003-07-10 12:04:05\n",
            "2003-07-09 12:04:05\n",
            "2003-07-08 12:04:05\n",
            "2003-07-07 12:04:05\n",
            "2003-07-06 12:04:05\n",
            "2003-07-05 12:04:05\n",
            "2003-07-04 12:04:05\n",
            "2003-07-03 12:04:05\n",
            "2003-07-02 12:04:05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIg5_-N-7KJQ",
        "outputId": "55465856-320a-4d29-8eb3-2acbd9debaa4"
      },
      "source": [
        "from datetime import date\n",
        "\n",
        "today = date.today()\n",
        "today"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2021, 3, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsT-NypY8Mmh",
        "outputId": "e2dbbd33-3d68-447e-cfe8-0a5fe88c6cb5"
      },
      "source": [
        "from datetime import date\n",
        "\n",
        "today = date.today()\n",
        "\n",
        "# dd/mm/YY\n",
        "d1 = today.strftime(\"%d/%m/%Y\")\n",
        "print(\"d1 =\", d1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d1 = 04/03/2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2JwePs4g7CDm",
        "outputId": "ec771659-117b-4b1f-88d5-ee0207c89e38"
      },
      "source": [
        "data_frame(30,\"04/03/2021\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-50c10d82c1ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"04/03/2021\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-a89b83abbc58>\u001b[0m in \u001b[0;36mdata_frame\u001b[0;34m(window, date)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdate\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"datetime.timedelta\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwaKL8-OuLrV"
      },
      "source": [
        "def predictions_2(path,window_length,type_ , user_id):\n",
        "    data = load_model_col(path)\n",
        "    date = data['Date_'][0]\n",
        "    data = data_frame(window_length,date)\n",
        "    model = LoadModel(path,type_ , user_id)\n",
        "    predictions = model.predict(data)\n",
        "    return predictions[['ds','yhat']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp9dTzx3uzYC"
      },
      "source": [
        "ls = predictions_2('/content/GOOG',7,'local',1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "BqOtVOOlwB54",
        "outputId": "f6cbc6e8-0788-4a56-b9d1-726d0f137b9c"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ds</th>\n",
              "      <th>yhat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-10-05</td>\n",
              "      <td>1244.251543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-10-06</td>\n",
              "      <td>1244.685272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-10-07</td>\n",
              "      <td>1248.890882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-10-08</td>\n",
              "      <td>1250.070120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-10-09</td>\n",
              "      <td>1250.803406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2019-10-10</td>\n",
              "      <td>1251.709928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2019-10-11</td>\n",
              "      <td>1252.111707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ds         yhat\n",
              "0 2019-10-05  1244.251543\n",
              "1 2019-10-06  1244.685272\n",
              "2 2019-10-07  1248.890882\n",
              "3 2019-10-08  1250.070120\n",
              "4 2019-10-09  1250.803406\n",
              "5 2019-10-10  1251.709928\n",
              "6 2019-10-11  1252.111707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPliYmdesZDs"
      },
      "source": [
        "import time,datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhyK_Eq6hBkp"
      },
      "source": [
        "import os,pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EOaR3x4hPsZ"
      },
      "source": [
        "# os.makedirs(path +'/forcasting',exist_ok =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMqf8FSFgb8x"
      },
      "source": [
        "some_obj = {'columns_forcasting':['date_column','prediction_column'], 'Date_':['2020-13-25']}\n",
        "os.makedirs('/content/sample_data/columns/',exist_ok =True)\n",
        "pickle_out = open('/content/sample_data/columns' + '/colums.teja',\"wb\")\n",
        "pickle.dump(some_obj, pickle_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTUzLSjGmGQj"
      },
      "source": [
        "#path = '/content/sample_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBoF1mYBj5mn"
      },
      "source": [
        "def save_model_col(path,some_obj):\n",
        "    os.makedirs(path + '/columns/',exist_ok =True)\n",
        "    with open(path + '/columns/' + '/mypickle.pickle', 'wb') as f:\n",
        "        pickle.dump(some_obj, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPr6xOnWmxfM"
      },
      "source": [
        "def load_model_col(path):\n",
        "    with open(path + '/columns/' + '/mypickle.pickle', 'rb') as f:\n",
        "        loaded_obj = pickle.load(f)\n",
        "        return loaded_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9NvwQyAkACl"
      },
      "source": [
        "with open('/content/sample_data/columns/' +'mypickle.pickle','rb') as f:\n",
        "    loaded_obj = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jb6aM9RkLdS",
        "outputId": "cbc27356-a002-4d5b-8a3f-a4a467a1e660"
      },
      "source": [
        "loaded_obj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Date_': ['2020-13-25'],\n",
              " 'columns_forcasting': ['date_column', 'prediction_column']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc1Sz5sodw2s"
      },
      "source": [
        "df = Data_set('/content/GOOG','Date','Close')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEYKOsM1fBj0"
      },
      "source": [
        "some_obj = {'columns_forcasting':[date_column,prediction_column], 'Date_':[max_date]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4xB7xJSFeBeS",
        "outputId": "d9e12700-529d-4c0d-f195-04ef0c4dcb1f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ds</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2004-08-19</td>\n",
              "      <td>49.982655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-08-20</td>\n",
              "      <td>53.952770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-08-23</td>\n",
              "      <td>54.495735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-08-24</td>\n",
              "      <td>52.239193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-08-25</td>\n",
              "      <td>52.802086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ds          y\n",
              "0 2004-08-19  49.982655\n",
              "1 2004-08-20  53.952770\n",
              "2 2004-08-23  54.495735\n",
              "3 2004-08-24  52.239193\n",
              "4 2004-08-25  52.802086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLaMIYbleETc",
        "outputId": "157b0eb6-3baa-4aef-a592-fd310fb98cc8"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ds    datetime64[ns]\n",
              "y            float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_W2UoqqeH30"
      },
      "source": [
        "cl_ = []\n",
        "cl_.append([i for i in df.columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZsrjOSCeMJc",
        "outputId": "e14cfe88-b25f-4873-f03d-286af10172d2"
      },
      "source": [
        "cl_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ds', 'y']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "SYRZWMrKDkK5",
        "outputId": "487af640-4be6-4fc7-a298-cbe0823de13d"
      },
      "source": [
        "\"\"\"def Traning(path,date_column,prediction_column):\n",
        "    df = Data_set(path,date_column,prediction_column)\n",
        "    model = Prophet()  \n",
        "    model.fit(df)\n",
        "    model_name = cureent_date_time()\n",
        "    with open(model_name, 'w') as fout:\n",
        "        json.dump(model_to_json(model), fout) \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def Traning(path,date_column,prediction_column):\\n    df = Data_set(path,date_column,prediction_column)\\n    model = Prophet()  \\n    model.fit(df)\\n    model_name = cureent_date_time()\\n    with open(model_name, 'w') as fout:\\n        json.dump(model_to_json(model), fout) \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MiMFTv3XpLl"
      },
      "source": [
        "df = Data_set('/content/GOOG','Date','Close')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_UIojjBZ7C_"
      },
      "source": [
        "import sys\n",
        "orig_out = sys.stdout\n",
        "sys.stdout = open(os.devnull, 'w')\n",
        "#m.fit(df)\n",
        "model = Prophet()\n",
        "model.fit(df)\n",
        "sys.stdout = orig_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hppYOoOybTlq"
      },
      "source": [
        "def Traning(path,date_column,prediction_column,user_id,type_):\n",
        "    df = Data_set(path,date_column,prediction_column)\n",
        "    #import logging\n",
        "    #logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "    orig_out = sys.stdout\n",
        "    sys.stdout = open(os.devnull, 'w')\n",
        "    model = Prophet()  \n",
        "    model.fit(df)\n",
        "    sys.stdout = orig_out\n",
        "    SaveModel(type_, path , user_id , model)\n",
        "    return {'model saved Sucessfully'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvIGr3Tpo-Yi"
      },
      "source": [
        "#Traning('/content/GOOG','Date','Close',1245,'local')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc09riXWXuM0",
        "outputId": "2b622ce0-01b4-4268-d9ae-fe9466336e5d"
      },
      "source": [
        "model = Prophet()\n",
        "import logging\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "logging.getLogger('fbprophet').setLevel(logging.ERROR)\n",
        "logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "model.fit(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fbprophet.forecaster.Prophet at 0x7faff021a7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BljwEFJX8rQ"
      },
      "source": [
        "# import logging\n",
        "# from fbprophet import Prophet\n",
        "\n",
        "# logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "\n",
        "# model = Prophet()\n",
        "# with self.suppress_stdout_stderr():\n",
        "#     model.fit(df)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M0Mh50WXlYU"
      },
      "source": [
        "import logging\n",
        "from fbprophet import Prophet\n",
        "\n",
        "logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "\n",
        "model = Prophet()\n",
        "with self.suppress_stdout_stderr():\n",
        "    model.fit(fit_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8ilJY7Aqb-",
        "outputId": "f6e26f7c-4f57-4667-8ef2-2432e00cebc1"
      },
      "source": [
        "Traning('/content/GOOG','Date','Close',1245,'local')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "local\n",
            "/content/GOOG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model saved Sucessfully'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUfr23GmEv7Q"
      },
      "source": [
        "#'/content/GOOG.csv'.split('.')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCfJ1ZUlJkoW"
      },
      "source": [
        "\"\"\"def load_model(model_name):\n",
        "    with open(model_name, 'r') as fin:\n",
        "        model = model_from_json(json.load(fin))\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAi3tVsn4cSW"
      },
      "source": [
        "li = [date_column,prediction_column]\n",
        "#predictios[li[0][1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpYUFK_JKf3"
      },
      "source": [
        "def prediction(path,date_column,prediction_column,window_size,type_,user_id):\n",
        "    Df = Data_set(path,date_column,prediction_column)\n",
        "    #model = load_model(model_name)\n",
        "    #path = path.split('.')[0]\n",
        "    path = path + '/forcasting/model.Teja'\n",
        "    #print(path)\n",
        "    model = LoadModel(path , type_ , user_id)\n",
        "    future = model.make_future_dataframe(periods=window_size,include_history = False)\n",
        "    predictios = model.predict(future)\n",
        "    predictios['ds'] = predictios['ds'].astype(str)\n",
        "    Table_val = predictios[['ds', 'yhat','yhat_lower', 'yhat_upper']]\n",
        "    Forcasting_val = predictios[['ds','yhat']]\n",
        "    return {'Blue':Df.to_dict(),'Red':Forcasting_val.to_dict(),'Table':Table_val.to_dict()}\n",
        "    #return Df,Forcasting_val,Table_val\n",
        "    #return Df.to_dict(),Forcasting_val.to_dict(),Table_val.to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtEiljCcKXlD"
      },
      "source": [
        "#prediction('/content/Churn_latest_modifed','date','CreditScore',7,'local',1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhmscDwkc6Kv"
      },
      "source": [
        "df3['ds'] = pd.to_datetime(df3['ds']).dt.date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmLldpc5dKL_"
      },
      "source": [
        "df3['ds'] = df3['ds'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l56iGWT7vC4A"
      },
      "source": [
        "#df3.to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_7FCKXlunq-"
      },
      "source": [
        "# Python\n",
        "m = Prophet()\n",
        "%time m.fit(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVo8H5xKuqrb"
      },
      "source": [
        "# Python\n",
        "future = m.make_future_dataframe(periods=365,include_history = False)\n",
        "#future.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7bVA8NpvYon"
      },
      "source": [
        "future.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tELZZ22Taaek"
      },
      "source": [
        "future.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-i07ht1vqGc"
      },
      "source": [
        "# Python\n",
        "forecast = m.predict(future)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTalUVlnwRvN"
      },
      "source": [
        "#forecast.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EariL0fEwQDJ"
      },
      "source": [
        "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0VVRAHkwfYr"
      },
      "source": [
        "# Python\n",
        "fig1 = m.plot(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_6KN8cGwnn4"
      },
      "source": [
        "# Python\n",
        "fig2 = m.plot_components(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giOsT3UXw1aB"
      },
      "source": [
        "# Python\n",
        "from fbprophet.plot import plot_plotly, plot_components_plotly\n",
        "\n",
        "plot_plotly(m, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OUP6XYAw5Rh"
      },
      "source": [
        "# Python\n",
        "plot_components_plotly(m, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umSrQoUVw9J3"
      },
      "source": [
        "# Python\n",
        "import json\n",
        "from fbprophet.serialize import model_to_json, model_from_json\n",
        "\n",
        "with open('serialized_model.json', 'w') as fout:\n",
        "    json.dump(model_to_json(m), fout)  # Save model\n",
        "\n",
        "with open('serialized_model.json', 'r') as fin:\n",
        "    m = model_from_json(json.load(fin))  # Load model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZNJkNCVJz0f"
      },
      "source": [
        "import pickle\n",
        "with open('forecast_model.pckl', 'wb') as fout:\n",
        "    pickle.dump(m, fout)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}